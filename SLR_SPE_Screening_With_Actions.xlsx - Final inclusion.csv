,,,,,,,,,,,,,,,,RE Task & Application Domain,,,,,,,,GenAI Model & Configuration,,,LLM Application Strategy & Prompt Engineering,,,,,Outputs & Resources,,,,Evaluation,,,Study Quality,,,,,Challenges & Future Directions,,,,,,,,,,,
New (2024.12-2025.5),Title,Authors,Year,Source,DOI,URL,Type,Title_lower,Status,Match_Selected,Match_Removed,Analysis_Action,Name,"Inclusion:  1. Papers addressing GenAI for RE AND 2. fully written in English
Exclusion: 1. . Papers that focus on GenAI for SE but not specifically on RE 
2. Papers that consider BERT as a GenAI or LLM 
3. Gray literature such as book chapters, PhD theses, white papers, and blogs 
4. Secondary studies (e.g., review articles, surveys) 
","Inclusion:[YES|NO]
If NO, following analysis is not necessary",full paper/ short paper,Elicitation,"Analysis","Specification","Validation",Management,Application Domain,Task Specificity,Specific LLM Model & Version,Fine-tuning,Parameters (Especially temperature),LLM Integration Strategy,LLM Application Techniques,Prompt Engineering (Learning paradigms),Prompt Type,Prompt Availability,Tool/Prototype Name,Tool Availability,Dataset/Benchmark Name,Dataset Availability,Evaluation Metrics,Evaluation Methodology,Characteristics of the model (ISO/IEC 25059),Q1: Is the research goal and context clearly stated in the paper?,Q2: Is the research methodology appropriate and rigorously applied to meet the stated objectives?,Q3: Is the data analysis comprehensive and are the results thoroughly presented?,Q4: Are the limitations adequately discussed and are meaningful suggestions provided for future research?,TOTAL,Bias and Fairness,Ethical and Regulatory Concerns,Security and Privacy,Interpretability and Explainability,Computational and Economic Cost,Real-Time Processing,Hallucinations,Reproducibility,Controllability,Authorship and Copyright,Industrial Adoption Status,Limitations
1,Evaluating Large Language Models in Exercises of UML Class Diagram Modeling,"De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca",2024,ACM DL,10.1145/3674805.3690741,https://doi.org/10.1145/3674805.3690741,,evaluating large language models in exercises of uml class diagram modeling,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Software development education,UML diagram generation,ChatGPT-4,No,No,Standalone (used as a single-step generator via a fixed prompt),No,One-shot ,Instruction,Yes,No,No,"Custom dataset of 20 educational UML exercises (proprietary compilation, publicly shared)",Yes,"Semantic Errors, Syntactic Errors, Pragmatic Errors",Controlled Experiment with human vs. LLM-generated diagrams,"Functional Suitability, Usability, ",1,1,1,1,4,1,0,0,1,0,0,1,1,0,0,Discussed Potential,"Small dataset, Only one prompt, One human annotator"
2,CoDefeater: Using LLMs To Find Defeaters in Assurance Cases,"Gohar, Usman and Hunter, Michael C. and Lutz, Robyn R. and Cohen, Myra B.",2024,ACM DL,10.1145/3691620.3695296,https://doi.org/10.1145/3691620.3695296,,codefeater: using llms to find defeaters in assurance cases,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,,1,,Safety-Critical Systems,Defeaters recognition,GPT-3.5-turbo,No,No,Standalone,No,Zero-shot/Role-based prompting,Instruction + Iterative,Yes,CoDefeater,Yes,"LHC MPS, sUAS Battery",Yes,Human Evaluation,Double review manual coding,"Functional Suitability, Usability",1,1,1,1,4,1,0,0,1,0,1,1,1,1,0,Prototype,"GPT-3.5 does not handle implicit assumptions well.
Only handles a single claim
Generalization ability"
3,Designing a Tool that automatically translates Makaton signs from live video streams into written English,"Karkalas, Sokratis and Omoyemi, Omotayo Emmanuel",2025,ACM DL,10.1145/3708635.3708647,https://doi.org/10.1145/3708635.3708647,,designing a tool that automatically translates makaton signs from live video streams into written english,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,General,System requirement mining capability,GPT-4,No,No,Standalone,multi-turn dialogue simulation,Role-based,Instruction + Iterative,Yes,No,No,Self-Build Requirements Scenarios Corpus,Yes,"Recall, Precision, F1-score",Multi-model comparison experiment,"Functional Suitability, Usability",1,1,1,1,4,1,0,0,1,0,0,1,1,1,0,Prototype,"The problem of context forgetting
Task simulation lacks real customer involvement"
4,BKRAG : A BGE Reranker RAG for similarity analysis of power project requirements,"Guo, Jun and Chen, Bojian and Zhao, Zhichao and He, Jindong and Chen, Shichun and Hu, Donglan and Pan, Hao",2024,ACM DL,10.1145/3689218.3689224,https://doi.org/10.1145/3689218.3689224,,bkrag : a bge reranker rag for similarity analysis of power project requirements,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,,,Power Project Requirements,Requirements Similarity Analysis,GPT-4 ,No,No,Hybrid: RAG + Rerank Model,Retrieval-Aided Prompting,,Instruction + Description,Yes,BKRAG,No,Power Project Dataset,No,"Hit Rate, MRR (Mean Reciprocal Rank)",Controlled experiment,Functional Suitability,1,1,1,0.5,3.5,0,0,0,0,1,0,1,0,1,0,Concept,"GPT-4 cost issues lead to only sampling a portion of the data
Generalization and multitasking ability were not discussed"
5,"Translation Titans, Reasoning Challenges: Satisfiability-Aided Language Models for Detecting Conflicting Requirements","Fazelnia, Mohamad and Mirakhorli, Mehdi and Bagheri, Hamid",2024,ACM DL,10.1145/3691620.3695302,https://doi.org/10.1145/3691620.3695302,,"translation titans, reasoning challenges: satisfiability-aided language models for detecting conflicting requirements",New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,,General software system,Conflicting Requirements Detection,GPT-4,No,No,SAT-LLM Framework, SMT formal logic reasoning/FOL formalization protocol,Few-shot + Instructional prompting,Instruction + Description + Example Based,Yes,SAT-LLM,No,From Fazelnia et al. 's work, Partial,"Precision, Recall, F1-Score",Controlled experiments,"Functional Suitability, Reliability, Performance Efficiency",1,1,1,1,4,0,0,0,1,0,0,1,0,1,0,Concept / Prototype,SAT-LLM has limited identification capabilities in Forbid-Stop and Output-Output type requirements
6,Toward Intelligent Generation of Tailored Graphical Concrete Syntax,"Ben Chaaben, Meriem and Ben Sghaier, Oussama and Dhaouadi, Mouna and Elrasheed, Nafisa and Darif, Ikram and Jaoua, Imen and Oakes, Bentley and Syriani, Eugene and Hamdaqa, Mohammad",2024,ACM DL,10.1145/3640310.3674085,https://doi.org/10.1145/3640310.3674085,,toward intelligent generation of tailored graphical concrete syntax,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,1,1,,Generic Domain,Concrete Syntax Generation/User Preference Modeling,GPT-4-1106-vision-preview,No,No,Standalone/Iterative,Symbolic reasoning,Few-shot+COT,Instruction+Description+Iterative refinement,Yes,Baseline intelligent CS generation framework,No,No,No,No,Case Study,"Usability, Functional Suitability",1,1,0.5,1,3.5,1,0,1,0,1,0,1,1,1,0,Concept/Vision paper,"Image generation capability is limited, especially for complex and abstract graphics."
7,What Is Wrong with My Model? Identifying Systematic Problems with Semantic Data Slicing,"Yang, Chenyang and Hong, Yining and Lewis, Grace and Wu, Tongshuang and K\""{a}stner, Christian",2024,ACM DL,10.1145/3691620.3695033,https://doi.org/10.1145/3691620.3695033,,what is wrong with my model? identifying systematic problems with semantic data slicing,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,,General-purpose ML model validation,Systematic error hypothesis validation,GPT-4-turbo-preview,No,"temperature=0, temperature=1",Standalone tool used in RE workflow,"Prompt optimization, few-shot example generation","Zero-shot,Few-shot ",Instruction + Classification prompt,Yes,SemSlicer,Yes,"CivilComments, HateCheck, AdaTest, Amazon Reviews",Yes,"F1-score,Accuracy ",Controlled experiment + Human subject case study,"Functional Suitability, Efficiency, Usability, Maintainability, Reproducibility/Portability",1,1,1,1,4,1,0,0,1,1,1,0,1,1,0,Prototype,The practical issues of label quality and few-shot sample synthesis
8,Rethinking Software Engineering in the Era of Foundation Models: A Curated Catalogue of Challenges in the Development of Trustworthy FMware,"Hassan, Ahmed E. and Lin, Dayi and Rajbahadur, Gopi Krishnan and Gallaba, Keheliya and Cogo, Filipe Roseiro and Chen, Boyuan and Zhang, Haoxiang and Thangarajah, Kishanthan and Oliva, Gustavo and Lin, Jiahuei (Justina) and Abdullah, Wali Mohammad and Jiang, Zhen Ming (Jack)",2024,ACM DL,10.1145/3663529.3663849,https://doi.org/10.1145/3663529.3663849,,rethinking software engineering in the era of foundation models: a curated catalogue of challenges in the development of trustworthy fmware,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,1,,,Enterprise-level software development scenarios,Challenges of requirements specification,GPT-4 ,Yes-Domain-adapted/Task-adapted,temperature=0,"Hybrid(Promptware, Agentware)","RLHF,Symbolic AI","Few-shot, COT","Instruction, Iterative Chains",Yes,FMArts,Partially open source,No,No,Human Evaluation. Correlation with GPT-4 Based Evaluation,"Based on experience summary, combined with the author's self-developed platform FMArts practice","Functional Suitability, Reliability, Performance Efficiency, Usability, Maintainability",1,0.5,0.5,1,3,1,1,0,1,1,0,1,0,0,0,Pilot Project to In-Production Transition,Lack of systematic empirical research
9,Towards an Automatic Extracting UML Class Diagram from System's Textual Specification,"Babaalla, Zakaria and Jakimi, Abdeslam and Oualla, Mohamed and Saadane, Rachid and Chehri, Abdellah",2024,ACM DL,10.1145/3659677.3659742,https://doi.org/10.1145/3659677.3659742,,towards an automatic extracting uml class diagram from system's textual specification,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,,Generic Domain,UML class diagram modeling task,LLaMA-2、GPT-2,No,No,Hybrid,"Bi-LSTM, Tree-LSTM, Softmax, Similarity Measures",No,No,No,No,No,No,NO,No,No,No,1,0.5,0,0.5,2,0,0,0,0,0,0,0,0,0,0,Early-stage concept,Model has not been trained yet and is in the stage of data preprocessing and corpus construction.
10,Emergence of A Novel Domain Expert: A Generative AI-based Framework for Software Function Point Analysis,"Zhao, Zheng and Jiang, Hongxiang and Zhao, Ran and He, Bing",2024,ACM DL,10.1145/3691620.3695293,https://doi.org/10.1145/3691620.3695293,,emergence of a novel domain expert: a generative ai-based framework for software function point analysis,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,"Multiple fields: government, financial management, social media, etc",Function Point (FP) analysis task,Qwen-72B,Yes- Densely Supervised Fine-Tuning,No,Standalone,"Densely Supervised Fine-Tuning (DSFT), ConceptAct Prompting",Few-shot,Instruction + Description + Example,Yes,FPA-EX,No,Self-built dataset,No,"Recall, False Alarm Rate (FAR), F1 Score",Controlled experiment + Case study,"Functional Suitability, Efficiency",1,1,1,1,4,0,0,1,0,0,0,0,0,0,0,Prototype / Pilot Project,"SRS data cannot be open-sourced and its reproduction capability is limited
Other RE tasks besides FPA (such as requirement conflict identification and tracking) are not involved"
11,ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering,"Ferrara, Carmine and Casillo, Francesco and Gravino, Carmine and De Lucia, Andrea and Palomba, Fabio",2024,ACM DL,10.1145/3597503.3639185,https://doi.org/10.1145/3597503.3639185,,refair: toward a context-aware recommender for fairness requirements engineering,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,"Including finance, education, medical care, politics, software, etc.","User behavior clustering, anomaly detection, term extraction, etc.",GPT-3.5,No,No,Standalone,No,No,instruction-based prompting,Yes,ReFAIR,Yes,Synthetic User Stories Dataset,Yes,"F1-score, Accuracy, Hamming Los, MoJo Distance","Ten-fold cross validation, Small-scale real-world user experiments","Functional Suitability, Performance Efficiency, Usability, Maintainability/Portability",1,1,1,1,4,1,1,0,1,0,0,0,1,1,0,Prototype ,"Sensitive to user story format, need support from actual development experience"
12,Automated Derivation of UML Sequence Diagrams from User Stories: Unleashing the Power of Generative AI vs. a Rule-Based Approach,"Jahan, Munima and Hassan, Mohammad Mahdi and Golpayegani, Reza and Ranjbaran, Golshid and Roy, Chanchal and Roy, Banani and Schneider, Kevin",2024,ACM DL,10.1145/3640310.3674081,https://doi.org/10.1145/3640310.3674081,,automated derivation of uml sequence diagrams from user stories: unleashing the power of generative ai vs. a rule-based approach,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,1,,Software Development Tools,Automatic structural analysis of user stories and  generate sequence diagrams (behavior modeling),ChatGPT-3.5,No,No,Standalone,No,Zero-shot,Instruction,Yes,No,Yes,Public dataset,Yes,Manual evaluation,Expert review + literature comparison + ChatGPT comparison,"Functional adaptability, Usability, Performance Efficiency",1,1,1,1,4,0,0,0,1,0,0,1,1,1,0,Concept/Prototype,ChatGPT over-models simple sentences; Performance of Rule-based methods declines under complex syntax
13,Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5,"Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa",2024,ACM DL,10.1145/3701625.3701687,https://doi.org/10.1145/3701625.3701687,,exploring the use of large language models in requirements engineering education: an experience report with chatgpt 3.5,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,1,,Generic RE tasks,"Identify functional vs non-functional requirements, extract intent and theme from user stories, detect contradictions between requirement sentences, classify NFRs (usability, security, etc.), extract actor-action-object from NL",GPT-3.5-turbo,No,temperature=0,Standalone,Using prompt-driven reasoning,"Zero-shot, Few-shot",Instruction+Question,Yes,No,No,"Puhua, Goal-oriented NFR, RE-Action, RE-MUC, RE-Codred, etc", Partial,"Accuracy, Precision/Recall/F1-score, Cohen’s Kappa, Human Evaluation",Quantitative Controlled Experiments,"Functional Suitability, Reliability, Usability",1,1,1,1,4,1,0,0,1,0,0,1,0,1,0,Experimental verification,"Task Settings have been simplified and cannot fully represent the actual RE scenarios.
Human annotators have difficulty making consistent judgments about contradiction labels"
14,Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach,"Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, Gerard and Maalej, Walid",2024,ACM DL,10.1145/3691620.3695591,https://doi.org/10.1145/3691620.3695591,,getting inspiration for feature elicitation: app store- vs. llm-based approach,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Generic RE tasks,User Story Completion,"GPT-3.5-turbo, GPT-4, Claude-2.1, PaLM-2, Command-R+",No,temperature = 0.5,Standalone(Use the LLM API to complete the full text without embedding specific RE tool processes),"Output Filtering, Ensemble Voting ",Few-shot ,Instruction + Structured Template Prompt,Yes,No,Yes, RE-UCDataset,Yes,"Automatic: BLEU, ROUGE, METEOR, BERTScore
Human Evaluation: Fluency, Coherence, Informativeness, Relevance",Controlled experiment + Human annotation + Inter-annotator agreement,"Functional Suitability, Usability",1,1,1,0.5,3.5,1,0,0,0,1,0,1,1,1,0,Concept/Prototype,"Due to the limited English corpus and data volume, as well as the annotations by a few experts"
15,Using LLMs for Use Case Modelling of IoT Systems: An Experience Report,"Tabassum, Mirza Rehenuma and Ritchie, Matthew J. and Mustafiz, Sadaf and Kienzle, J\""{o}rg",2024,ACM DL,10.1145/3652620.3687810,https://doi.org/10.1145/3652620.3687810,,using llms for use case modelling of iot systems: an experience report,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,1,,,Internet of Things (IoT),"Use Case Modelling, Exception + Handler Use Case Generation","GPT-4o, Gemini 1.5 Flash",No,"GPT-4: temperature = 0.5

Gemini: temperature = 0.0, top_p = 0.95",Standalone generation: LLM directly generates use case models based on the input unstructured descriptions,Only use multi-round prompt enhancement and structure template guidance,Few-shot ,Instruction + Descriptive,Yes,No,Yes,Self-constructed dataset,Yes,"overlap, missing, new, excess",Benchmark-based Human Evaluation,"Functional Suitabilit, Usability, Reliability",1,1,1,1,4,0,0,0,0,0,0,1,1,1,0,Concept/Prototype,Limitations such as prompt sensitivity and LLM’s lack of IoT domain knowledge
16,Self-Elicitation of Requirements with Automated GUI Prototyping,"Kolthoff, Kristian and Bartelt, Christian and Ponzetto, Simone Paolo and Schneider, Kurt",2024,ACM DL,10.1145/3691620.3695350,https://doi.org/10.1145/3691620.3695350,,self-elicitation of requirements with automated gui prototyping,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,User-facing systems,"GUI prototype generation and GUI feature recommendation
Matching self-demand expression based on natural language and visual GUI",GPT-4,No,No,Hybrid (LLM is one of the components responsible for GUI feature recommendation and is integrated into the complete automated GUI prototype system SERGUI),Custom templates + multiple contexts,Few-shot ,Instruction + Description,Yes,SERGUI,Yes,"Rico GUI Dataset, Screen2Words",Yes,"Feature Recommendation, Aspect-GUI matching, GUI Reranking",Small-scale pre-experiment,"Functional Suitability, Usability, Performance Efficiency",1,1,1,1,4,0,0,0,1,0,0,1,1,1,0,Proof-of-Concept,The adaptability of the system needs to be enhanced
17,LLM4Fin: Fully Automating LLM-Powered Test Case Generation for FinTech Software Acceptance Testing,"Xue, Zhiyi and Li, Liangguo and Tian, Senyue and Chen, Xiaohong and Li, Pingping and Chen, Liangyu and Jiang, Tingting and Zhang, Min",2024,ACM DL,10.1145/3650212.3680388,https://doi.org/10.1145/3650212.3680388,,llm4fin: fully automating llm-powered test case generation for fintech software acceptance testing,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,1,,FinTech,"Extract structured rules from natural language business rules
Automatically generate test scenarios and data","Mengzi-BERT-base-fin, ChatGPT GPT-4, ChatGLM, LLaMA2-7B","Yes- Perform two fine-tuning operations on Mengzi-BERT (Task 1: Rule filtering, Task 2: Element extraction)","Fine-tuning：
Learning rate: 1^e -5decay to 0 after 5-epoch warmup
Epochs: 50 (rule filtering), 20 (element extraction)","Hybrid: LLMs combined with traditional algorithms (such as SMT solvers, rule combinators)","Symbolic AI Combination
Domain-Knowledge Encoding",Few-shot & Carefully Designed Prompt,Instruction + Description + Iterative,Yes,LLM4Fin,Yes,Proprietary datasets,Yes,"Business Scenario Coverage (BSC)，
Code Coverage (SBC, MC/DC)，
Time Cost",Controlled Experiment,"Functional Suitability, Performance Efficiency, Usability",1,1,1,1,4,0,1,1,1,0,1,1,1,1,0,In Production,"Fine-tuning and terminology database construction require high labor costs
LLM relies on the representation and input of domain knowledge, and has a high learning curve
LLM has weak recognition of abstract terms, and prompts are burdensome"
18,A Comparative Analysis of ChatGPT-Generated and Human-Written Use Case Descriptions,"Aslan O\u{g}uz, Evin and Kuester, Jochen Malte",2024,ACM DL,10.1145/3652620.3687800,https://doi.org/10.1145/3652620.3687800,,a comparative analysis of chatgpt-generated and human-written use case descriptions,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Teaching,"Use case behavior modeling, user interaction modeling","ChatGPT, GPT-4",No,No,"Standalone, interactively generate use case descriptions using the ChatGPT Web API","Prompt strategy optimization, multiple rounds of prompt questions",Zero-shot + Few-shot,Instruction + Iterative,Yes,No,No,Stock Market case,No,Likert Scale Rating,User research/surveys,"Functional Suitability, Usability, Reliability",1,1,1,1,4,0,0,0,1,0,0,1,0,1,0,Teaching experiments,Too much sensitivity and reliance on prompts
19,A Comparative Study of Large Language Models for Goal Model Extraction,"Siddeshwar, Vaishali and Alwidian, Sanaa and Makrehchi, Masoud",2024,ACM DL,10.1145/3652620.3686246,https://doi.org/10.1145/3652620.3686246,,a comparative study of large language models for goal model extraction,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,,,"Multi-field coverage (Traffic Simulator, Hospital Wait Time Estimation)",Automatically extract intent elements from user stories,"GPT-4 ,Llama-13b-chat , Cohere 4.37 ",No,"GPT-4 , Llama =0.6-0.8",Standalone application: Use API to call LLM to independently generate XML goal model,Multi-step reasoning,Few-shot,Instruction + Iterative + Descriptive,Yes,Exporting a GRL XML Model,Yes,Requirements constructed from existing literature,Yes,"Syntactic Score, Semantic Completeness, Correctness, Completeness, Understandability","Experimental comparison, using ground truth model + manual analysis for verification","Functional Suitability, Usability",1,1,1,1,4,1,0,0,1,0,0,1,1,0,0,Prototype,XML output is sometimes formatted incorrectly; Weak generalization across different domains
20,Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development,"Kretzer, Felix and Kolthoff, Kristian and Bartelt, Christian and Ponzetto, Simone Paolo and Maedche, Alexander",2025,ACM DL,10.1145/3706598.3713932,https://doi.org/10.1145/3706598.3713932,,closing the loop between user stories and gui prototypes: an llm-based assistant for cross-functional integration in software development,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,,,"General fields (applicable to many fields, including travel booking apps, recipe apps, translation apps, etc.)",User story detection and generation,GPT-4o,No,temperature=0,Hybrid,Two-Stage Generation,Zero-shot + Chain-of-thought,Instruction+Descriptive,Yes,No,No,"From (Kolthoff et al., 2024) and Rico GUI datase",Yes,"User Story Completion, Component Correctness","Laboratory controlled experiment, expert interviews","Functional Suitability, Usability",1,1,1,1,4,0,0,0,1,1,1,0,0,1,0,Prototype,"Currently only functional user stories are supported, non-functional requirements are not covered"
21,Neural Language Models and Few Shot Learning for Systematic Requirements Processing in MDSE,"Bertram, Vincent and Bo\ss{}, Miriam and Kusmenko, Evgeny and Nachmann, Imke Helene and Rumpe, Bernhard and Trotta, Danilo and Wachtmeister, Louis",2022,ACM DL,10.1145/3567512.3567534,https://doi.org/10.1145/3567512.3567534,,neural language models and few shot learning for systematic requirements processing in mdse,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,,,Automotive systems,Logical expression,GPT-J-6B,No,No,Standalone,"Three levels of rules for If-Then, modal words, and expressions",Zero-Shot + Few-Shot,Instruction + Example Pairs,Yes,No,Yes,ADAS and ALS Natural Language Requirements Set,Yes,Customized six-level quality classification,"Few-Shot example number comparison experiment, manual annotation",Functional Suitability,1,1,1,1,4,0,0,0,0,1,0,1,1,1,0,Concept/Prototype,"Only supports single-sentence requirements, does not cover cross-sentence or document-level dependencies"
22,Test Case Generation for Requirements in Natural Language - An LLM Comparison Study,"Korraprolu, Brahma Reddy and Pinninti, Pavitra and Reddy, Y. Raghu",2025,ACM DL,10.1145/3717383.3717389,https://doi.org/10.1145/3717383.3717389,,test case generation for requirements in natural language - an llm comparison study,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,,1,,Embedded and control systems,"Test case generation, coverage indicator evaluation",Bard、ChatGPT-3.5、Claude、Gemini、ChatGPT-4o (Omni)、Llama3,No,No,Standalone,Zero-Shot Prompt,Zero-Shot,Instruction + Descriptive,Yes,No,Yes,25 hand-written natural language requirements (Cyclomatic Complexity 3–41),Yes,Decision Coverage、Condition Coverage、MCDC、Execution Coverage,Compare coverage and observe how LLM performance changes with demand complexity,Reliability,1,1,1,1,4,0,0,0,0,0,0,1,1,1,0,Prototype/Preliminary comparative study stage,"Correctness, completeness, and accuracy are not evaluated; only coverage is examined, not efficiency (generation time)."
23,A Human Behavior Exploration Approach Using LLMs for Cyber-Physical Systems,"Burgue\~{n}o, Lola and Keet, Maria and Kienzle, J\""{o}rg and Michael, Judith and Babur, \""{O}nder",2024,ACM DL,10.1145/3652620.3687806,https://doi.org/10.1145/3652620.3687806,,a human behavior exploration approach using llms for cyber-physical systems,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,Cyber-Physical Systems,Generation of human behavior types,GPT-4o,No,No,Standalone pipeline call,Multi-step Prompting,Zero-Shot,Instruction,Yes,SEED（Scenario Elicitation Enhanced by LLMs）,Yes,Smart Home Energy use case,Yes,"Usefulness, Outside-the-box, Duplicates, Overlap",Asynchronous offline experiment,"Functional Suitability, Usability",1,1,1,1,4,0,0,0,1,1,0,0,1,1,0,Prototype/Proof of Concept,"Only for static main scenes, does not support cross-scene dependencies, and has not yet automated the OWL → Prompt pipeline"
24,Quality assurance of generative dialog models in an evolving conversational agent used for Swedish language practice,"Borg, Markus and Bengtsson, Johan and \""{O}sterling, Harald and Hagelborn, Alexander and Gagner, Isabella and Tomaszewski, Piotr",2022,ACM DL,10.1145/3522664.3528592,https://doi.org/10.1145/3522664.3528592,,quality assurance of generative dialog models in an evolving conversational agent used for swedish language practice,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,1,1,,Educational Technology,Eliciting and organizing quality requirements for GDMs,Facebook AI’s Blenderbot pre-trained models ,Yes – domain-adapted transfer learning on interview dialogs.,No,Standalone GDM hybrid rule-based filters,"Transfer Learning(domain adaptation), Symbolic AI Combination",No,No,Yes, Emely (the Swedish practice ConvAg),Yes,Proprietary interview dialog dataset,No,"Automated Test Metrics, Validation Metrics","Controlled Experiments, Expert Validation","Functional Suitability, Reliability, Performance Efficiency, Usability",1,1,1,1,4,1,1,0,0,0,1,0,1,0,0,Prototype/pilot stage,very limited retention → frustrated users.
25,A gray box approach for Large Language Model-guided Natural Language to Temporal Logic Automatic Translation,Shukla E.; Thibeault Q.; Pedrielli G.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007301637&doi=10.1145%2f3716550.3725163&partnerID=40&md5=935cc560097830406f8df957a8517ea8,Conference paper,a gray box approach for large language model-guided natural language to temporal logic automatic translation,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Cyber-Physical Systems (CPS) Verification,NL-to-TL translation to generate an Intermediate Representation,“OpenAI Fine-Tuning API”,Yes-Use domain data for fine-tuning,No,Hybrid — Mixed with LLM via Structured Intermediate Representation (IR),"Intermediate Representation (IR) + LLM's ""Ashtack Method""",Few-shot,Instruction + Description,No,Gray-box NL-to-TL translation module,No,NL2TL ,Yes,"Syntax correctness, Logical consistency, Fidelity to specification",Controlled Experiment,"Functional Suitability, Reliability, Usability",1,1,0.5,1,3.5,0,0,0,1,0,0,0,0,0,0,Concept/Prototype,Complex language structure is still a bottleneck; Small sample set and limited experimental scale; Sensitive to tree depth and formula complexity
26,A ChatGPT-powered Prompt Engineering Framework for Generating Software Acceptance Criteria,Rawson J.; Reddivari S.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007440286&doi=10.1145%2f3696673.3723078&partnerID=40&md5=f1f41bfdcc6a129b05cd4af3d19cdb76,Conference paper,a chatgpt-powered prompt engineering framework for generating software acceptance criteria,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,1,,General-purpose software systems,Automatically generate Acceptance Criteria related requirements and code file recognition.,GPT-3、GPT-4,No,No,Hybrid,Embedded pipeline based on prompt,Few-shot + Role Assignment + Constraint-based prompting,"Instruction, Description, Iterative",Yes, Prompt Framework Pipeline,No,No,No,No,Planned: future human evaluation,"Functional Suitability, Reliability, Usability",1,1,0,1,3,0,0,0,1,1,0,1,1,1,0,Discussed Potential,Memory truncation and unable to perform outbound API calls (current GPT functionality limitation)
27,Visual analysis of LLM-based entity resolution from scientific papers,Wu S.; Yang Y.; Wu W.; Li R.; Zhang Y.; Wang G.; Tan H.; Liu Z.; Shi L.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007017763&doi=10.1016%2fj.visinf.2025.100236&partnerID=40&md5=995b2e85010d7d60fe7dedbd1a7a25a1,Article,visual analysis of llm-based entity resolution from scientific papers,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Materials science,Entity extraction tasks and multimodal verification tasks,"GPT-4, GPT-3.5",No,temperature=0,RAG: Select representative paragraphs as examples through discriminant models,"Prompt Engineering; Few-shot sample driven
and Structured output control",Few-shot learning and structured prompting,"Instruction, JSON format",Yes,No,No,Self-built labeling set,No,"Precision, Recall, F1, Accuracy",Case Study + Quantitative Metrics,"Functional Suitability, Reliability, Usability",1,1,1,1,4,0,0,0,1,1,0,1,1,1,0,Prototype,Multi-RAG configuration cannot be compared at the same time; and the data volume is small
28,Exploring Large Language Models’ Ability to Describe Entity-Relationship Schema-Based Conceptual Data Models,Avignone A.; Tierno A.; Fiori A.; Chiusano S.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006565084&doi=10.3390%2finfo16050368&partnerID=40&md5=ccdec45949e154c2fa59ff5d353adce6,Article,exploring large language models’ ability to describe entity-relationship schema-based conceptual data models,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,Generic, User Story Elicitation,GPT-3.5,No,temperature=0.2,Standalone,No,Few-shot,Instruction + Role-playing,Yes, ChatGPT API,Yes,No,No,Qualitative analysis and quantitative indicators,Controlled Experiment,Functional Suitability,1,1,1,0.5,3.5,0,1,0,1,0,0,1,1,1,0,Exploration phase,Prompt design and user interaction have a great impact on quality (non-standardized)
29,Generative language models potential for requirement engineering applications: insights into current strengths and limitations,Saleem S.; Asim M.N.; Elst L.V.; Dengel A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004442965&doi=10.1007%2fs40747-024-01707-6&partnerID=40&md5=2fa68c7a3a20335a71d4ba7d1ffe11dc,Article,generative language models potential for requirement engineering applications: insights into current strengths and limitations,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,"Aerospace (for NER), Defense & Security (QA), General Software Systems","Named Entity Recognition (SYS, VAL, ORG, DATETIME, RES)","ChatGPT-3.5, Gemini",No,No,Standalone prompts,Pure prompt-response model,Few-shot,Instruction,Yes,No,No,"PURE, PROMISE, Aerospace NER, REQuestA",Yes,"Accuracy, F1, Precision, Recall for extraction/classification/NER. ROUGE, BLEU, METEOR for QA","Benchmark-based evaluation. Five-run average (NER), manual + automated scoring (QA).","Functional Suitability, Performance Efficiency, Reliability",1,1,1,1,4,1,0,0,1,0,0,1,1,1,0,Conceptual Evaluation,GLMs not optimal for NER without heavy prompt tuning.
30,GUing: A Mobile GUI Search Engine using a Vision-Language Model,Wei J.; Courbis A.-L.; Lambolais T.; Xu B.; Bernard P.L.; Dray G.; Maalej W.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005206519&doi=10.1145%2f3702993&partnerID=40&md5=d5bacb83be83d8a093ff028df4af93df,Article,guing: a mobile gui search engine using a vision-language model,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,1,,, General ,Text-to-GUI retrieval for early prototyping,CLIP (openai/clip-vit-base-patch32),"Yes — Fine-tuned on GUI-specific data (SCapRepo, Screen2Words, Clarity)","Training: 5 epochs, batch size 128, learning rate 5e−5",Standalone system (GUing search engine) built on GUIClip,Contrastive learning with CLIP-style loss,Zero-shot,Instructional/Descriptive,Yes,GUing,Yes,"SCapRepo (135k image-caption pairs)
ScreenRepo (303k images)
Also uses: Clarity, Screen2Words, Enrico, Swire",Yes,"Precision, Recall, F1
",Domain experts,"Functional Suitability, Reliability, Performance Efficiency, Usability, Maintainability, Portability",1,1,1,1,4,1,0,0,1,1,1,0,1,0,1,Conceptual / Prototype,Human Evaluation Bias and query selection bias
31,Collaboration with Generative AI to improve Requirements Change,Kong Y.; Zhang N.; Duan Z.; Yu B.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003992421&doi=10.1016%2fj.csi.2025.104013&partnerID=40&md5=c16461112c4cd9a3e5e381d1eb4dad66,Article,collaboration with generative ai to improve requirements change,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,,,1,Software development systems,Requirements Change (RC) management,ChatGPT-3.5,No,No,Hibrid-Incorporates Requirements Traceability Matrix (RTM) and Generative Requirements Structure Model (GRSM),Multi-agent role prompting,"Few-shot, CoT",Instructional and iterative,Yes,SRC (Satisfy Requirements Change),No,No,No,"Efficiency improvement, Pass/fail verification, Manual and formal verification",Controlled case studies+Human evaluation,"Functional suitability, Reliability, Performance efficiency, Usability, Security",1,1,1,1,4,0,0,1,1,1,0,0,1,1,0,Case studies,Modeling dependency
32,An empirical study on LLM-based classification of requirements-related provisions in food-safety regulations,Hassani S.; Sabetzadeh M.; Amyot D.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218632450&doi=10.1007%2fs10664-025-10619-z&partnerID=40&md5=fb9cc044506c4fa76c0e46df090a0ec2,Article,an empirical study on llm-based classification of requirements-related provisions in food-safety regulations,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,, Food safety,Sentence-level classification of legal text into RE-relevant categories,"GPT-3.5-turbo, GPT-4o,  LLaMA-3-8B-Instruct, Mixtral-8x7B-Instruct-v0.1",Yes – GPT-3.5 and GPT-4o are fine-tuned using a conversational setup.,temperature=0.2,Standalone classification pipeline with sentence-level input,"Few-shot learning, fine-tuning, and manual keyword backoff",Few-shot,Instructional + Examples,Yes,No,Yes,"Training: Canadian SFCR & FSRG regulations
Test set includes additional FSRG and US FDA regulations",Yes,"Precision, Recall, F1",Controlled experiment,"Functional suitability, Performance efficiency, Usability",1,1,1,1,4,1,0,0,1,1,1,0,1,1,1,Concept/prototype,"Caution against fine-tuning overfitting, domain generalizability"
33,User needs insights from UGC based on large language model,Wei W.; Hao C.; Wang Z.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001055948&doi=10.1016%2fj.aei.2025.103268&partnerID=40&md5=44afd12ea80f44125c42a1c433549270,Article,user needs insights from ugc based on large language model,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,"Smart wearable bands (consumer electronics, e-commerce)",Extraction and prioritization of product attributes; sentiment analysis and mapping to IPA-Kano model,LLaMA2-Chinese-7B,No,No,Standalone,MLP,Zero-shot,Instruction + Example,Yes,No,No,"proprietary dataset (JD.com, Xiaomi, Huawei community UGC)",Yes (on request),"controlled experiment (MLP classification on labeled sentiment data, comparison with baselines)",,Performance efficiency,1,1,1,1,4,0,0,0,0,1,0,0,0,0,0,"concept/prototype, discussed potential",Model struggles with neutral sentiment classification; computational cost of LLMs; limited by data deviation; no fine-tuning
34,Research on Hybrid Collaborative Development Model Based on Multi-Dimensional Behavioral Information,Gao S.; Liao W.; Shu T.; Zhao Z.; Wang Y.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004796181&doi=10.3390%2fapp15094907&partnerID=40&md5=c66ade03198bba5c9aaae1e3416b63d4,Article,research on hybrid collaborative development model based on multi-dimensional behavioral information,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,1,"General software engineering (cross-domain, not limited to a specific industry)","Requirements semantic parsing, code generation, test optimization, project deployment/orchestration, cross-stage collaboration, expert routing","Deepseek v3-32B, CodeGeeX4-all-9B",Yes,No,Hybrid,,Few-shot,Instruction + Descriptive + Chain-of-thought + Role-based,Yes,HCDMB (Hybrid Collaborative Development Model based on Multi-Dimensional Behavioral Information),No,No,No,"expert activation accuracy (F1), variance of weight assignment (ANOVA), user adoption rate, system response latency",system implementation with quantitative evaluation (no controlled user study),"Functional Suitability, Reliability, Usability, Performance efficiency",1,1,1,1,4,0,0,1,1,1,1,1,0,0,0,"concept/prototype, barriers highlighted","Limited expert model coverage,  generalization in vertical domains, tradeoff between scalability and task-decoupling, computation cost vs. real-time, no public dataset or open-source code"
35,HGNNLink: recovering requirements-code traceability links with text and dependency-aware heterogeneous graph neural networks,Wang B.; Zou Z.; Liang X.; Jin H.; Liang P.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006909628&doi=10.1007%2fs10515-025-00528-2&partnerID=40&md5=1ddbc82115af34f5522405d8b843d4b6,Article,hgnnlink: recovering requirements-code traceability links with text and dependency-aware heterogeneous graph neural networks,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,,1,1,General domain,Requirements-to-code traceability link recovery (RC-TLR),"GraphCodeBERT (for code artifacts), general-purpose pre-trained models (Word2Vec, BERT, RoBERTa, ALBERT, XLNet) for requirements artifacts",No,No,Hybrid,,"feature-based, message-passing, graph neural network aggregation",N/A,No,HGNNLink, Yes,"Ten open-source software projects (iTrust, Derby, Drools, Maven, Pig, Seam2, Infinispan, smos, Groovy, Dronology)",Yes,"precision, recall, F1-score",controlled experiment (empirical study with repeated runs and statistical significance testing),Performance efficiency,1,1,1,1,4,0,0,0,0,0,0,0,1,0,0,concept/prototype,"Limited to Java code artifacts; performance depends on artifact scale and quality; cannot analyze non-Java dependencies (e.g., JSP); requires high-quality, sufficiently large datasets"
36,Overcoming Data Shortage in Critical Domains With Data Augmentation for Natural Language Software Requirements,Korfmann R.; Beyersdorffer P.; Gerlich R.; Münch J.; Kuhrmann M.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005212822&doi=10.1002%2fsmr.70027&partnerID=40&md5=ff501a63796536da75d85603092d1b9e,Article,overcoming data shortage in critical domains with data augmentation for natural language software requirements,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,,"Aerospace (critical domains, European space projects)",Data augmentation of software requirements for AI-based quality assurance; generation of synthetic requirements; semantic similarity detection; ambiguity detection,"GPT-2 (for generative augmentation); T5 (for PARA paraphrasing); BERT (for classifier, not as GenAI)",Yes,No,Standalone,Data Augmentation,few-shot (for GPT-2 generation); instruction-based for PARA and RTT; manual annotation for classifier,"Instruction (sentence completion, paraphrasing, translation)",No,No,No, ESSR (European Space Software Repository),No,"Precision, Recall, Specificity, F1-score, Training loss, Validation loss, Accuracy (for classifier)",Controlled experiment; single-blind manual evaluation; 10-fold cross-validation for classifier,"Performance efficiency, Reliability",1,1,1,1,4,1,0,1,0,1,0,1,1,1,0,"concept/prototype; barriers highlighted (data scarcity, domain adaptation)",Generalizability to other domains not established; quality of input requirements directly affects output; duplicates in augmentation; manual annotation required
37,Elicitron: A Large Language Model Agent-Based Simulation Framework for Design Requirements Elicitation,Ataei M.; Cheong H.; Grandi D.; Wang Y.; Morris N.; Tessier A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001098804&doi=10.1115%2f1.4067388&partnerID=40&md5=fdb2a897825b4bd016f5dfce02026c3c,Article,elicitron: a large language model agent-based simulation framework for design requirements elicitation,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,"Product design, specifically tent design (generalizable to other product domains)",Automated and augmented requirements elicitation using LLM agents to simulate diverse user interviews,GPT-4-Turbo,No,No,Standalone (agent-based simulation framework),,"few-shot, chain-of-thought, role-based","Instruction + Descriptive + Iterative (role, scenario, interview, chain-of-thought)",Yes,Elicitron,No,"Proprietary dataset (tent design scenario, agent responses, interview data)",No," mean distance to centroid, silhouette score, F1-score (interrater agreement), precision, recall, human qualitative analysis","Controlled experiment (three experiments: agent diversity, latent needs generation, latent needs detection)",,1,1,1,1,4,1,0,0,1,1,0,0,0,0,0,concept/prototype,"LLM bias, dependence on training data, risk of generic outputs"
38,COTR: Efficient Job Task Recognition for Occupational Information Systems with Class-incremental Learning,Qin C.; Fang C.; Yao K.; Chen X.; Zhuang F.; Zhu H.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005642562&doi=10.1145%2f3712306&partnerID=40&md5=250927e6b87400990bd68f2e78b9572a,Article,cotr: efficient job task recognition for occupational information systems with class-incremental learning,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,1,Occupational Information Systems,Occupation-specific job task (OST) recognition and incremental OST recognition from job descriptions,"ChatGPT (GPT-3.5/4), Nanbeige-16B, Llama2-13B, Baichuan2-13B",Yes,No,Hybrid,out-of-distribution (OOD) detection module,"few-shot, supervised fine-tuning (LoRA)",Instruction + Descriptive + Classification + Iterative,Yes,COTR,No,"Job-CN, Job-US, CLINC-FULL, BANKING","partial (Job-CN, Job-US proprietary; CLINC-FULL, BANKING public)","accuracy, F1-score, Forgetting Rate (FR), human evaluation","controlled experiment, case study, human expert study","Functional suitability, Performance efficiency, Usability",1,1,1,1,4,0,0,0,0,1,0,0,0,0,0,concept/prototype,"Annotation cost, instability of LLM API, limited open-source LLM performance"
39,Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool,Akhmetov I.; Prpa M.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000236520&doi=10.1145%2f3641555.3705250&partnerID=40&md5=673d5629c240bcd218aef1390d8e79c7,Conference paper,simulating requirement elicitation: development and evaluation of a persona-based tool,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,Software engineering education (Database Management Systems course),Simulated requirements elicitation interviews with LLM-driven personas for conceptual modeling and ER diagram creation,gpt-4o-mini,No,No,Standalone,,role-based,Instruction + Descriptive + Classification + Iterative,No,Requirement Elicitation Tool,Yes,No,No,"number of student interactions, quality of ER diagrams (subjective)",classroom deployment (case study),Usability,1,0.5,0.5,1,3,0,0,0,0,1,0,0,0,0,0,concept/prototype,No direct user feedback yet
40,Mining App Reviews for User Feedback Analysis in Requirements Engineering: A Project Report,Motger Q.; Oriol M.; Tiessler M.; Franch X.; Marco J.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006486626&partnerID=40&md5=0bcc30073d212abe22063e4b1751b7a9,Conference paper,mining app reviews for user feedback analysis in requirements engineering: a project report,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,Mobile app review mining ,"Feature extraction, competition analysis, emotion extraction from app reviews","GPT-4o, DeepSeek, Mistral, encoder-only LLMs (BERT, RoBERTa, XLNet)",Yes,No,"Standalone, retrieval-augmented, agent (multi-agent framework in related projects)",supervised and unsupervised learning,few-shot,"Instruction + Descriptive, guidelines/examples for few-shot",No,"AppReviewCollector, TransFeatEx, T-FREX, RE-Miner",Yes,"MApp-KG, Features from crowdsourced repositories, Emotions from manual annotation",Yes,"inter-rater agreement (emotion annotation), accuracy (planned for extraction methods)","Replication studies, annotation agreement analysis, planned controlled experiments","Functional suitability, Performance efficiency, Usability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,concept/prototype,"Sentiment ambiguity, data imbalance"
41,Implementation of Sensor Input Setup Assistance Service Using Generative AI for SEMAR IoT Application Server Platform,Kotama I.N.D.; Funabiki N.; Panduman Y.Y.F.; Brata K.C.; Pradhana A.A.S.; Noprianto; Desnanjaya I.G.M.N.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218455427&doi=10.3390%2finfo16020108&partnerID=40&md5=f2b49e2cf86294ca96f8a9937e695d02,Article,implementation of sensor input setup assistance service using generative ai for semar iot application server platform,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,1,,IoT application server platform (SEMAR),"Sensor input setup assistance for IoT device integration, including hardware selection, connectivity, protocol configuration, troubleshooting, and guided step-by-step setup",ChatGPT-4o,No,No,retrieval-augmented, SEMAR,"few-shot, one-shot, role-based",Instruction + Descriptive + Iterative (conversational Q&A),Yes,SEMAR sensor input setup assistance service,Yes,No,No,"System Usability Scale (SUS), user study completion rate, qualitative feedback","case study, user study (course assignment)","Functional Suitability, Reliability, Usability, Performance efficiency",1,1,1,1,4,0,0,0,0,0,0,1,0,0,0,"concept/prototype, pilot project","Lack of message editing, limited support for new hardware, occasional LLM hallucinations"
42,Requirement-service mapping technology in the industrial application field based on large language models: Requirement-service mapping technology in the industrial application field..: L. Ruixiang et al.,Ruixiang L.; Qiujun D.; Xianhui L.; Chenglin Z.; Weidong Z.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211107006&doi=10.1007%2fs10489-024-05969-y&partnerID=40&md5=15b1857a90181586c1fa8fc255f5599c,Article,requirement-service mapping technology in the industrial application field based on large language models: requirement-service mapping technology in the industrial application field..: l. ruixiang et al.,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,"industrial application services (cloud manufacturing, microservices, service mapping)",Requirement-service mapping,GPT-3.5/4,No,No,Hybird,Service selection,"chain-of-thought, zero-shot/few-shot",Instruction + Descriptive + Example-based,Yes,Service Template Generation System,No,Artifact Hub,No,"Match Rate (MR), False Match Rate (FMR)",case study,"Functional Suitability, Reliability",1,1,1,0.5,3.5,0,0,0,0,1,0,1,0,1,0,concept/prototype,"Proprietary dataset, not open-source; LLM hallucination and cost of fine-tuning discussed; no human/industrial evaluation"
43,Synthetic users: insights from designers' interactions with persona-based chatbots,Gu E.H.; Chandrasegaran S.; Lloyd P.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216548039&doi=10.1017%2fS0890060424000283&partnerID=40&md5=065b52986e17b5971be610da980b2ea1,Article,synthetic users: insights from designers' interactions with persona-based chatbots,New,FALSE,FALSE,Analyze now,,,Yes,F,1,1,,,,"Design (industrial/product design), general domain",Designer interaction with persona-based chatbots (Synthetic Users) for user insight gathering and ideation,GPT-3 (text-davinci-003),No,No,Standalone,,,Instruction + Descriptive + Example-based,yes,Synthetic User web app,no,no,no,"Persona Perception Scale (PPS), NASA TLX usability survey, LIWC linguistic analysis, Idea count, Topic diversity (BERTopic)",Between-subjects user study with qualitative and quantitative analysis,"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,1,0,1,0,0,0,1,0,0,0,concept/prototype,"Small sample size, only one persona used, limited generalizability, need for improved evaluation methods for Synthetic Users"
44,RECOVER: Toward Requirements Generation from Stakeholders’ Conversations,Voria G.; Casillo F.; Gravino C.; Catolino G.; Palomba F.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005800526&doi=10.1109%2fTSE.2025.3572056&partnerID=40&md5=4e4adf89ce9138ee0ee5cbd2282efd0b,Article,recover: toward requirements generation from stakeholders’ conversations,New,FALSE,FALSE,Analyze now,,,Yes,F,1,,,,,General domain,Extraction and generation of system requirements from conversations,LLaMA 2 (7B parameter version),No,No,Hybrid,boilerplate format,Few-shot,Instruction,Yes,RECOVER,Yes,"PURE, RECONSUM, dataset from Rodeghero et al.",Partial,"Precision, Recall, BLEU, ROUGE, METEOR
Correctness, Completeness, Actionability (Likert scale)",Controlled experiment,"Functional suitability, Reliability, Usability",1,1,1,1,4,0,0,0,0,1,0,1,1,1,0,prototype,Traceability and conflict resolution are open problems
45,Deep Generative Model for Mechanical System Configuration Design,Etesam Y.; Cheong H.; Ataei M.; Jayaraman P.K.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003973131&doi=10.1609%2faaai.v39i16.33812&partnerID=40&md5=1d91abcc4289a1c3491ee7849d795a6f,Conference paper,deep generative model for mechanical system configuration design,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,1,,"Mechanical engineering, specifically mechanical system configuration design (gear train synthesis)",Automatic generation of mechanical system configurations (gear trains),Transformer-based,Yes,No,Standalone and hybrid (with EDA and MCTS),"Hybrid with search methods (EDA, MCTS), autoregressive generation, Gumbel-Softmax for differentiable sampling",NO,No,No,GearFormer,Yes,"GearFåormer dataset (synthetic, for gear train synthesis)",Yes,"Validity, Feasibility, Output position match (Euclidean distance), Speed ratio match (RMSLE), Output motion vector match, Input/output motion type match, Weight",Controlled experiment (benchmarking against baselines and hybrid methods),"functional_suitability, performance_efficiency, usability",1,1,1,1,4,0,0,0,0,1,1,0,1,0,0,concept/prototype,Dataset is synthetic; real-world generalization not tested. Limited to gear train synthesis; extension to other domains suggested as future work.
46,Sim911: Towards Effective and Equitable 9-1-1 Dispatcher Training with an LLM-Enabled Simulation,Chen Z.; Chason E.; Mladenovski N.; Wilson E.; Mullen K.; Martini S.; Ma M.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003907390&doi=10.1609%2faaai.v39i27.35006&partnerID=40&md5=d69909c84ac65a76a16cc44e00d50b8d,Conference paper,sim911: towards effective and equitable 9-1-1 dispatcher training with an llm-enabled simulation,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,,1,1,emergency response (9-1-1 dispatcher training),"simulation of 9-1-1 calls for dispatcher training, focusing on realism, equity, and inclusiveness",GPT-4o,No,No,hybrid,"retrieval-augmented generation, chain-of-thought, few-shot prompting, in-context validation, co-pilot design","zero-shot, few-shot, chain-of-thought",Instruction + Descriptive + Iterative,no,Sim911,yes,MNDEC 9-1-1 call dataset (proprietary),no,"Perplexity (PPL), METEOR, Type-Token Ratio (TTR), Google Maps API locating success rate (GMap), Simulation Alignment Rate (SAR), BART Score, Margin Score, NRCLex, Gunning Fog Index, human evaluation (scaled ratings, written feedback)","controlled experiment, real-world deployment, user study","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,1,1,1,0,0,0,1,0,0,0,pilot (real-world deployment in Metro Nashville Department of Emergency Communications),"limited to one metro area, dataset not public, interpretability and reproducibility not addressed
"
47,Evaluating the Capabilities of LLMs in Traceability Maintenance for Automotive System and Software Requirements,Hippargi V.; Kamsties E.; Naumann J.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006634399&partnerID=40&md5=624bd0dfaabdecd50531b401ed0d63ca,Conference paper,evaluating the capabilities of llms in traceability maintenance for automotive system and software requirements,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,1,Automotive (firmware for Ultrasonic Park Assist IC),"Trace link quality assessment, trace link prediction, anomaly detection, inconsistency detection between requirements and test cases",ChatGPT-4o,No,No,Standalone,"zero-shot, prompt-based, iterative refinement",zero-shot,Instruction + Descriptive,yes,no,no,"CaseStudyonChatGPTforRE (proprietary, anonymized, available on GitHub)",yes,"Precision, Recall, F1-score, Expert ranking, Survey (qualitative)","Controlled experiment, expert study, survey","functional_suitability, usability",1,1,1,1,4,0,0,0,0,0,0,0,1,0,0,"concept/prototype, discussed potential, barriers highlighted","Small, low-complexity dataset; tool-specific results; prompt engineering limitations; human expert variability"
48,Trust at Your Own Peril: A Mixed Methods Exploration of the Ability of Large Language Models to Generate Expert-Like Systems Engineering Artifacts and a Characterization of Failure Modes,Topcu T.G.; Husain M.; Ofsa M.; Wach P.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218709286&doi=10.1002%2fsys.21810&partnerID=40&md5=09aa13722c3c81935fdb6b66cbf43206,Article,trust at your own peril: a mixed methods exploration of the ability of large language models to generate expert-like systems engineering artifacts and a characterization of failure modes,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,,,"Systems engineering for defense (unmanned ground vehicle, military context)","Generation of expert-like systems engineering artifacts (e.g., Capability Description Document segments, requirements, KPPs, KSAs) using LLMs; comparison to human expert artifacts; identification of LLM failure modes","GPT-4, GPT-3.5 Turbo, Claude",No,No,Standalone,"Iterative prompt engineering, prompt specificity refinement","Zero-shot, iterative prompting","Instructional, descriptive, iterative",yes,no,no,Bulldog Unmanned Ground Vehicle (UGV) dataset,no,"MAUVE (semantic similarity metric), qualitative human expert analysis","Mixed-methods: quantitative NLP similarity analysis, qualitative expert coding and comparison","functional_suitability, usability",1,1,1,1,4,0,0,1,0,0,0,1,1,0,0,"concept/prototype, barriers highlighted",Limited to one benchmark dataset; LLMs not fine-tuned; non-determinism of LLMs not explored; qualitative coding not blinded; closed-source models only; dataset not public
49,Automatic instantiation of assurance cases from patterns using large language models,Odu O.; Belle A.B.; Wang S.; Kpodjedo S.; Lethbridge T.C.; Hemmati H.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216448475&doi=10.1016%2fj.jss.2025.112353&partnerID=40&md5=c5352c59fb30067a071b81cf70503df4,Article,automatic instantiation of assurance cases from patterns using large language models,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,1,,"General domain (applied to aviation, automotive, medical, and computing systems)","Automatic instantiation of assurance cases from formalized patterns using LLMs; focuses on non-functional requirements (e.g., safety, security, reliability) assurance case generation","GPT-4o, GPT-4 Turbo",No,No,Standalone,,,Instruction + Descriptive + Example (for one-shot),yes,SmartGSN,yes,"Custom dataset (6 assurance case patterns, 5 assurance cases, multi-domain)",yes,"Exact match, BLEU score, Semantic similarity (cosine), Human reasonability rating","Controlled experiment, manual expert assessment","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,"concept/prototype (SmartGSN tool, not in production)","Ambiguity in pattern cardinality, need for human expert refinement, dataset size and coverage, potential overlap with LLM training data"
50,Implementing Generative AI Into ERP Software,Sarferaz S.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003671586&doi=10.1109%2fACCESS.2025.3564133&partnerID=40&md5=edc8c0279369df94c184c91e21412046,Article,implementing generative ai into erp software,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,1,1,"Enterprise Resource Planning (ERP) software across multiple business domains (finance, HR, supply chain, etc.)","Content generation, question-answering, conversation agents, text summarization, translation, sentiment analysis, text classification, code generation, data augmentation, information extraction, personalization, creative applications","OpenAI GPT series (e.g., GPT-3, GPT-4) and other vendor LLMs (not specified by version)",no,No,"Hybrid (ERP system with AI Technology Platform, retrieval-augmented, prompt engineering, orchestration)",,,"Instruction + Descriptive (prompt templates with placeholders, instructions, and context)",yes,"SAP Generative AI Framework (Intelligent Scenario, Prompt Executor, Orchestration Service)",no,no,no,"Customer feedback (efficiency, cost reduction, time-to-market), Operational adoption (number of customers, daily usage)","Case study, real-world deployment, customer feedback","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,1,1,1,0,1,1,1,0,1,0,"production (SAP ERP product, 10,000+ customers)",No public datasets or open-source tools; interpretability and reproducibility not explicitly addressed.
51,Gensors: Authoring Personalized Visual Sensors with Multimodal Foundation Models and Reasoning,Liu M.X.; Petridis S.; Tsai V.; Fiannaca A.J.; Olwal A.; Terry M.; Cai C.J.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001920147&doi=10.1145%2f3708359.3712085&partnerID=40&md5=3cfd3f5106e3c1dec525465ee8a093ad,Conference paper,gensors: authoring personalized visual sensors with multimodal foundation models and reasoning,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,1,1,,General domain (personalized visual sensors for smart home and personal environments),"Authoring, debugging, and refining personalized visual sensor requirements using multimodal LLMs; criteria elicitation, criteria-based reasoning, sensor configuration, and stress-testing.",Gemini 1.5 Flash and Gemini 1.5 Pro,No,No,Hybrid,,,Instruction + Descriptive + Example-based,no,Gensors,no,no,no,"User self-reported control (Likert scale), Understanding of model capabilities (Likert scale), Ability to communicate requirements (Likert scale), Ability to test and probe sensor (Likert scale), Feature helpfulness (Likert scale)","User study (within-subjects, n=12, compared to baseline prompt-editor)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,1,1,1,1,1,0,1,0,concept/prototype,"Small, tech-savvy participant sample; limited use cases; generalizability concerns; hallucinations and stochasticity of MLLMs; privacy risks with cloud-based models; limited on-device support."
52,Design Knowledge as Attention Emphasizer in Large Language Model-Based Sentiment Analysis,Han Y.; Moghaddam M.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001426237&doi=10.1115%2f1.4067212&partnerID=40&md5=a11f6ea961a2e843e910eec85ffa0be8,Article,design knowledge as attention emphasizer in large language model-based sentiment analysis,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,1,,,,"Product design, specifically athletic footwear (apparel and footwear e-commerce reviews)","Aspect, category, opinion, sentiment, and implicit indicator (ACOSI) extraction from user reviews for implicit knowledge completion",T5 (Text-to-Text Transfer Transformer),Yes,No,Standalone,fine-tuned transformer with design-knowledge-guided position encoding,"few-shot (custom dataset, annotated examples)",Instruction + special tokens for label types,no,DKG-T5,no,Shoes-ACOSI (annotated dataset for ACOSI task in product design),no,"ROUGE1, ROUGE2, ROUGEL, DKG-ROUGE (domain knowledge ROUGE), design-bag-of-words (DBW), Cohen鈥檚 Kappa (annotation agreement)","controlled experiment (model comparison, statistical testing)","functional_suitability, performance_efficiency",1,1,1,1,4,1,0,0,0,1,1,0,0,0,0,"concept/prototype, barriers highlighted","Transferability to other domains, scalability, subjectivity in implicit knowledge, lexicon dependency, label order in autoregressive models"
53,Choosing a Creativity Technique for Requirements Elicitation: an updated framework,Mich L.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006523553&partnerID=40&md5=1ef54b18005d392263309a8b0d3d4997,Conference paper,choosing a creativity technique for requirements elicitation: an updated framework,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,1,,,,,"General domain; focuses on requirements elicitation across various domains using creativity techniques, including GenAI/LLMs.","Selection and application of creativity techniques for requirements elicitation, considering the integration of LLM GenAI systems.",N/A,No,No,"Standalone (conceptual framework, not a specific tool)",N/A,N/A,N/A,No,No,No,No,No,,N/A,,1,0.5,0.5,1,3,0,1,0,1,0,0,1,0,0,1,"Barriers highlighted, conceptual framework only",No empirical evaluation; conceptual and preliminary; no tool or dataset provided.
54,Automated Identification and Representation of System Requirements Based on Large Language Models and Knowledge Graphs,Wang L.; Wang M.-C.; Zhang Y.-R.; Ma J.; Shao H.-Y.; Chang Z.-X.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002283101&doi=10.3390%2fapp15073502&partnerID=40&md5=be47df56f82c0f85c2b31b1a47723dba,Article,automated identification and representation of system requirements based on large language models and knowledge graphs,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,1,metro/railway system engineering (Code for Design of Metro),Automated extraction and structured representation of system requirements from requirement documents using LLMs and knowledge graphs,GPT-4,No,No,hybrid,"retrieval-augmented, prompt engineering, template-based extraction, few-shot learning, post-processing validation",few-shot,Instruction + Descriptive + Example (few-shot),yes,no,no,Metro_Code_Chapters_18_to_22_Data (HuggingFace),yes,"accuracy (custom weighted, combining exact match and cosine similarity)","case study, comparative experiment with baselines (BERT, RoBERTa, GPT-3.5-turbo)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,1,0,0,1,1,0,0,"prototype, concept, barriers highlighted",LLM struggles with hierarchical dependencies and entity disambiguation; hallucinations and format inconsistencies; not all node relationships are uniformly implemented; domain-specific fine-tuning and advanced prompt strategies suggested for future work
55,Enhancing Conversational Agent Development Through a Semi-Automatization Development Proposal,Martínez-Gárate Á.; Aguilar-Calderón J.A.; Tripp-Barba C.; Zaldívar-Colado A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217572386&doi=10.3390%2fapp15031139&partnerID=40&md5=c792bafea1b3fa2c2c6b706f9b382ffd,Article,enhancing conversational agent development through a semi-automatization development proposal,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,1,,"Higher education (university postgraduate program information chatbot, WhatsApp deployment)","Semi-automated chatbot development for information query answering, fallback suggestion generation using LLM, WhatsApp integration",GPT-3 (text-curie-001),No,No,Hybrid,"Fallback to LLM for unhandled queries, prompt engineering, model-to-text code generation",Few-shot,Instruction + Example-based,yes,PCIBot (Xatkit enhancement),no,"User interaction logs, satisfaction survey (PCIBot)",yes,"User satisfaction rate, Feature usage statistics","Case study, user survey (n=100)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,1,0,1,1,0,0,"concept/prototype, pilot project, barriers highlighted",Manual code intervention still required for advanced features; limited to WhatsApp via Twilio; no direct WhatsApp Business API integration
56,Refactoring goal-oriented models: a linguistic improvement using large language models,Alturayeif N.; Hassine J.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217364855&doi=10.1007%2fs10270-024-01254-1&partnerID=40&md5=d74294c74f929c3217579c7eb76bf2ee,Article,refactoring goal-oriented models: a linguistic improvement using large language models,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,1,"Goal-oriented requirements engineering (GORE), general domain, with examples in electric vehicles, healthcare, university alumni, and AI-powered mental health systems","Detection and automated refactoring of linguistic bad smells in goal-oriented requirements models (GRL/TGRL), including tasks like identifying unclear/ambiguous goal statements, conflicting requirements, misspellings, and syntactic/semantic issues",GPT-3.5-turbo,No,No,Standalone,,,Instruction + Descriptive + Example-based,yes,TGRL Bad Smells Detection and Refactoring Tool,yes,"Four GRL/TGRL models (University Alumni, Healthcare, Electric Vehicle, AI-Powered Mental Health Companion)",yes,"precision, recall, F1-score, F2-score, human evaluation (Likert scale)","Case study, user study (questionnaire with 13 participants)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,0,0,0,0,"concept/prototype, barriers highlighted, future work includes industrial models","Limited to TGRL/GRL models, evaluation on four models, subjective refactoring for some bad smells, dependency on GPT, not all linguistic anomalies covered, external validity concerns"
57,Enhancing Agile Requirements Change Management: Integrating LLMs with Fuzzy Best-Worst Method for Decision Support,Aljohani B.; Aljuhani A.; Alsanoosy T.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001551303&doi=10.14569%2fIJACSA.2025.01603103&partnerID=40&md5=267ed1ffd4d06162c2474201db73157e,Article,enhancing agile requirements change management: integrating llms with fuzzy best-worst method for decision support,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,1,Agile Requirements Change Management (ARCM) in Global Software Development (GSD),Prioritization of success factors for ARCM using LLM-driven Fuzzy Best-Worst Method (FBWM),GPT-4,No,No,hybrid,,,Instruction + Descriptive,yes,no,no,no,no,"Consistency Ratio (CR), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Spearman鈥檚 Rank Correlation (蟻), Kendall鈥檚 Tau Correlation (蟿)",Controlled experiment (comparison of human and LLM expert rankings),"functional_suitability, reliability, performance_efficiency",1,1,1,1,4,1,0,0,1,1,0,0,0,0,0,concept/prototype,Scalability to larger datasets and resource constraints (computational tools) are mentioned as limitations.
58,DesignQA: A Multimodal Benchmark for Evaluating Large Language Models’ Understanding of Engineering Documentation,Doris A.C.; Grandi D.; Tomich R.; Alam M.F.; Ataei M.; Cheong H.; Ahmed F.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001121788&doi=10.1115%2f1.4067333&partnerID=40&md5=421264076326700d156e79c53252ac8e,Article,designqa: a multimodal benchmark for evaluating large language models’ understanding of engineering documentation,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,1,,"engineering design (Formula SAE automotive student competition, generalizable to technical engineering documentation)","Rule extraction, rule comprehension (component identification, presence), rule compliance (dimension and functional performance checking) from technical requirements and multimodal data","GPT-4o, GPT-4, Claude-Opus, Gemini-1.0, LLaVA-1.5",No,No,Standalone and retrieval-augmented generation (RAG),zero-shot,zero-shot,Instruction + Descriptive (detailed task-specific prompts for each subtask),yes,DesignQA,yes,DesignQA,yes,"F1-score (BoW, rules, characters), accuracy, BLEU, ROUGE, Sentence-BERT similarity",benchmarking (controlled experiment with multiple models and baselines),"functional_suitability, performance_efficiency, usability, reliability",1,1,1,1,4,0,0,0,1,1,0,1,1,0,0,"concept/prototype, open benchmark for future research",Limited to one rule document; generalizability to other documents not tested; some subsets small due to manual QA creation; automatic metrics may not always match human judgment.
59,Applying Large Language Model Analysis and Backend Web Services in Regulatory Technologies for Continuous Compliance Checks,Li J.; Maiti A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001376735&doi=10.3390%2ffi17030100&partnerID=40&md5=4ca89a8da88c6f4a871ce30076e9740c,Article,applying large language model analysis and backend web services in regulatory technologies for continuous compliance checks,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,1,1,"Agriculture (RegTech for compliance in primary industries, with case studies in cherry orchards and honeybee apiaries)","Continuous compliance checks, list extraction, numeric/milestone/binary analysis, rule identification, document and process checks, format checking","Ollama (Llama 3.2, Llama 3.1), Copilot, ChatGPT (GPT-4o), Gemini 2.0, Claude 3",No,No,Hybrid (LLM with backend web services/tool-calling),,,Instruction,yes,no,no,"Australian Cherry Guidelines, time series weather station data, honeybee compliance forms",no,"Extraction accuracy (位), Execution time (seconds), List order variation, Average item displacement",Controlled experiment (LLM performance on compliance tasks using real-world datasets and forms),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,1,1,1,1,1,1,1,0,"concept/prototype, barriers highlighted","LLMs are inconsistent for complex analytical tasks, require backend web services for reliability, and have limited ability to explain outputs in human-friendly terms."
60,Locating requirements in backlog items: Content analysis and experiments with large language models,van Can A.T.; Dalpiaz F.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212435343&doi=10.1016%2fj.infsof.2024.107644&partnerID=40&md5=f9fba7b9ca0dfbf1bab2d50227466b10,Article,locating requirements in backlog items: content analysis and experiments with large language models,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,,,"General domain (agile software development, issue tracking systems, user stories, backlogs)","Automated identification and classification of requirements in backlog items (user stories, tasks, etc.) in issue tracking systems","ChatGPT (GPT-4), Llama 3, Mistral 7B, BERT (base, cased), RoBERTa (base)",yes,No,Standalone,fine-tuning (encoder-only); in-context learning (decoder-only); prompt engineering (decoder-only),fine-tuning (encoder-only); zero-shot and few-shot/in-context (decoder-only),Instruction + Description + Template + Persona (for decoder-only); standard supervised input (for encoder-only),yes,no,no,"Annotated backlog items from 14 projects (7 OSS, 7 proprietary); open-source portion available via Zenodo (see Data Availability)",yes,"precision, recall, F1-score",controlled experiment (cross-validation on annotated dataset),"functional_suitability, performance_efficiency, usability, reliability",1,1,1,1,4,0,0,0,0,1,0,0,1,0,0,"concept/prototype (no tool, only experiments); barriers highlighted (need for fine-tuning, data labeling, model selection)",Limited to annotated data from 14 projects; proprietary data not shared; no hyperparameter tuning; decoder-only models not fine-tuned due to computational cost; only certain LLMs tested; generalizability to other domains not established.
61,An exploratory study on automatic identification of assumptions in the development of deep learning frameworks,Yang C.; Liang P.; Ma Z.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205432669&doi=10.1016%2fj.scico.2024.103218&partnerID=40&md5=ff029e8e971b9b82610fcedd2d0207a4,Article,an exploratory study on automatic identification of assumptions in the development of deep learning frameworks,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,,,1,"Deep learning framework development (TensorFlow, Keras)","Automatic identification of assumptions in GitHub issues, pull requests, and commits","ChatGPT (GPT-3.5, GPT-4), Claude 3.5 Sonnet, Gemini 1.0 pro, ALBERT",no,No,Standalone,,,Instruction + Descriptive (decoder-only models),yes,Assumption Miner,yes,AssuEval,yes,"accuracy, precision, recall, f1-score",case study,"functional_suitability, performance_efficiency, usability, reliability",1,1,1,1,4,0,0,0,0,1,0,1,1,0,1,concept/prototype,ALBERT input length limit; decoder-only models not fine-tuned; generalizability to other domains not tested
62,LLM-Based Automation of COSMIC Functional Size Measurement From Use Cases,De Vito G.; Di Martino S.; Ferrucci F.; Gravino C.; Palomba F.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001517411&doi=10.1109%2fTSE.2025.3554562&partnerID=40&md5=0173cd5a801ea0f0860cc7b6a67e1283,Article,llm-based automation of cosmic functional size measurement from use cases,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,,1,,,Management Info Systems,COSMIC functional size measurement from natural language use case specifications,GPT-4,No,Temperature: optimal = 0,Standalone,Prompt engineering with handcrafted examples,Few-shot,Instruction + Description + Examples,yes,CosMet,yes,"Albergate (MIS)
FIDCPM, FID-MTC, FID-TCT (Telemedicine)
U-CURE (ML App)
Rise Cooker, Auto Line Switching (Real-time COSMIC use cases)",yes,"1-Rouge, BLEU, BERTScore,MAE, MdAE,Human evaluation ","Controlled experiments, Expert-based evaluation","functional_suitability, performance_efficiency, usability, reliability",1,1,1,1,4,0,0,0,1,0,0,0,1,1,1,Pilot phase,Struggles with subtle semantic or implicit domain knowledge
63,Improving Software Development Traceability with Structured Prompting,Kim D.-K.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218677264&doi=10.1080%2f08874417.2025.2470919&partnerID=40&md5=1f1e326b61097d93ea9ad36695105c7f,Article,improving software development traceability with structured prompting,New,FALSE,FALSE,Analyze now,Haowei,,Yes,F,,1,1,,,General domain (smart home system as case study; applicable to software development broadly),"Improving traceability of software artifacts across requirements analysis, design modeling, implementation, and testing using structured prompting with LLMs","Meta Llama 3, Gemini (Google), GitHub Copilot, Claude 3.5 Sonnet, ChatGPT-4o",No,No,Standalone,Structured prompt engineering (based on social science principles),Zero-shot,"Instruction + Descriptive (structured prompt with context, input data, task, expected outcome)",yes,no,no,no,no,"Validity, Completeness, Consistency, Traceability Metric for Activity (TMA), Traceability Metric for Phase (TMP), Traceability Metric for Process (TMPR)",Case study (smart home system across 5 LLMs),"functional_suitability, usability",1,1,1,1,4,0,0,0,0,0,0,0,1,1,0,"concept/prototype (case study only, not in production)",Limited to a single case study (smart home system); challenges in controlling LLM adherence to prompt instructions; over-specification due to LLM domain knowledge
64,Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering,Gonzalez-Maldonado D.; Liu J.; Franklin D.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000208259&doi=10.1145%2f3641554.3701910&partnerID=40&md5=e0f8c66ad0c27466cc238a2649954727,Conference paper,evaluating gpt for use in k-12 block based cs instruction using a transpiler and prompt engineering,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,1,1,,"K-12 computer science education, block-based programming (Scratch)",(1) Generating sample solutions for Scratch assignments; (2) Natural language autograding of student Scratch projects,"GPT (version not explicitly stated, but context suggests GPT-3.5 or GPT-4)",No,No,"standalone (prompt-based interaction with LLM, using transpiled code)","prompt engineering, transpiler (Scratch↔Python, Scratch↔S-Expressions), multi-turn dialogue simulation",zero-shot,"Instruction + Descriptive (premise, sample, then task)",Yes,no,No,Scratch Encore student projects (2018-19),No,"syntax correctness (compilation), requirement score (task completion), extension score, correlation (Pearson's r) with official autograder, false positive/negative error analysis",controlled experiment (LLM-generated solutions and grading compared to ground truth),"functional suitability, performance efficiency, usability",1,1,1,1,4,0,1,1,0,1,0,1,0,0,0,"concept/prototype, barriers highlighted",Prompt-only approach is insufficient for reliable results; fine-tuning and multimodal models suggested as future work; dataset availability and privacy are challenges.
65,Task Decomposition and Self-Evaluation Mechanisms for Home Healthcare Robots Using Large Language Models,Liu L.; Zhang S.; Jiang Y.; Guo J.; Zhao W.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003231100&doi=10.1109%2fACCESS.2025.3559076&partnerID=40&md5=19d22edb3770ba4ca1744a77b706e850,Article,task decomposition and self-evaluation mechanisms for home healthcare robots using large language models,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,1,1,,Home healthcare robotics (elderly care),"Task decomposition, code generation, and self-evaluation for robot control in home healthcare tasks (e.g., grab cup, deliver medicine, clean table)",LLaMA3 8B (fine-tuned),Yes,No,standalone (robot control system),"self-evaluation module, task decomposition, prompt engineering, LoRA fine-tuning","few-shot, chain-of-thought",Instruction + Descriptive + Iterative (multi-layered prompt structure),Yes,Elderly Care GPT,No,"Home healthcare robot task dataset (2,000 real-world entries, constructed for this study)",No,"Task success rate, Accuracy, Response time, Comparative analysis with other models","Controlled experiment (real-world robot tasks, repeated trials, expert scoring)","Functional suitability, Reliability, Performance efficiency, Usability",1,1,1,1,4,0,0,0,0,0,1,1,0,1,0,"concept/prototype (real robot experiments, not in production)","Tested in controlled environments; adaptability to unstructured, real-world home settings remains for future work."
66,Leveraging machines to derive domain models from user stories,Bragilovski M.; van Can A.T.; Dalpiaz F.; Sturm A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003180477&doi=10.1007%2fs00766-025-00442-9&partnerID=40&md5=f1b7b6cc2c57c7f14380ec64263ed022,Article,leveraging machines to derive domain models from user stories,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,1,,,"General software development (user stories from various domains, e.g., School, Supermarket, Ticket, etc.)",Derivation of domain models (classes and associations) from user stories,"ChatGPT 4.0 (GPT-4), Mistral",No,No,standalone,"prompt engineering with structured, persona-based, and stepwise prompts; multiple prompt strategies (single prompt, iterative prompts in one session, iterative prompts in separate sessions)","zero-shot, iterative","Instruction + Descriptive, Iterative",Yes,no,No,"Benchmark dataset of user stories and domain models (nine projects, e.g., School, Supermarket, Ticket, etc.)",Yes,"F0.5-score, F1-score, F2-score, precision, recall","controlled experiment, comparative evaluation with human experts and novices","functional suitability, usability",1,1,1,1,4,0,0,0,1,0,0,1,1,0,0,"concept/prototype, discussed potential, barriers highlighted",LLMs struggle with distinguishing classes vs. attributes and implementation constructs; performance varies by domain familiarity; human oversight needed for correctness.
67,Language Models to Support Multi-Label Classification of Industrial Data,Abdeen W.; Unterkalmsteiner M.; Wnuk K.; Ferrari A.; Chatzipetrou P.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007293644&doi=10.1109%2fSANER64311.2025.00013&partnerID=40&md5=bb3100c22e6ba6fab85db92793802009,Conference paper,language models to support multi-label classification of industrial data,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,"industrial requirements engineering (transportation software domain, generalizable to other domains)",multi-label requirements classification using hierarchical taxonomies for traceability and automation,"T5-xl, T5-large, T5-base, MiniLM, DistillRoBERTa, MPNet, Multi-MPNet, RoBERTa-base, RoBERTa-large, Llama2-7B, Llama2-13B, Llama2-70B, Mistral-7B, Mixtral-8x7B",No,No,standalone (zero-shot classifier using embeddings from LMs/LLMs),cosine similarity between requirement and class embeddings; hierarchical strategy for taxonomy; context aggregation; top-k label selection,zero-shot,"N/A (embedding-based, not prompt-based)",No,zero-shot requirements classifier (no specific name),Yes,"industrial requirements dataset (22000 total, 377 annotated for study); taxonomies: SB11 and CoClass",Yes,"precision, recall, F1-score, Fβ (F189), novel label distance metric (Dn)","controlled experiment (systematic comparison across 14 models, 6 output spaces)","functional suitability, performance efficiency, usability",1,1,1,1,4,0,0,0,0,1,0,0,1,0,0,concept/prototype; potential for semi-automation in industry discussed,external validity (single domain dataset); subjective analysis in scatter plots; resource limitations for largest models
68,Automatic Analysis of App Reviews Using LLMs,Gunathilaka S.; de Silva N.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001692633&doi=10.5220%2f0013375600003890&partnerID=40&md5=cd54669e0220f69e2d298771177eaffb,Conference paper,automatic analysis of app reviews using llms,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,Mobile app review analysis for software evolution and requirements engineering,"Classification of app reviews into bug reports, feature requests, user experiences, and ratings","GPT-3.5, Gemini Pro 1.0, Llama-2-7b-chat-hf, Mistral-7B-Instruct",Yes,No,Standalone,"zero-shot, instruction fine-tuning, explain-then-annotate, parameter-efficient fine-tuning (PEFT), QLoRA","zero-shot, few-shot (for fine-tuning)","Instruction, Instruction + Explanation (explain-then-annotate)",Yes,no,no,"Maalej and Nabil (2015) subset, 10,000 GPT-3.5-annotated app reviews",yes,"precision, recall, F1-score, Cohen's kappa, manual human evaluation","controlled experiment, manual annotation review","functional_suitability, usability, performance_efficiency",1,1,1,1,4,1,1,1,0,1,0,0,1,0,0,"concept/prototype, open-source code and dataset released","Limited to English, U.S. app reviews, only 7B parameter models, small benchmark, temporal model variation, energy/environmental cost, potential for misuse"
69,Identifying open-texture in regulations using LLMs,Guitton C.; Gubelmann R.; Karray G.; Mayer S.; Tamò-Larrieux A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004360223&doi=10.1007%2fs10506-025-09450-0&partnerID=40&md5=8bbef6ddb15611e9337b57723eeb96de,Article,identifying open-texture in regulations using llms,New,FALSE,FALSE,Analyze now,Jati,‘,Yes,F,,1,,1,,"Legal domain (regulatory documents, specifically GDPR)","Automatic detection of open-texture (vague, ambiguous, under-specified, or abstract terms) in legal texts","gpt-3.5-turbo, llama-2-70b-chat (plus additional sensitivity analysis with Gemma2, Mixtral, Llama3, GPT-4o)",No,No,standalone,prompt-based extraction of open-textured terms; sensitivity analysis with prompt variations and few-shot examples,"zero-shot, few-shot (in sensitivity analysis)","Instruction, Instruction + Descriptive, with and without few-shot examples",Yes,no,No,"GDPR (General Data Protection Regulation), annotated dataset (https://osf.io/frjxg/)",Yes,"precision, recall, F1-score, Cohen’s kappa (inter-annotator agreement)","expert study (12 law students as annotators, majority vote, comparison with LLM output)","functional suitability, usability, reliability",1,1,1,1,4,1,1,0,1,1,0,1,1,0,1,"concept/prototype, discussed potential, barriers highlighted",Low inter-annotator agreement; subjectivity of open-texture; use of law students instead of professionals; prompt/LLM sensitivity; not all legal tasks covered.
70,RE-Miner 2.0: A Holistic Framework for Mining Mobile Application Reviews,Tiessler M.; Motger Q.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006492184&partnerID=40&md5=1947a754590410799d7814a2a80e9793,Conference paper,re-miner 2.0: a holistic framework for mining mobile application reviews,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,,,,Mobile application reviews (app stores/marketplaces),"Feature extraction, emotion classification, topic analysis, review type identification, polarity analysis, feature clustering","GPT-3.5 (for emotion extraction), BERT, BETO, RoBERTa, DistilBERT, SVM, MLP, T-FREX, TransFeatEx, HCA (custom)",Yes,No,"Hybrid (microservice-based, multi-model)",,,"N/A (API/microservice-based, not prompt-driven)",no,RE-Miner 2.0,yes,"T-FREX, AWARE, de Amba et al., Araujo et al., Polarity Analysis Dataset, Review Type Analysis Dataset, Review Topic Analysis Dataset",yes,"quantitative ground-truth evaluation (accuracy, cross-validation), performance efficiency (response time, scalability), usability (user study, satisfaction)","Planned/ongoing: empirical evaluation, cross-validation, user studies","performance_efficiency, usability",1,1,0.5,1,3.5,1,0,1,1,0,0,0,1,0,0,"concept/prototype (work-in-progress, demo available)","Generalization, annotation quality, domain specificity, real-world variation"
71,StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions,Chen Z.; Wang J.; Xia M.; Shigyo K.; Liu D.; Zhang R.; Qu H.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000387127&doi=10.1109%2fTVCG.2024.3456363&partnerID=40&md5=ce1c8badfd7da3cb3fc993a46c5ffbff,Article,stugptviz: a visual analytics approach to understand student-chatgpt interactions,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,,1,,Education (graduate-level data visualization course),"Analysis of student-ChatGPT interaction patterns, cognitive level classification, prompt strategy mining, and evaluation of learning outcomes in educational tasks","ChatGPT (OpenAI, specific version not stated)",No,No,Standalone,"Prompt pattern mining, cognitive level coding, information gain metric, expert-in-the-loop coding",N/A,N/A,no,StuGPTViz,no,"Student-ChatGPT conversation dataset (data visualization course, Spring 2024)",no,"Information Gain (custom metric), Response Relevance (Ragas), Response Correctness (manual), Learning Outcome (score), Frequency, Length","Case study, expert interview, questionnaire, manual coding, correlation analysis","functional_suitability, usability, performance_efficiency",1,1,1,1,4,0,1,0,1,0,0,1,0,0,0,"concept/prototype, discussed potential, barriers highlighted (scalability, generalizability)","Scalability for large classes, generalizability to other domains, ChatGPT's limitations in visual data interpretation"
72,Early Fault-Detection in the Development of Exceedingly Complex Reactive Systems,Marron A.; Harel D.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001847800&doi=10.5220%2f0013369200003896&partnerID=40&md5=d566d05c95d6a10779309ac47dd0c176,Conference paper,early fault-detection in the development of exceedingly complex reactive systems,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,1,1,,"General domain, with focus on super-reactive (complex, interwoven, evolving) systems (e.g., autonomous vehicles, critical infrastructure, etc.)","Early fault detection, simulation, analysis, and handling of hidden faults in requirements and specifications using natural language and LLMs",Not specified (mentions OpenAI ChatGPT and LLMs in general),No,No,Hybrid,,,"Instruction, scenario description, iterative",Yes,"i-model, Intelligent Development Aide (IDA), i-model Builder, i-model Analyzer, Emergent Effect Detector, Repair Advisor",no,no,no,"Qualitative demonstration (scenario-based, e.g., traffic scenario with ChatGPT)","Demonstrative example, position/vision paper (no formal experiment)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,0.5,0.5,1,3,0,0,1,1,0,0,1,0,0,1,"concept/prototype, discussed potential, barriers highlighted","Scalability, need for human review, LLM errors/hallucinations, lack of formal evaluation"
73,An Experience Report on Leveraging LLMs for GUI Generation: Automating Coding to Prioritise Creativity,Broccia G.; Borselli A.; Cefaloni M.R.; Delcorno F.; Ferrari A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006503622&partnerID=40&md5=d42fc80a39f6c7ed1a05fd3d015dfae4,Conference paper,an experience report on leveraging llms for gui generation: automating coding to prioritise creativity,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,,,,"GUI design for predictive maintenance dashboard in railways (industrial case study, railway domain)","Requirements analysis, information architecture extraction, mockup generation, and mockup refinement for a predictive maintenance dashboard","ChatGPT (GPT-4o, GPT-3.5), DeepSeek-V3",No,No,Standalone,"Role-based prompting, iterative refinement, human-in-the-loop","Zero-shot, iterative","Instructional, role-based, iterative",Yes,No,No,No,No,Stakeholder feedback (qualitative),"Experience report, focus group with stakeholders","functional_suitability, usability",1,0.5,1,1,3.5,0,0,0,0,0,0,0,0,0,0,"concept/prototype (industrial pilot, not in production)","Empirical rigor limited (experience report, not controlled study); generalizability limited; workflow constraints with LLMs; risk of unrealistic stakeholder expectations"
74,A linguistics-based approach to refining automatic intent detection in conversational agent design,Ferrera A.; Mezzotero G.; Ursino D.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204348144&doi=10.1016%2fj.ins.2024.121493&partnerID=40&md5=220b426249cb41bdf3eeeb76441a3e72,Article,a linguistics-based approach to refining automatic intent detection in conversational agent design,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,1,,"Conversational agent design (general domain, with experiments in banking and corporate IT helpdesk)",Automatic intent detection and labeling for conversational agent design,"all-mpnet-base-v2, all-distilroberta-v1, all-MiniLM-L12-v2, all-MiniLM-L6-v2, Universal Sentence Encoder (USE)",No,No,standalone,"Unsupervised clustering with sentence embeddings, UMAP dimensionality reduction, HDBSCAN clustering, linguistics-based automatic labeling using spaCy and dependency parsing",N/A,N/A,No,AID (Automatic Intent Detector),No,"Banking77, proprietary corporate dataset","Banking77: Yes, Corporate: No","Adjusted Rand Index (ARI), Normalized Mutual Information (NMI), Fowlkes-Mallows Index, Homogeneity, Completeness, V-measure, Silhouette Score, Density-Based Clustering Validation (DBCV), Human expert evaluation (semantic coherence, variability, label appropriateness), Spearman’s rank correlation","Controlled experiment (public dataset), case study (corporate dataset), human expert evaluation","Functional suitability, Usability, Performance efficiency",1,1,1,1,4,0,0,0,1,0,0,0,1,0,0,"concept/prototype, discussed potential, barriers highlighted (e.g., language adaptation, lemmatizer errors)","Language-specific lemmatization errors, limited to English, not multimodal, no real-time or economic cost analysis"
75,Leveraging Knowledge Graphs for Personalized Internship Recommendations: A Case Study on Software Engineering Courses,Seetaworn S.; Phenhiran P.; Ngokpol P.; Innoy M.; Ingboon S.; Utasri T.; Takhom A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006539753&doi=10.1109%2fICCI64209.2025.10987407&partnerID=40&md5=c241f683265751acd00fc0cd572b97fe,Conference paper,leveraging knowledge graphs for personalized internship recommendations: a case study on software engineering courses,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,Education-to-Work (Software Engineering internships),"Personalized internship recommendation and skill gap identification using course, student, and job data",N/A (LLM type not specified),No,No,"hybrid (LLM for entity extraction and term expansion, KG for reasoning)","LLM-based entity extraction, term expansion, knowledge graph traversal, semantic scoring",N/A,N/A,No,no,No,no,No,"F1-score, precision, recall, skill fulfillment score","case study (18 students, real-world internship logs, human annotation comparison)","functional suitability, performance efficiency, usability",1,1,1,1,4,0,0,0,0,0,0,0,0,0,0,"concept/prototype (case study, not in production)","Granularity of skill extraction, data completeness, and quality of course/internship descriptions"
76,Grounded Ethical AI: A Demonstrative Approach with RAG-Enhanced Agents,de Cerqueira J.A.S.; Khan A.A.; Rousi R.; Xi N.; Hamari J.; Kemell K.-K.; Abrahamsson P.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218445480&partnerID=40&md5=177ec8602df7141e5ba2d379301de978,Conference paper,grounded ethical ai: a demonstrative approach with rag-enhanced agents,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,,,,1,"General domain, with a focus on AI system development and compliance with ethical/legal guidelines (e.g., EU AI Act)","Supporting developers in creating AI systems that align with legal and ethical guidelines, operationalizing AI ethics and regulatory compliance",N/A,No,No,"Retrieval-augmented, multi-agent system",,,Instruction + Descriptive,no,LLM-based multi-agent system with RAG,no (planned open-source in future),AI Incident Database (real-world cases),no,"Citation accuracy, Alignment with ethical/legal requirements","Demonstration with real-world cases, iterative refinement","functional_suitability, usability",1,0.5,0.5,1,3,1,1,0,0,0,0,1,0,0,0,"concept/prototype, open-sourcing planned, not in production","Citation accuracy, practical usability for developers, need for more extensive testing and practitioner feedback"
77,Explainable Security Requirements Classification Through Transformer Models,Petrillo L.; Martinelli F.; Santone A.; Mercaldo F.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216026594&doi=10.3390%2ffi17010015&partnerID=40&md5=dc87d026ef7b9f2e4b4a78be3d949286,Article,explainable security requirements classification through transformer models,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,General software engineering (security requirements classification),Automatic classification of security vs. non-security requirements,"BERT-base-uncased, DistilBERT-base-uncased, RoBERTa-base, XLNet-base-cased",Yes,No,standalone,"fine-tuning, data augmentation (word augmentation, back translation, paraphrasing), SetFit for few-shot learning, attention visualization for explainability","few-shot, fine-tuning",N/A,No,no,No,SecReq,Yes,"accuracy, precision, recall, F1-score","controlled experiment (train/test/validation split, multiple augmentation strategies)","functional suitability, performance efficiency, usability, interpretability",1,1,1,1,4,1,0,0,1,1,0,0,1,0,0,barriers,"Model sensitivity to augmentation, overfitting on small datasets, challenges with paraphrased/augmented data"
78,Do Chase Your Tail! Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-Tail Software Through Feature Inference,Han L.; Pan S.; Xing Z.; Sun J.; Yitagesu S.; Zhang X.; Feng Z.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201171147&doi=10.1109%2fTSE.2024.3523284&partnerID=40&md5=4a57e30cd25f90a5202f5b904815c95c,Article,do chase your tail! missing key aspects augmentation in textual vulnerability descriptions of long-tail software through feature inference,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,1,1,"Software vulnerability analysis, especially for long-tail (niche) and non-long-tail (mainstream) software","Augmenting missing key aspects (e.g., Attack Vector, Vulnerability Type, Attacker Type, Impact, Root Cause) in Textual Vulnerability Descriptions (TVDs) using LLMs and NLI models","GPT-3.5, GPT-4, LLaMA, T5",No,No,Hybrid,,,Instruction + Descriptive + Fill-in-the-blank + Selection,Yes,no,no,"CVE, NVD, NVD* (custom split), Software-CVE Mapping Database, CWE",yes,"BERTscore, F1-score (for downstream tasks)","Controlled experiment, ablation study, comparison with baselines","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,1,1,0,1,1,0,0,"concept/prototype, discussed potential, barriers highlighted","Vague key aspect descriptions in data, model struggles with complex/long content, lack of qualitative (human) evaluation"
79,Enabling Architecture Traceability by LLM-based Architecture Component Name Extraction,Fuchs D.; Liu H.; Hey T.; Keim J.; Koziolek A.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005025443&doi=10.1109%2fICSA65012.2025.00011&partnerID=40&md5=cf1641cc0fb1d9996a8ae9344dba2df7,Conference paper,enabling architecture traceability by llm-based architecture component name extraction,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,"Software architecture traceability (general domain, open-source projects)",LLM-based extraction of architecture component names from software architecture documentation (SAD) and/or source code to enable traceability link recovery (TLR) between SAD and code.,"GPT-4o, GPT-4 Turbo, GPT-4, GPT-3.5 Turbo, Codellama 13b, Llama 3.1 8b, Llama 3.1 70b",No,No,"Standalone (LLM used to extract component names, then integrated with TransArC TLR pipeline)",,,"Instruction + Descriptive (multi-step, iterative)",Yes,no,no,"TransArC benchmark dataset (Fuchß et al. 2022, Keim et al. 2024)",yes,"precision, recall, F1-score (macro and weighted), Wilcoxon signed-rank test (statistical significance)","Controlled experiment (multiple LLMs, multiple open-source projects, comparison to state-of-the-art baselines)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,"concept/prototype (empirical evaluation, not in production)","Dataset/project diversity, prompt engineering not emphasized, closed-source LLMs may have unknown training data, non-determinism of LLMs, open-source vs. closed-source LLM performance gap."
80,Beyond Just Generative AI for Discovering Software Opportunities,Maiden N.; Zachos K.; Petrianakis K.; Lockerbie J.; Chanpalangsri C.; Ernst H.; Kara S.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003027324&doi=10.1109%2fMS.2025.3540672&partnerID=40&md5=a3831c4efd5c716bd1bef768d2c5275d,Article,beyond just generative ai for discovering software opportunities,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,,,,General domain; evaluated in domestic appliances (Miele) and biomass power (Thailand),Discovery and invention of creative requirements/opportunities from large volumes of project-related information; domain and problem/solution space analysis,GPT-4o (August 2024),No,No,Hybrid,,,"Instruction + Descriptive (see Figure 2, page 4)",Yes,INSIGHTS,no,Proprietary datasets (Miele: 468 documents; Thailand: 100 PDFs),no,"User ratings (novelty, usefulness, process impact), Number and diversity of opportunities generated",Two case studies (workshops with stakeholders in industry settings),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,1,0,1,0,0,1,0,"concept/prototype; pilot workshops in industry; barriers highlighted (e.g., information coverage, traceability)",Limited novelty of generated opportunities; lack of traceability to source documents; need for broader information coverage
81,Database Chatbot Success: User-Centered Design With LLMs,Pinon S.; Burnay C.; Linden I.; Michel R.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219663628&doi=10.1080%2f08874417.2025.2467632&partnerID=40&md5=5050fa818339b0e5dd7d9aa8eb252b0f,Article,database chatbot success: user-centered design with llms,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,1,1,,"Healthcare (medical data, MIMIC IV); general business decision support","Natural language data query support system (NL-DQSS) for business professionals; requirements elicitation, user-centered design, iterative query refinement, secure access, context integration","GPT-4 (OpenAI, via LangChain)",No,No,hybrid (LLM agent + information retrieval + access control),"Tree of Thought, Interaction Chain, Prompt Engineering, Retrieval-augmented generation, Role-based Access Control (RBAC)","zero-shot, prompt-based","Instruction + Descriptive, Iterative, Profile-adapted",No,B2Data,Yes,MIMIC IV (subset),Yes,"User study Likert-scale scores (ease of use, usefulness, intention to use), qualitative feedback","User study (interviews, scenario-based user tests, questionnaire)","Functional suitability, Usability, Security, Performance efficiency",1,1,1,1,4,0,0,1,1,1,0,0,0,0,0,"concept/prototype, user-tested, not in production",Limited to medical domain in evaluation; small user sample; no fine-tuning; only qualitative results
82,Cross-Level Requirements Tracing Based on Large Language Models,Ge C.; Wang T.; Yang X.; Treude C.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005774424&doi=10.1109%2fTSE.2025.3572094&partnerID=40&md5=c31505995be2c38e3f6ca4cd7c078760,Article,cross-level requirements tracing based on large language models,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,1,"Aerospace, project management, web tools, healthcare (cross-domain, including single-project, cross-project, and cross-domain datasets)",Cross-level requirements traceability (linking high-level and low-level requirements),"LLaMA (1.1B, 7B, 13B)",Yes,No,Standalone,"Prompt-Tuning, LoRA, P-Tuning (parameter-efficient fine-tuning)","few-shot (with fine-tuning), also compared to zero-shot prompting in baselines",Instruction + Classification (binary classification: traceable or not),yes,no,no,"CM1, Modis, GANNT, WARC, CCHIT, IP, CM1-Modis, GANNT-WARC, IP-CCHIT, Cross-project (all described in Table 1, page 9)",yes,"Accuracy, Precision, Recall, F1 Score","Controlled experiment (multiple datasets, ablation studies, comparison with baselines)","functional_suitability, performance_efficiency, usability, maintainability",1,1,1,1,4,0,0,0,0,1,0,0,1,0,1,"barriers (discussed as future work, not yet in production)","Limited to LLaMA models; domain coverage; data augmentation may introduce noise; practical challenge of acquiring large, high-quality traceability datasets."
83,Test2Text: AI-Based Mapping between Autogenerated Tests and Atomic Requirements,Treshcheva E.; Itkin I.; Yavorskiy R.; Dorofeev N.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004740527&doi=10.1109%2fICSTW64639.2025.10962519&partnerID=40&md5=3a6c3ff6de752288bb74d732f022eb17,Conference paper,test2text: ai-based mapping between autogenerated tests and atomic requirements,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,1,,1,"industrial software testing (exchange systems, trading technology)",,N/A,No,No,hybrid (LLM + classic ML),"prompt-based annotation generation and mapping, Steps-to-Prose engine, classic ML for acceleration",N/A,Instruction + Summarization + Likelihood,No,Test2Text,No,No,No,"annotation accuracy (future work), mapping correctness (future work)",N/A (solution design only),functional suitability (discussed),1,0.5,0.5,1,3,1,0,0,0,1,1,0,0,0,0,concept/prototype (future work),"processing time, need for domain-specific customization, lack of evaluation"
84,Semantic-Driven Paradigm Shift in Campus Guide Design Leveraging the KE-AIGC Framework,Chen X.; Wang J.; Zhuang Y.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217020445&doi=10.4018%2fIJSWIS.368039&partnerID=40&md5=3c892149a0f717b6a5bce758fca0ba16,Article,semantic-driven paradigm shift in campus guide design leveraging the ke-aigc framework,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,1,1,1,1,,university campus guide systems (wayfinding design),Semantic-driven translation of emotional and functional user requirements into design elements for campus guide systems using Kansei Engineering and Generative AI,"AIGC (Generative AI, specific model not named)",No,No,"hybrid (Semantic Web, NLP, Kansei Engineering, and Generative AI)","Prompt engineering, modular component generation, style transfer, clustering, topic modeling, SEM mapping",N/A,"Instruction + Descriptive (see prompt templates on page 10, Table 2 and page 18, Table 6)",Yes,KE-AIGC-design framework,No,"proprietary dataset (user questionnaires, interviews, and experimental data)",No,"user satisfaction, need identification accuracy, emotional mapping consistency, improvement rate, statistical significance (p-value)","controlled experiment (multi-phase, with user studies and quantitative analysis)","functional suitability, usability, performance efficiency",1,1,1,1,4,0,0,0,0,0,1,0,0,1,0,"concept/prototype, successful campus pilot, future broader application discussed",Limited accessibility improvements for visually impaired users and performance in adverse weather; future work includes AR/IoT integration and real-time feedback.
85,Using ChatGPT to Refine Draft Conceptual Schemata in Supply-Driven Design of Multidimensional Cubes,Rizzi S.,2025,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000270138&partnerID=40&md5=b4aa3319bf5151137729304cba19c75c,Conference paper,using chatgpt to refine draft conceptual schemata in supply-driven design of multidimensional cubes,New,FALSE,FALSE,Analyze now,Jati,,Yes,F,,1,,,,"Conceptual design of multidimensional data cubes (data warehousing, business intelligence)","Refinement of draft Dimensional Fact Model (DFM) schemata in supply-driven design: making attribute names intuitive, labeling measures for additivity, finding descriptive/discretized/optional attributes, completing time hierarchies, removing uninteresting attributes.",GPT-4o,No,No,Standalone,,,"Instruction, Case, Iterative (with examples and procedures for improved prompts)",Yes,no,no,proprietary set of 5 test cases (from master course exercises),no,Number of refinement errors per test case (by subtask),Manual error counting on test cases (quasi-experimental),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,"concept/prototype (lab experiment, not deployed)",Residual errors in LLM output require human intervention; struggles with shared hierarchies and YAML syntax; subjective nature of refinement; no public dataset.
86,ReqBrain: Task-Specific Instruction Tuning of LLMs for AI-Assisted Requirements Generation,"Habib, Mohammad Kasra; Graziotin, Daniel; Wagner, Stefan",2025,arXiv,10.48550/arXiv.2505.17632,http://arxiv.org/abs/2505.17632,preprint,reqbrain: task-specific instruction tuning of llms for ai-assisted requirements generation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,1,,,"General domain (software engineering, multiple domains via SwaRD and KIB3 projects)","Automated generation of ISO 29148-compliant requirements; includes sub-tasks: generating, classifying, and completing requirements, identifying missing requirements, and generating requirements from instructions or partial sets.","Zephyr-7b-beta (with comparison to Mistral-7B-Instruct-v0.2, Llama-2-7b-chat-hf, Falcon-7b-instruct, Falcon-7b, and ChatGPT-4o)",Yes,No,Standalone (with potential for RAG integration),task-specific instruction tuning (LoRA-based parameter-efficient fine-tuning),Supervised fine-tuning (not zero/few/one-shot); instruction-based learning,"Instruction (with context, requirement class, and compliance details)",Yes,ReqBrain,yes,SwaRD (Software Requirements Dataset) + instruct dataset (open) + KIB3 project requirements,yes,"BERT Score, FRUGAL Score, F1-score, Human evaluation (perceived authorship, Likert ratings for adequacy, compliance, completeness)","Controlled experiment (NLP benchmarking), user/expert study (human evaluation)","functional_suitability, usability, maintainability, portability",1,1,1,1,4,0,0,1,0,1,0,1,1,0,1,"concept/prototype; industrial case study underway; open-source, RAG-enabled version in development",Limited number of human evaluators; domain diversity of evaluation projects; manual selection of training data; need for further usability studies.
87,Towards Requirements Engineering for RAG Systems,"Sporsem, Tor; Ulfsnes, Rasmus",2025,arXiv,10.48550/arXiv.2505.07553,http://arxiv.org/abs/2505.07553,preprint,towards requirements engineering for rag systems,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,1,1,"maritime industry, regulatory compliance, expert support",Eliciting and managing 'retrieval requirements' for RAG systems; filtering and contextual retrieval for regulatory Q&A; expectation management,GPT-4,No,No,retrieval-augmented,"iterative filtering, user-in-the-loop, context-based retrieval",N/A,N/A,no,no,no,proprietary Marcomp case handler Q&A database,no,"user feedback, qualitative observation","case study, field observation, interviews","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,1,1,0,1,0,1,0,"pilot project, concept, barriers highlighted","Single case study, limited generalizability, construct validity challenges, no quantitative impact measurement"
88,Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models,"El-Hajjami, Abdelkarim; Salinesi, Camille",2025,arXiv,10.48550/arXiv.2505.03265,http://arxiv.org/abs/2505.03265,preprint,synthline: a product line approach for synthetic requirements engineering data generation using large language models,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,,,Healthcare and restaurant operations management; generalizable to classification-based RE tasks,"Synthetic data generation for requirements specification defect classification (e.g., ambiguous, directive, non-measurable, optional, uncertain, non-atomic requirements)","GPT-4o, DeepSeek-V3",No,No,Standalone,,,Instruction + Descriptive (structured template),Yes,Synthline,yes,"Synthline synthetic RE defect dataset, Fazelnia et al. real dataset",yes,"Vocabulary size, Normalized vocabulary size, Average Pairwise Similarity (APS), Intra-class APS, Inter-sample N-gram Frequency (INGF), Precision, Recall","Controlled experiment (train-on-synthetic, test-on-real paradigm, multiple runs)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,0,1,1,0,"concept/prototype, open-source, barriers highlighted (e.g., generalizability, prompt design, domain limitations)","Limited diversity in synthetic data, domain generalizability, prompt design sensitivity, small real test set, fixed hyperparameters, constrained NL format limits diversity"
89,Automating Automotive Software Development: A Synergy of Generative AI and Formal Methods,"Pan, Fengjunjie; Song, Yinglei; Wen, Long; Petrovic, Nenad; Lebioda, Krzysztof; Knoll, Alois",2025,arXiv,10.48550/arXiv.2505.02500,http://arxiv.org/abs/2505.02500,preprint,automating automotive software development: a synergy of generative ai and formal methods,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,,Automotive software development (Autonomous Emergency Braking scenario),"Automated extraction of event chains from requirements, code generation for subcomponents, formal model creation, and integration code generation for automotive systems",GPT-4o,No,No,Hybrid,"Agentic workflow, model-driven engineering, prompt-based event chain extraction, model-based code generation","One-shot (for model generation), prompt-based for other tasks",Instruction + Descriptive + Template-based,Yes,No,No,No,No,"Functional correctness (simulation-based), Early-phase model validation (OCL constraints)",Case study (Autonomous Emergency Braking in CARLA simulator),"functional_suitability, usability",1,1,1,1,4,0,0,0,0,0,1,1,0,0,0,concept/prototype (demonstrated in simulation),Dependence on input requirement quality; scalability and robustness for larger systems not yet evaluated; automated test generation for LLM code is future work
90,From Inductive to Deductive: LLMs-Based Qualitative Data Analysis in Requirements Engineering,"Shah, Syed Tauhid Ullah; Hussein, Mohamad; Barcomb, Ann; Moshirpour, Mohammad",2025,arXiv,10.48550/arXiv.2504.19384,http://arxiv.org/abs/2504.19384,preprint,from inductive to deductive: llms-based qualitative data analysis in requirements engineering,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,,,"General domain (Library Management System, Smart Home System)",Qualitative Data Analysis (QDA) annotation of requirements—labeling/coding requirement statements into domain-relevant categories,"GPT-4, Mistral, LLaMA-2",No,No,Standalone,"zero-shot, one-shot, few-shot","zero-shot, one-shot, few-shot","Instructional, context-rich, classification",Yes,no,no,"PURE dataset, supplemented with SRS/FRS documents from the internet",no,"Cohen’s Kappa, accuracy, precision, recall, F1-score, standard deviation (SD), Intraclass Correlation Coefficient (ICC)",Controlled experiment (comparison with human analysts),"functional_suitability, reliability, performance_efficiency",1,1,1,1,4,1,0,0,0,0,0,0,1,0,0,concept/prototype,"Limited domain diversity, potential prompt design bias, human annotation subjectivity"
91,How Effective are Generative Large Language Models in Performing Requirements Classification?,"Alhoshan, Waad; Ferrari, Alessio; Zhao, Liping",2025,arXiv,10.48550/arXiv.2504.16768,http://arxiv.org/abs/2504.16768,preprint,how effective are generative large language models in performing requirements classification?,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,,,"General domain (software requirements from PROMISE NFR, Functional-Quality, and SecReq datasets)",Requirements classification (binary and multi-class),"Bloom, Gemma, Llama (specific versions: bigscience/bloom-560m, google/gemma-2b, meta-llama/Meta-Llama-3-8B)",No,No,Standalone,Inference-based (zero-shot) learning,Zero-shot,"Assertion-based, definition-based, Q/A-based (Instructional, Descriptive, Question)",yes,no,no,"PROMISE NFR, Functional-Quality, SecReq",yes,"precision, recall, F1-score, weighted precision, weighted recall, weighted F1-score",Controlled experiment (systematic experiments with statistical analysis),"functional_suitability, performance_efficiency, reliability",1,1,1,1,4,0,0,0,0,0,0,0,1,0,0,barriers (limitations and generalizability discussed),"Dataset limitations, technological obsolescence, construct validity"
92,Un marco conceptual para la generación de requerimientos de software de calidad,"Pacchiotti, Mauro José; Ballejos, Mariel Ale y Luciana",2025,arXiv,10.48550/arXiv.2504.10654,http://arxiv.org/abs/2504.10654,preprint,un marco conceptual para la generación de requerimientos de software de calidad,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,,,General domain (software requirements across various domains),"Improving the quality of natural language software requirements; requirement evaluation, question generation for clarification, and rewriting requirements",ChatGPT (GPT-4o mini),No,No,"Standalone, agent (optional), retrieval-augmented (RAG in some variants)",,,"Instruction, iterative, descriptive, table-based",yes,no,no,no,no,% of INCOSE characteristics fulfilled (custom metric),"Conceptual proof, controlled example-based evaluation","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,0.5,0.5,1,3,0,0,0,0,0,0,1,1,0,0,concept/prototype,"No real-world dataset, only conceptual proof; non-determinism of LLM outputs; no agent implementation"
93,Leveraging LLMs for User Stories in AI Systems: UStAI Dataset,"Yamani, Asma; Baslyman, Malak; Ahmed, Moataz",2025,arXiv,10.48550/arXiv.2504.00513,http://arxiv.org/abs/2504.00513,preprint,leveraging llms for user stories in ai systems: ustai dataset,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,,,"General AI systems across 26 domains (e.g., health, information systems, autonomous vehicles, law, marketing, etc.)","Generation of user stories for AI systems from scholarly abstracts, including annotation for non-functional requirements (NFRs) and ethical principles.","Gemini 1.5 Flash, ChatGPT o1-mini, Llama 3.1 70b",No,No,Standalone,Zero-shot,Zero-shot,Instruction,Yes,UStAI,Yes,UStAI,Yes,"QUS framework (syntactic, semantic, pragmatic quality criteria), inter-annotator agreement (Cohen’s Kappa)",Manual annotation and expert validation (user study),"functional_suitability, usability, maintainability",1,1,1,1,4,1,1,1,0,0,0,0,1,0,0,"concept/prototype, dataset released, barriers highlighted","LLMs not ready to fully replace humans in RE; dataset based on abstracts, not real industrial specs; prompt and LLM selection bias; limited completeness due to abstract input."
94,Automated Non-Functional Requirements Generation in Software Engineering with Large Language Models: A Comparative Study,"Almonte, Jomar Thomas; Boominathan, Santhosh Anitha; Nascimento, Nathalia",2025,arXiv,10.48550/arXiv.2503.15248,http://arxiv.org/abs/2503.15248,preprint,automated non-functional requirements generation in software engineering with large language models: a comparative study,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,,1,,"general domain (software systems, SRS documents from various domains)","Automated generation of non-functional requirements (NFRs) from functional requirements (FRs) using LLMs, including attribute assignment and expert validation.","gpt-4o-mini, claude-3-5-haiku-20241022, claude-3-7-sonnet-20250219, gemini-1.5-pro, Llama-3.3-70B-Instruct-Turbo-Free, deepSeek-V3, Qwen2.5-72B-Instruct-Turbo, grok-2-1212",No,No,Standalone,,,Instruction + Example + Structured Output + Iterative,Yes,no,no,"FR NFR dataset, PURE dataset (subset), open expert-annotated dataset (Zenodo DOI:10.5281/zenodo.15002723)",yes,"Validity (1-5 scale), Applicability (1-5 scale), Attribute accuracy (expert match %)","Expert study (10 industry evaluators, web-based interface, blind review, stratified sampling)","functional_suitability, usability",1,1,1,1,4,1,1,0,0,0,0,1,1,0,0,"concept/prototype, open dataset, future work for real-world case study","Small sample size, dataset from older SRS documents, evaluator subjectivity, isolated NFR generation (no stakeholder interaction), need for larger/modern datasets and real-world validation."
95,Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for Impacting Mapping on Requirements Elicitation,"Zou, Xinkai; Liu, Yan; Shi, Xiongbo; Yang, Chen",2025,arXiv,10.48550/arXiv.2503.13279,http://arxiv.org/abs/2503.13279,preprint,goal2story: a multi-agent fleet based on privately enabled sllms for impacting mapping on requirements elicitation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,,,,General domain (agile software projects from various domains),Goal-driven requirements elicitation using Impact Mapping to generate user stories from business goals,"Llama-2-7B, Qwen2.5-7B-Instruct-1M, DeepSeek-R1-Distill-Qwen-7B (for Goal2Story); GPT-4o, DeepSeek-R1 (for Super-Agent baseline)",no,No,"Hybrid (multi-agent fleet with standalone sLLMs for subtasks, compared to a Super-Agent baseline)",,,Instruction + Descriptive + JSON output format,yes,Goal2Story,"yes (open-source, https://github.com/SoftACE-Lab/goal2story)",StorySeek,"yes (open-source, https://huggingface.co/datasets/SoftACE/StorySeek)","Factuality Hit Rate (FHR), Quality And Consistency Evaluation (QuACE), F1-score, Alignment Rate, False Positive Rate (FPR)","Controlled experiment, human alignment study","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,1,0,1,0,0,1,0,0,"concept/prototype, discussed potential",Profile feature impact varies; model characteristics influence performance but are not sole determinants; human alignment FPR for QuACE is relatively high
96,"An LLM-Integrated Framework for Completion, Management, and Tracing of STPA","Raeisdanaei, Ali; Kim, Juho; Liao, Michael; Kochhar, Sparsh",2025,arXiv,10.48550/arXiv.2503.12043,http://arxiv.org/abs/2503.12043,preprint,"an llm-integrated framework for completion, management, and tracing of stpa",New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,,1,"General safety-critical systems (examples: automotive, aviation, nuclear, healthcare, military)","STPA artifact completion, management, and traceability; UCA and loss scenario generation; automated artifact linking","GPT-4o (OpenAI, vision-enabled)",No,No,Standalone (Python framework with LLM integration),,,Instruction + Descriptive + Few-shot,yes,stpa (https://github.com/blueskysolarracing/stpa),yes,"STPA Handbook case studies (e.g., aviation, nuclear, automotive, etc.)",yes,"Human annotation (correct/useful, correct/useless, incorrect), Accuracy, Precision, Recall, F1-score","Case study, human annotation","functional_suitability, usability, maintainability",1,1,1,1,4,1,1,0,0,0,1,1,0,0,0,"concept/prototype, open-source, discussed potential, barriers highlighted",Possible data leakage from public case studies; small-scale evaluation; need for more diverse/real-world exemplars; human-in-the-loop required
97,PromAssistant: Leveraging Large Language Models for Text-to-PromQL,"Zhang, Chenxi; Zhang, Bicheng; Yang, Dingyu; Peng, Xin; Chen, Miao; Xie, Senyu; Chen, Gang; Bi, Wei; Li, Wei",2025,arXiv,10.48550/arXiv.2503.03114,http://arxiv.org/abs/2503.03114,preprint,promassistant: leveraging large language models for text-to-promql,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,,,"Metric monitoring in online service systems (Prometheus/PromQL, AIOps)",Natural language to PromQL query generation (text-to-PromQL),"GPT-4-Turbo, DeepSeek-Coder-V2-236B",No,No,Hybrid,"Knowledge graph-enhanced retrieval-augmented generation (RAG), multi-hop reasoning, BM25, Chain-of-Thought, few-shot learning","Few-shot, Chain-of-Thought",Instruction + Descriptive + Chain-of-Thought + Example,yes,PromAssistant,no,text-to-PromQL benchmark (TrainTicket-based),no,"MetricAcc, SyntaxAcc, QueryAcc, Precision, Recall, F1-score","Controlled experiment, ablation study, manual evaluation","functional_suitability, performance_efficiency, usability",1,1,1,1,4,0,0,0,1,1,0,1,0,0,0,"concept/prototype, discussed potential, barriers highlighted",Dataset based on a single open-source system; generalizability to other domains/systems not fully validated
98,Promptware Engineering: Software Engineering for LLM Prompt Development,"Chen, Zhenpeng; Wang, Chong; Sun, Weisong; Yang, Guang; Liu, Xuanzhe; Zhang, Jie M.; Liu, Yang",2025,arXiv,10.48550/arXiv.2503.02400,http://arxiv.org/abs/2503.02400,preprint,promptware engineering: software engineering for llm prompt development,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,1,"General domain; focuses on promptware engineering for LLM-based software, not a specific industry domain","Vision paper proposing systematic requirements engineering, design, implementation, testing, debugging, and evolution for prompt development in LLM-based software","GPT, LLaMA, Claude, DeepSeek (general references, not specific version or configuration)",no,No,Standalone (conceptual framework),,,N/A (vision/conceptual),no,no,no,no,no,,N/A (vision/conceptual),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,0.5,0.5,1,3,1,1,1,1,1,1,1,1,1,1,concept/vision; not implemented,No empirical validation; conceptual/vision only
99,Classification or Prompting: A Case Study on Legal Requirements Traceability,"Etezadi, Romina; Abualhaija, Sallam; Arora, Chetan; Briand, Lionel",2025,arXiv,10.48550/arXiv.2502.04916,http://arxiv.org/abs/2502.04916,preprint,classification or prompting: a case study on legal requirements traceability,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,,,"Legal requirements traceability for regulatory compliance (GDPR, HIPAA); general domain with examples in healthcare, cybersecurity, digital services, digital library, professional networking.",Automated prediction of trace links between software requirements and legal provisions (LRT: Legal Requirements Traceability).,GPT-4o,no,No,Standalone,,,Instruction + Examples (RICE framework),yes,Rice,no,"HIPAA, GDPR-derived dataset (4 new documents)",yes,"recall, precision, F1-score, success rate (requirement-level)","Empirical evaluation on benchmark and new datasets; leave-one-out, manual annotation, comparison with baseline and fine-tuned models","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,1,0,0,1,0,0,1,1,0,0,"concept/prototype, barriers highlighted","Terminology gap, generalization across regulations, subjectivity in ground truth, false positives, need for human-in-the-loop validation."
100,Analysis of LLMs vs Human Experts in Requirements Engineering,"Hymel, Cory; Johnson, Hiroe",2025,arXiv,10.48550/arXiv.2501.19297,http://arxiv.org/abs/2501.19297,preprint,analysis of llms vs human experts in requirements engineering,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,,,,General software development (requirements elicitation for user-submitted software ideas),Generation of epics and user stories from natural language software project descriptions,GPT-4,,No,No,Standalone,zero-shot,Instruction,yes,no,no,no,no,"alignment score, completeness rating, identification accuracy",controlled experiment (comparative study with human experts and LLM),"functional_suitability, performance_efficiency, cost",1,1,1,1,4,1,0,0,0,1,0,0,0,0,0,concept/prototype,"Single-instance comparison, subjective evaluation, small sample size, time-boxed comparison"
101,From Bugs to Benefits: Improving User Stories by Leveraging Crowd Knowledge with CrUISE-AC,"Schwedt, Stefan; Ströder, Thomas",2025,arXiv,10.1109/ICSE55347.2025.00217,http://arxiv.org/abs/2501.15181,preprint,from bugs to benefits: improving user stories by leveraging crowd knowledge with cruise-ac,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,1,,E-commerce and content management systems (CMS); generalizable to other domains with issue trackers,Automatic generation of non-trivial acceptance criteria for user stories using crowd knowledge from public issue trackers,"Ensemble of open-source decoder-only LLMs (gemma2:7b, mistral-nemo:12b, llama3:8b, llama3.1:8b, gemma2:27b) for matching; GPT-4 Turbo for acceptance criteria generation and evaluation",no,No,"Hybrid (ensemble for matching, standalone for generation/evaluation)",,,Instruction,yes,CrUISE-AC,"yes (research artifacts and code, see Zenodo links in paper)",User stories and issues from e-commerce and CMS domains (see Zenodo links),yes,"Expert approval rate, F1-score (for trivia filtering), Accuracy (for trivia filtering), Cohen's Kappa, Gwet's AC1",Manual expert study (for acceptance criteria relevance); quantitative evaluation for preprocessing models,"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,1,1,1,1,0,1,concept/prototype; field study and industrial validation planned as future work,Dependence on accessible and relevant issue tracker data; no global check for conflict-free/non-overlapping criteria; manual evaluation required; slow processing for large corpora; only title/description/labels of issues used
102,Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based Automated Requirement Traceability and Compliance Checks,"Masoudifard, Arsalan; Sorond, Mohammad Mowlavi; Madadi, Moein; Sabokrou, Mohammad; Habibi, Elahe",2024,arXiv,10.48550/arXiv.2412.08593,http://arxiv.org/abs/2412.08593,preprint,leveraging graph-rag and prompt engineering to enhance llm-based automated requirement traceability and compliance checks,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,,1,1,,"Regulated environments (finance, aerospace); SRS compliance and traceability",,GPT-4o and GPT-4o-mini,No,No,Hybrid (Graph-RAG with LLM),"Retrieval-augmented generation, chain-of-thought, tree-of-thought, few-shot prompting, multi-agent reasoning","Few-shot, chain-of-thought, tree-of-thought","Instruction, few-shot, chain-of-thought, tree-of-thought, iterative, multi-agent",Yes,No,No,"SRS Broker, SRS Aero, regulatory articles, FTPP specs",No,"Precision, Recall, F1-Score",Controlled experiment (automated evaluation on labeled datasets),"functional_suitability, performance_efficiency, usability",1,1,1,1,4,1,0,0,1,1,0,1,0,0,0,concept/prototype,Effectiveness depends on data quality/completeness; high computational cost; complexity of graph construction; limited generalizability to other domains
103,Automating Business Intelligence Requirements with Generative AI and Semantic Search,"Busany, Nimrod; Hadar, Ethan; Hadad, Hananel; Rosenblum, Gil; Maszlanka, Zofia; Akhigbe, Okhaide; Amyot, Daniel",2024,arXiv,10.48550/arXiv.2412.07668,http://arxiv.org/abs/2412.07668,preprint,automating business intelligence requirements with generative ai and semantic search,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,,"Business Intelligence (BI) systems across security, air defense, retail, and banking domains","Automated elicitation, specification, and validation of BI requirements via conversational interface, text-to-SQL, ontology mapping, and test-case generation","N/A (uses pre-trained or fine-tuned LLMs, specific model not disclosed)",no,No,hybrid,"self-debugging, semantic search, ontology-based query generation, conversational feedback loop","few-shot (example pairs provided), iterative refinement, conversational context",Instruction + Descriptive + Schema context,yes,AUTOBIR,no,"AdventureWorks2014, Spider, BIRD",yes,"Exact Matching, Execution Accuracy, qualitative SME feedback","expert study, qualitative evaluation, benchmark comparison","functional_suitability, usability, security",1,1,1,1,4,1,0,1,1,0,0,1,0,0,0,"concept/prototype, internal use, pilot in multiple domains","Scalability to enterprise-grade environments, applicability to non-standardized data, dependency on ontology quality, limited public availability"
104,System Test Case Design from Requirements Specifications: Insights and Challenges of Using ChatGPT,"Bhatia, Shreya; Gandhi, Tarushi; Kumar, Dhruv; Jalote, Pankaj",2024,arXiv,10.48550/arXiv.2412.03693,http://arxiv.org/abs/2412.03693,preprint,system test case design from requirements specifications: insights and challenges of using chatgpt,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,,,1,,"General software engineering student projects (portals, event management, academic management)",System test case design generation and redundancy detection from SRS,ChatGPT-4o Turbo,No,No,Standalone,"Prompt chaining, role prompting, output format specification",Zero-shot,"Instruction + Descriptive (role-based, output format specified, iterative)",yes,no,no,Five proprietary SRS documents from student engineering projects,no,"Proportion of valid, redundant, not applicable, and missed test cases (developer feedback)",Expert study (developer feedback on generated test cases),"functional_suitability, usability",1,1,1,1,4,0,0,0,0,0,0,1,0,0,1,concept/prototype,"Small dataset, limited generalizability, false positives in redundancy detection, limited system behavior understanding"
105,RECOVER: Toward Requirements Generation from Stakeholders' Conversations,"Voria, Gianmario; Casillo, Francesco; Gravino, Carmine; Catolino, Gemma; Palomba, Fabio",2025,arXiv,10.48550/arXiv.2411.19552,http://arxiv.org/abs/2411.19552,preprint,recover: toward requirements generation from stakeholders' conversations,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,,,,General domain; demonstrated on football league management and industrial meetings (software development),Automatic extraction and generation of system requirements from stakeholder conversations (turn-level identification and requirement generation),Llama 2 (7B),No,No,Standalone (multi-step pipeline),few-shot prompting,few-shot,Instruction + Example (two-shot: positive and negative),yes,RECOVER,yes,"PURE (for classifier training), Spijkman et al. conversation dataset, industrial meeting transcripts",yes,"Precision, Recall, Accuracy, F1-score, BLEU, ROUGE, METEOR, Brevity Penalty (BP), Length Ratio (LR), Human expert Likert ratings (correctness, completeness, actionability)","Mixed-method: controlled experiment, user study (questionnaire), expert panel (Delphi), in-vivo industrial case study","functional_suitability, usability, performance_efficiency",1,1,1,1,4,0,0,0,0,1,0,1,1,0,0,"concept/prototype, in-vivo tested, barriers highlighted","No explicit traceability, no conflict resolution, recall/precision trade-off, context limitations, needs human oversight, limited to explicit requirements, not all RE phases covered"
106,AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG,"Shi, Yichen; Tao, Zhuofu; Gao, Yuhao; Zhou, Tianjia; Chang, Cheng; Wang, Yaxing; Chen, Bingyu; Zhang, Genhao; Liu, Alvin; Yu, Zhiping; Lin, Ting-Jung; He, Lei",2024,arXiv,10.48550/arXiv.2411.13560,http://arxiv.org/abs/2411.13560,preprint,amsnet-kg: a netlist dataset for llm-based ams circuit auto-design using knowledge graph rag,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,Analog and mixed-signal (AMS) circuit design (EDA domain),Automated circuit topology selection and transistor sizing from performance specifications using LLMs and knowledge graph RAG,GPT-4,No,No,retrieval-augmented (KG-RAG),"in-context learning, chain-of-thought, retrieval-augmented generation, constraint-augmented optimization","few-shot, chain-of-thought",Instruction + Descriptive + Iterative (with few-shot and CoT),yes,AMSgen,no,AMSnet-KG,yes,"Figure of Merit (FoM), convergence time, final performance (gain, CMRR, PSRR, GBW, phase margin, offset voltage, propagation delay, power)",case study (OPAMP and comparator design),"functional_suitability, performance_efficiency, usability, maintainability",1,1,1,1,4,0,0,0,0,1,0,1,1,0,1,"concept/prototype, open dataset, no production use","LLM quantitative knowledge limitations, dataset coverage, no real-time or security/ethics analysis"
107,Exploring LLMs for Verifying Technical System Specifications Against Requirements,"Reinpold, Lasse M.; Schieseck, Marvin; Wagner, Lukas P.; Gehlhoff, Felix; Fay, Alexander",2024,arXiv,10.48550/arXiv.2411.11582,http://arxiv.org/abs/2411.11582,preprint,exploring llms for verifying technical system specifications against requirements,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,,,1,,Smart grid domain (energy systems),Verifying if a textual system specification fulfills a set of requirements (requirements verification),"GPT-4o, Claude 3.5 Sonnet, Gemini-1.5, GPT-3.5-turbo",No,No,Standalone,"zero-shot, chain-of-thought, few-shot","zero-shot, chain-of-thought, few-shot","Instruction, chain-of-thought, few-shot",yes,no,no,Proprietary dataset (created for this study),yes,"precision, recall, f1-score",controlled experiment (systematic evaluation against formal rule-based benchmark),functional_suitability,1,1,1,1,4,0,0,0,0,1,0,1,1,0,1,concept/prototype,"Limited dataset size and domain; only accuracy compared, not operational cost or time; only smart grid domain tested"
108,Chain-of-Programming (CoP) : Empowering Large Language Models for Geospatial Code Generation,"Hou, Shuyang; Jiao, Haoyue; Shen, Zhangxiao; Liang, Jianyuan; Zhao, Anqi; Zhang, Xiaopu; Wang, Jianxun; Wu, Huayi",2024,arXiv,10.48550/arXiv.2411.10753,http://arxiv.org/abs/2411.10753,preprint,chain-of-programming (cop) : empowering large language models for geospatial code generation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,1,"Geospatial code generation (geographic information science, remote sensing, mapping, urban planning, environmental analysis)","End-to-end geospatial code generation from natural language requirements, including requirement analysis, algorithm design, code implementation, debugging, and annotation","Multiple: GPT-4, GPT-4-turbo, Claude-3-Opus, ERNIE-4.0, LLaMA3-70B, PaLM-540B, BLOOM-176B, CodeGemma-7B, StarCoder 2-15B, CodeQwen-14B, WizardCoder-15B, Code Llama-13B, OctoCoder-15.5B, CodeGeeX2-6B, CodeT5+-16B, CodeGen-16.1B, CodeX-12B",no,No,hybrid,,,"Instruction + Descriptive + Iterative (multi-stage prompts for requirement analysis, algorithm design, code generation, debugging, and annotation)",yes,Chain of Programming (CoP) framework,no,GeoCode-Eval benchmark,no,"Matchability, Executability, Accuracy, Readability (expert rating)","Controlled experiment (quantitative evaluation on benchmark), ablation study, comparative analysis, case study","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,1,0,1,0,0,0,"concept/prototype, barriers highlighted",Manual expert feedback required; knowledge base and information pool compatibility with diverse data sources/platforms needs improvement; automation of feedback suggested for future work
109,Interaction Design with Generative AI: An Empirical Study of Emerging Strategies Across the Four Phases of Design,"Muehlhaus, Marie; Steimle, Jürgen",2024,arXiv,10.48550/arXiv.2411.02662,http://arxiv.org/abs/2411.02662,preprint,interaction design with generative ai: an empirical study of emerging strategies across the four phases of design,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,1,,"Interaction design for VR haptics (general domain, with a focus on VR gaming and haptic devices)","Personas and scenario generation, conceptual design assessment, component selection, experiment design and review","GPT-4 (via Bing Chat/Copilot), DALL-E3 for images",No,No,Standalone,"Zero-shot, few-shot, iterative prompting, meta-prompting, role-based prompting","Zero-shot, few-shot, iterative","Instruction, Instruction + Descriptive, Persona, Iterative, Flipped interaction",yes,no,no,no,no,"Human evaluation (Likert scale: quality, detail, relevance)","User study (n=10 for design, n=7 for evaluation)","functional_suitability, usability",1,1,1,1,4,1,1,0,0,0,0,1,0,1,1,"concept/prototype, barriers highlighted","Limited to academic context, early adopters; not exhaustive prompting strategies; model limitations for technical/functional design"
110,Exploring Student Perspectives on Generative AI in Requirements Engineering Education,"Mellqvist, Nicklas; Mozelius, Peter",2024,Google Scholar,,https://urn.kb.se/resolve?urn=urn:nbn:se:miun:diva-53272,conferencePaper,exploring student perspectives on generative ai in requirements engineering education,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,,1,Higher education (requirements engineering education),"Student use of GenAI (ChatGPT) for generating, refining, and evaluating software requirements in educational workshops","ChatGPT (likely GPT-3.5 or GPT-4, not explicitly specified)",no,No,Standalone,"Iterative refinement, critical review, hybrid human+AI approach","Zero-shot, iterative prompting","Instruction, iterative refinement",no,no,no,no,no,"Descriptive statistics (mean, median, std dev), Thematic analysis (qualitative)","Workshops, mixed-methods (qualitative thematic analysis, quantitative survey)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,1,0,0,0,0,1,0,0,0,concept/prototype (educational workshops),Small and heterogeneous sample size; need for larger and more diverse follow-up studies
111,Exploring Multi-Label Data Augmentation for LLM Fine-Tuning and Inference in Requirements Engineering: A Study with Domain Expert Evaluation,"Liu, Hanyue; García, Marina Bueno; Korkakakis, Nikolaos",2024,Google Scholar,10.1109/ICMLA61862.2024.00064,https://ieeexplore.ieee.org/abstract/document/10903507,conferencePaper,exploring multi-label data augmentation for llm fine-tuning and inference in requirements engineering: a study with domain expert evaluation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,Automotive industry (Volvo Cars); technical requirements and test case specification generation,Multi-label data augmentation for generating test case specifications (TCSs) from requirements; evaluation of LLMs as judges,"Llama-2-7b-chat-hf (fine-tuned); Llama-3-70B-Instruct, Qwen2-72B-Instruct, Mixtral-8x7B-Instruct-v0.1 (for evaluation)",Yes,No,Standalone,"Fine-tuning, data augmentation, zero-shot prompting for prompt design",Zero-shot (prompt design and evaluation),Instruction + Descriptive (custom prompt formatter for TCS generation),yes,no,no,"Proprietary Volvo Cars requirements dataset (Dataset 0, 1, 2)",no,"BLEU, ROUGE, BERTScore, Human expert evaluation (completeness, correctness, relevance, repetition, terminology, overall quality)","Controlled experiment, expert study, LLM-based evaluation","functional_suitability, usability, reliability",1,1,1,1,4,1,0,1,0,0,0,0,0,0,0,"concept/prototype (industrial dataset, not in production)",Only one LLM fine-tuned; limited expert evaluation; LLM-as-judge bias; proprietary data
112,ReqGenie: GPT-Powered Conversational-AI for Requirements Elicitation,"Fotrousi, Farnaz; Tavantzis, Theocharis",2025,Google Scholar,10.1007/978-3-031-78386-9_25,,conferencePaper,reqgenie: gpt-powered conversational-ai for requirements elicitation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,,,,General software products,Interview-based requirements elicitation,Custom GPT based on GPT-4 ,No,No,Standalone conversational agent, iterative prompt refinement ,Few-shot / iterative prompt,"Instruction-based, iterative, structured prompt",Yes,ReqGenie,yes,Virtual Clinic/Campus Recruitment System from Github project,yes,"Completeness,Consistency ",Case study / expert evaluation ,"functional_suitability, usability, reliability,performance_efficiency",1,1,0.5,1,3.5,1,0,1,0,0,1,1,1,1,0,Prototype,"Limited domain generalization, reliance on user input, challenges with large-scale systems."
113,Service-Oriented Requirements Elicitation Through Systematic Questionnaire Design: A Problem-Driven GenAI Approach,"Rauer, Julie; Pham, To Kim Bao; Supakkul, Sam; Hill, Tom; Chung, Lawrence",2025,Google Scholar,10.1007/978-981-96-0805-8_17,,conferencePaper,service-oriented requirements elicitation through systematic questionnaire design: a problem-driven genai approach,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,,,Assistive Technology ,Requirements elicitation questionnaire design,ChatGPT 4.0,No,No,Standalone approach,No,zero-shot/few-shot,Instruction + Question,Yes,No,Partially,Experiment S  & Experiment T,Partially,Human evaluation,Controlled experiment with two groups,"Functional suitability, usability",1,1,0.5,1,3.5,0,0,0,1,1,0,1,1,1,0,Concept/prototype,"GenAI struggles with non-functional requirements
Lacks contextual sensitivity & domain-specific reasoning."
114,Work in Progress: AI-Powered Engineering-Bridging Theory and Practice,O. Levy; I. Dikman; N. Levy; M. Winokur,2025,IEEE Xplore,10.1109/EDUNINE62377.2025.10981330,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981330,Work in Progress: AI-Powered Engineering-Bridging Theory and Practice,work in progress: ai-powered engineering-bridging theory and practice,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,"Systems engineering (focus on medical equipment management, general systems engineering)","Classification of requirements (functional vs. non-functional), quality assessment of requirements (INCOSE criteria), automated test case generation","GPT-4, Claude Sonnet, Llama",No,No,Standalone,"zero-shot, few-shot (implied by use of LLMs for classification and explanation)","zero-shot, few-shot",Instruction + Descriptive,no,no,no,DR TOOL project requirements dataset,no,"Cohen’s Kappa, qualitative comparison",Controlled experiment (comparison with expert panel),"functional_suitability, reliability, usability",1,1,0.5,1,3.5,0,1,0,0,0,0,1,0,0,0,"concept/prototype, discussed potential, barriers highlighted","AI hallucinations, contextual misunderstandings, lack of domain-specific optimization"
115,Generating and Verifying Synthetic Datasets with Requirements Engineering,L. Vonderhaar; T. Elvira; O. Ochoa,2025,IEEE Xplore,10.1109/CAIN66642.2025.00032,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030042,Generating and Verifying Synthetic Datasets with Requirements Engineering,generating and verifying synthetic datasets with requirements engineering,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,,1,1,,General domain; synthetic image dataset generation for ML model training and verification,Generating synthetic image datasets using requirement specifications as prompts; verifying generated images against requirements using object detection and manual review,FLUX.1-schnell (diffusion model),No,No,Standalone,,,Instruction + Descriptive,yes,no,no,"SyntheticDataVerification (custom synthetic dataset, see GitHub)",yes,"Pass/fail per requirement specification (manual and YOLOv8-based), Passing percentage",Controlled experiment (systematic generation and verification of 1000 images),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,1,1,0,0,1,1,0,0,concept/prototype,"Diffusion model limitations (e.g., inability to generate certain image types); YOLOv8 class confusion; prompt/specification mismatch; only object/count/location specs tested"
116,Exploring Large Language Models for Requirements on String Values,A. A. Babikian; B. Chen; G. Mussbacher,2025,IEEE Xplore,10.1109/MO2RE66661.2025.00009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028238,Exploring Large Language Models for Requirements on String Values,exploring large language models for requirements on string values,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,,1,1,,General domain (requirements engineering for string constraints in BDD scenarios),"Generation of realistic, constraint-satisfying string values and detection of constraint inconsistencies for requirements expressed in natural language (BDD)","GPT-4o, GPT-4o-mini, Llama3.1-8b",No,No,Standalone and hybrid (LLM + solver),,,Instruction + Descriptive + Iterative (with JSON output format),yes,no,no,"Custom dataset from undergraduate SE course (6 string types, 192 scenarios)",yes,"Generation Success Rate (GSR), Recall (UNSAT-R), Precision (UNSAT-P)","Controlled experiment (comparative evaluation with solvers and LLMs, multiple runs for LLMs)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,1,0,1,0,1,0,0,1,0,0,"concept/prototype, barriers highlighted",Manual translation of requirements to constraints may introduce bias; dataset from educational context may limit generalizability
117,Architecture Exploration and Reflection Meet LLM-based Agents,J. A. Diaz-Pace; A. Tommasel; R. Capilla; Y. E. Ramírez,2025,IEEE Xplore,10.1109/ICSA-C65153.2025.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014919,Architecture Exploration and Reflection Meet LLM-based Agents,architecture exploration and reflection meet llm-based agents,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,"Software architecture design (general domain, with case study in mobility application)",Exploration and evaluation of architectural patterns and tactics for given requirements using LLM-based agents,GPT-4o-mini (via LlamaIndex),No,No,Hybrid (ReAct and LATS agent frameworks with tool orchestration),"Reflection, tree-of-thought, multi-step reasoning, LLM-as-a-judge","Zero-shot, few-shot (prompting with domain-specific instructions)",Instruction + Descriptive + Reflection,Yes,ReArch,Yes (GitHub repository),CampusBike case study (from prior work),No,"Correctness, Completeness, Degree of requirement satisfaction (LLM-as-a-judge)",Case study (comparison with original architecture),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,0.5,1,3.5,0,0,0,0,0,0,1,0,0,0,concept/prototype,"Duplicate patterns, hallucinations, lack of real-world validation, overly general recommendations"
118,LLM-Based Safety Case Generation for Baidu Apollo: Are We there Yet?,O. Odu; A. B. Belle; S. Wang,2025,IEEE Xplore,10.1109/CAIN66642.2025.00033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030020,LLM-Based Safety Case Generation for Baidu Apollo: Are We there Yet?,llm-based safety case generation for baidu apollo: are we there yet?,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,"Automotive domain, specifically autonomous driving systems (Baidu Apollo)",Automatic generation of safety (assurance) cases for the ML-enabled trajectory prediction component in an autonomous driving system,GPT-4o,No,No,Standalone,,,Instruction + Descriptive + Example (CoT),yes,no,no,"Safety case for Baidu Apollo, ACP and derived assurance case for DeepMind system",yes,"Exact Match, BLEU Score, Semantic Similarity (Cosine Similarity)",Controlled experiment (comparison of LLM-generated vs. manually created safety cases),"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,1,0,0,0,"concept/prototype (case study, not in production)",Single case study (Baidu Apollo); LLM-generated safety case not reviewed by original system developers; generalizability limited
119,A Smart Framework for Optimizing User Feedback Prioritization in Application Development,N. Almoqren; M. Alrashoud,2025,IEEE Xplore,10.1109/ITIKD63574.2025.11004934,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004934,A Smart Framework for Optimizing User Feedback Prioritization in Application Development,a smart framework for optimizing user feedback prioritization in application development,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,,"Mobile application development, specifically user feedback from app reviews","Automated extraction, classification, and prioritization of requirements from user reviews using GenAI, active learning, and ontologies",N/A,No,No,Hybrid,"Active learning, ontology-based retrieval, LLM-based extraction/classification, optimization algorithms","Zero-shot, few-shot, in-context learning (ICL)",Instruction + Descriptive,no,no,no,no,no,,Conceptual framework (no empirical evaluation yet),"functional_suitability, usability, maintainability",1,0.5,0.5,1,3,0,0,0,0,1,0,0,0,0,0,concept,No empirical evaluation; framework is theoretical; future work to evaluate in real-world scenarios
120,Evaluating Multi-Modal LLMs for Automatically Recognizing Semantic Elements in UML Use Case Diagram Images,J. Hassine,2025,IEEE Xplore,10.1109/SANER64311.2025.00092,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992325,Evaluating Multi-Modal LLMs for Automatically Recognizing Semantic Elements in UML Use Case Diagram Images,evaluating multi-modal llms for automatically recognizing semantic elements in uml use case diagram images,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,1,,General domain (UML Use Case Diagrams in Requirements Engineering),"Automatic recognition and extraction of semantic elements (actors, use cases, boundaries, relationships) from UML Use Case Diagram images","GPT-4o, GPT-4o-mini",No,No,Standalone,Zero-shot,Zero-shot,Instruction,Yes,no,no,"New UCD image dataset (191 images, 94 UCDs)",Yes,"Precision, Recall, F1-score, F2-score, Correct count (for actors/use cases)",Controlled experiment (quantitative evaluation on annotated dataset),"functional_suitability, reliability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,concept,"Dataset sampling bias, manual labeling errors, vision limitations of GPT-4o/mini, lack of fine-tuning"
121,Generative Rules for More Creative Thinking About Requirements,N. Maiden,2025,IEEE Xplore,10.1109/MS.2025.3539819,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10953346,Generative Rules for More Creative Thinking About Requirements,generative rules for more creative thinking about requirements,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,,,,General requirements engineering across domains; focus on creative thinking in RE tasks,Augmenting creative thinking in requirements elicitation and analysis using generative AI; generating novel requirements and identifying unexpected stakeholders,ChatGPT-4o (GPT-4o),No,No,Standalone,Prompt engineering with generative rules (SCAMPER); no advanced techniques like RLHF or retrieval-augmentation,Zero-shot,Instruction + Descriptive (with generative rules),yes,no,no,no,no,,"N/A (experience-based column, not empirical study)","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,0,0.5,0.5,2,0,0,0,0,0,0,0,0,0,0,discussed potential,Lack of empirical evaluation; prompts do not incorporate advanced creative thinking knowledge by default
122,How Reliable Are GPT-4o and LLAMA3.3-70B in Classifying Natural Language Requirements?,F. Karlsson; P. Chatzipetrou; S. Gao; T. E. Havstorm,2025,IEEE Xplore,10.1109/MS.2025.3572561,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012694,How Reliable Are GPT-4o and LLAMA3.3-70B in Classifying Natural Language Requirements?,how reliable are gpt-4o and llama3.3-70b in classifying natural language requirements?,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,,,General software engineering (natural language requirements classification),Classification of natural language requirements (NLRs) into functional and non-functional requirements,"GPT-4o, LLAMA3.3-70B",No,No,Standalone,,,Instruction,yes,no,no,PROMISE NFR dataset,yes,"Precision, Recall, F1-score, Fleiss’ Kappa",Controlled experiment,"functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,0,0,0,0,1,0,0,concept,Did not investigate effect of prompt design variation; did not elaborate on reasons for misclassifications; did not evaluate impact of batch size.
123,Evaluating Large Language Models in Exercises of UML Use Case Diagrams Modeling,G. Garaccione; P. F. Vega Carrazan; R. Coppola; L. Ardito,2025,IEEE Xplore,10.1109/NLBSE66842.2025.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029431,Evaluating Large Language Models in Exercises of UML Use Case Diagrams Modeling,evaluating large language models in exercises of uml use case diagrams modeling,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,,,General software engineering education (UML Use Case Diagrams),Automatic generation of UML Use Case Diagrams from natural language requirements,ChatGPT-4,No,No,Standalone,one-shot,one-shot,Instruction,yes,no,no,"UML use case diagram exercises (17 exercises, available online)",yes,"Completeness Rate, Redundancy Rate",Controlled experiment (comparison with human solutions),functional_suitability,1,1,1,1,4,0,0,0,0,0,0,0,0,0,0,concept/prototype,"Limited sample size, single human solver, one-shot prompting, limited generalizability"
124,Rethinking Technological Investment and Cost-Benefit: A Software Requirements Dependency Extraction Case Study,G. Ginde; G. Ruhe; C. Saunders,2025,IEEE Xplore,10.1109/ACCESS.2025.3556313,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10945779,Rethinking Technological Investment and Cost-Benefit: A Software Requirements Dependency Extraction Case Study,rethinking technological investment and cost-benefit: a software requirements dependency extraction case study,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,,,,1,Software requirements dependency extraction (general software engineering domain),"Requirements dependency extraction/classification (REQUIRES, RELATES_TO) from textual requirements","BERT (fine-tuned, encoder-only LLM)",Yes,No,Standalone,fine-tuning (transfer learning),supervised (not zero/few/one-shot),N/A (BERT is not prompt-based),no,RDC-BERT (fine-tuned BERT for RDC),no,"Firefox, Typo3 (both open-source requirements datasets)",yes,"F1-score, F2-score, Precision, Recall, ROI (Return on Investment)",controlled experiment (empirical evaluation on two datasets),"functional_suitability, performance_efficiency, usability",1,1,1,1,4,1,1,0,1,1,0,0,1,0,0,"concept/prototype (proof of concept tool, not in production)",Hardware/computational costs not included; generalizability to other domains/LLMs not tested; multiple runs for finer metrics suggested; responsible AI trade-offs discussed as future work.
125,Leveraging LLMs to Automate Software Architecture Design from Informal Specifications,A. Tagliaferro; S. Corboe; B. Guindani,2025,IEEE Xplore,10.1109/ICSA-C65153.2025.00049,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014997,Leveraging LLMs to Automate Software Architecture Design from Informal Specifications,leveraging llms to automate software architecture design from informal specifications,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,,,General domain (software architecture design from informal specifications),Automated generation of UML component diagrams from informal natural language software specifications,GPT-4o (December 2024 version),No,No,Standalone,"In-context learning, prompt engineering",Few-shot,Instruction + Example,yes,no,no,Proprietary exam traces from Politecnico di Milano,no,"Syntactic correctness (isConn, illConn, compWithMeth), Semantic correctness (specMissComp, specMissInt, domMissComp, domMissInt, specMissMeth, misplMeth, domMissMeth), Complexity (Δcomp, Δint, Δconn, ΔmaxReqInt, ΔmaxExpInt, ΔprimComp, ΔprimInt)",Controlled experiment (comparison with expert-drawn ground truth diagrams),"functional_suitability, usability",1,1,1,1,4,0,0,0,0,0,0,1,0,0,0,concept/prototype,"Oversimplification, missing implicit/domain-specific elements, limited scalability, non-determinism"
126,"Assessing Compliance of Software System Designs to Laws, Regulations, and their Underlying Values",A. Marczak-Czajka; K. Dearstyne; J. Cleland-Huang,2025,IEEE Xplore,10.1109/Designing66910.2025.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029552,"Assessing Compliance of Software System Designs to Laws, Regulations, and their Underlying Values","assessing compliance of software system designs to laws, regulations, and their underlying values",New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,1,1,1,1,,"Safety-critical systems (e.g., baby monitors, multi-vehicle autonomous Uncrewed Aerial Systems) with a focus on legal and societal value compliance","Mapping requirements and design decisions to laws, regulations, and societal values; compliance assessment",GPT-4.0,No,No,Standalone,"Zero-shot, prompt engineering, interactive querying",Zero-shot,"Instruction, scenario-based, mapping, classification",yes,Accountable Design Assistant (ADA),No,No,No,"Qualitative assessment (focus group feedback, case study analysis)","Case study, focus group","functional_suitability, usability",1,1,1,1,4,0,1,1,0,0,0,0,0,0,0,"concept/prototype, barriers highlighted","Limited real-world validation, participants did not interact directly with the tool, values engagement not deeply assessed, generalizability limited by case study scope"
127,"Can GPT-4 Aid in Detecting Ambiguities, Inconsistencies, and Incompleteness in Requirements Analysis? A Comprehensive Case Study","Mahbub, T; Dghaym, D; Shankarnarayanan, A; Syed, T; Shapsough, S; Zualkernan, I",2024,Web of Science,10.1109/ACCESS.2024.3464242,http://dx.doi.org/10.1109/ACCESS.2024.3464242,J,"can gpt-4 aid in detecting ambiguities, inconsistencies, and incompleteness in requirements analysis? a comprehensive case study",New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,1,,"Healthcare (mechanical lung ventilator, industrial SRS)","Detection of ambiguities, inconsistencies, and incompleteness in requirements analysis; technical question answering from SRS; defect detection across SRS versions",GPT-4 Turbo (and GPT-4 Vision for figures),No,No,Standalone,,,"Instructional, section-specific, and question-answering",yes,no,no,MLV SRS (Mechanical Lung Ventilator) from ABZ 2024; custom QA dataset from GitHub issues,yes,"Precision, Severity rating (1-5), Recall (for versioning and expert comparison), Human expert qualitative analysis","Case study, expert study, comparison with formal modeling, QA dataset validation","functional_suitability, usability, reliability",1,1,1,1,4,0,0,1,1,1,0,1,1,0,0,concept/prototype; barriers highlighted,"Limited domain/contextual understanding, inability to cross-reference, struggles with diagrams, verbose answers, not a replacement for formal modeling"
128,Prompting GPT-4 to support automatic safety case generation,"Sivakumar, M; Belle, AB; Shan, JJ; Shahandashti, KK",2024,Web of Science,10.1016/j.eswa.2024.124653,http://dx.doi.org/10.1016/j.eswa.2024.124653,J,prompting gpt-4 to support automatic safety case generation,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,1,1,,"Safety-critical systems (automotive, healthcare, energy); focus on safety case generation for X-ray systems, ML-enabled tire noise recognition, and lane management systems",Automatic generation of safety cases using GSN (Goal Structuring Notation) with LLMs; evaluation of LLM's ability to generate structurally and semantically correct safety arguments,GPT-4,No,No,Standalone,,,Instruction + Descriptive + Example (varies by experiment),yes,no,no,no,no,"Structural and lexical similarity (manual rating), Cosine similarity (semantic similarity, automated), Reasonability (manual rating), Kendall's Tau (inter-rater agreement)",Controlled experiment with multiple runs and human expert evaluation,"functional_suitability, usability, reliability",1,1,1,1,4,0,0,0,0,0,0,1,1,0,0,concept/prototype,Non-determinism of LLM outputs; dependency on prompt design; limited by information in reference cases; human intervention still required for high-stakes use
129,Collision risk prediction and takeover requirements assessment based on radar-video integrated sensors data: A system framework based on LLM,"Liu, QC; Yu, RH; Cai, YF; Yuan, Q; Wei, HL; Lv, C",2025,Web of Science,10.1016/j.aap.2025.108041,http://dx.doi.org/10.1016/j.aap.2025.108041,J,collision risk prediction and takeover requirements assessment based on radar-video integrated sensors data: a system framework based on llm,New,FALSE,FALSE,Analyze now,Yijun,,Yes,F,,1,,1,,"Automotive (autonomous driving, road safety)",Collision risk prediction and takeover requirements assessment using radar-video integrated sensors data,LLaMA3-8B-Instruct,Yes,No,Standalone,"Reasoning chain, error detection and correction, LoRA parameter-efficient fine-tuning",Few-shot (two-stage fine-tuning with domain/task data),Instruction + Descriptive + Iterative (reasoning chain),yes,CPTR-LLM,no,Proprietary radar-video integrated sensors dataset (Jiangsu University campus),no,"Accuracy, Precision, Recall, Human evaluation (reliability, consistency), Robustness (CS-ARDL, AMG)","Controlled experiment, ablation study, empirical analysis, robustness check","functional_suitability, reliability, performance_efficiency, usability",1,1,1,1,4,0,0,0,1,1,1,1,0,0,0,"concept/prototype, practical application potential discussed, barriers highlighted",No driver-related data; sensor/environmental limitations; lack of complex real-world samples; hallucination risk; not intended to replace human decision-making
Old (2019-2024.10),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Could a Large Language Model Contribute Significantly to Requirements Analysis?,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197103918&doi=10.1007%2f978-3-031-61007-3_19&partnerID=40&md5=406d6ed33ca28a57f26ece1e2e6318a9,,,,,,,,,YES,F,,1,,,,General organizational systems ,System Structure Analysis and Requirement Situation Analysi,ChatGPT-4,NO,-,Standalone use (ChatGPT-4 used directly with manually designed prompts; no retrieval augmentation or hybrid agents).,,-,Instruction，Iterative,YES,No,No,"proprietary case studies (ride-hailing, BCMA, Amazon warehouses).",Partially,"Qualitative assessment (human interpretation of usefulness, coherence, and relevance)",Quasi-experiment and case study,"Functional Suitability, relialibity",1,1,0.5,1,3.5,no,no,no,no,no,no,YES,YES,no,no,Only conceptual,"Lack of common-sense reasoning
Recommendations often impractical or irrelevant"
2,Engineering Safety Requirements for Autonomous Driving with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198180648&doi=10.1109%2fRE59067.2024.00029&partnerID=40&md5=317ea27f5761c7c9bb14ff4451102c7f,,,,,,,,,YES,F,,,,1,1,"Automotive domain, specifically autonomous driving safety requirements engineering",Engineering safety requirements,GPT-4,No,-,Standalone pipeline (Python script orchestrating LLM API calls for each subtask),"Few-shot learning, rule-based hybridization, prompt engineering, redundancy detection, retrieval-augmented generation (RAG) discussed",FS,Instuction and Iterative,Yes,"no (prototype pipeline, not named)",no,"no (uses company-internal and public scenarios, not a named dataset)",no,"Expert review checklist (ISO 26262 criteria), qualitative feedback, average expert scores (Likert scale)","Expert study, case study, iterative design science cycles",Reliability，Security,1,1,1,0.5,3.5,no,YES,no,YES,YES,no,YES,YES,YES,no,"concept/prototype, evaluated in pilot with industry experts, not in production","LLM hallucinations, lack of systematic completeness in scenario identification, need for human-in-the-loop, not yet suitable for full automation, domain adaptation challenges"
3,Automated requirement contradiction detection through formal logic and LLMs,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195535591&doi=10.1007%2fs10515-024-00452-x&partnerID=40&md5=38f7fd3126f46b82b1f306541ac340e1,,,,,,,,,YES,F,,1,,1,,Automotive and related engineering domains; general formal requirements in controlled natural language,Contradiction detection between requirement pairs,GPT-3,NO,temperature:0,Hybrid,,FS COT,"Question, Instruction",Yes,ALICE (Automated Logic for Identifying Contradictions in Engineering),no,"Dataset 1 (reference, available), Dataset 2 (anonymized, partially available), Dataset 3 (anonymized, partially available)",yes,"accuracy, recall, precision, confusion matrix, human expert validation",Controlled experiment with real-world and synthetic datasets; expert validation,"Reliability,Functional Suitability, Compatibility，Performance Efficiency",1,1,1,1,4,NO,NO,no,YES,Computational,NO,no,YES,no,no,concept/prototype; integration into product development discussed; barriers and future work highlighted,"LLM and formal logic limitations, dataset size, generalizability to non-formal requirements, language ambiguity, passive constructions, neologisms, and technical writing style."
4,Model Generation with LLMs: From Requirements to UML Sequence Diagrams,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203104651&doi=10.1109%2fREW61692.2024.00044&partnerID=40&md5=aa4d86c40139c05c35b7a2bf861fcb65,,,,,,,,,YES,F,,,1,,,"General domain (multiple domains: cyber-physical, healthcare, e-commerce, gaming, etc.)",Requirements to UML sequence diagram transformation,ChatGPT,NO,-,Standalone,zero-shot,-,instruction，Iterative,Yes,no,no,"PURE, Ten Lockheed Martin Cyber-Physical Challenges, user story dataset (Dalpiaz & Sturm 2020)",yes,"completeness, correctness, adherence to standard, understandability, terminological alignment","Expert study (qualitative and quantitative evaluation by experienced annotators, thematic analysis)",Functional Suitability，Reliability，Performance Efficiency,1,1,1,1,4,no,No,NO,YES,NO,no,YES,no,YES,no,"concept/prototype, discussed potential, barriers highlighted","Lack of domain/contextual knowledge, memory-induced hallucinations, ignored requirements modifications, variability of output, subjectivity in evaluation"
5,ReqCompletion: Domain-Enhanced Automatic Completion for Software Requirements,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202750940&doi=10.1109%2fRE59067.2024.00023&partnerID=40&md5=0a64a29adbf00d6f0ea32078e15e2e6f,,,,,,,,,YES,F,,,1,,,"software requirements (general domain, with UAV and Building Automation System as examples)",Context-aware requirement writing,GPT-2,YES,-,Standalone,"knowledge-injection, pointer network, knowledge distillation",-,-,Yes,ReqCompletion (and DistilReqCompletion),no,"Dronology UAV requirements, BAS Standard Specification",yes,"Recall@1, Recall@3, Recall@5, Recall@7, ROUGE (user study)","controlled experiment, ablation study, small user study","Functional Suitability,Performance Efficiency,Interaction Capability",1,1,1,1,4,no,No,NO,NO,NO,YES,no,no,no,no,"concept/prototype, small user study, barriers highlighted","Only single-token completion, requires domain ontologies, limited user study, only two domains evaluated"
6,Generating Test Scenarios from NL Requirements Using Retrieval-Augmented LLMs: An Industrial Study,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202782130&doi=10.1109%2fRE59067.2024.00031&partnerID=40&md5=270d40e949bba76cb02755d0c136ffcb,,,,,,,,,YES,F,,,,1,,"Logistics (postal/delivery software, Austrian Post)",Test Scenario Generation,GPT-3.5,No,temperature:0,Retrieval-augmented (RAG),"Few-shot and zero-shot prompting, context retrieval via vector DB, chunking, glossary terms for domain adaptation",FS，ZS,Instruction,Yes,RAGTAG,no,"Proprietary industrial requirements and test scenarios from Austrian Post (ProjA, ProjB)",no,"BLEU, ROUGE, METEOR, Expert human evaluation (Likert scale: relevance, coverage, correctness, coherence, feasibility)",Controlled experiment (quantitative metrics) and expert user study (interview survey),"Functional Suitability, Reliability, ",1,1,1,1,4,no,No,NO,NO,NO,NO,YES,no,no,no,"concept/prototype, positive expert feedback, ready for adoption in context, not yet in production","Domain-specific knowledge gaps, bilingual requirements, need for human-in-the-loop for correctness, input data quality, lack of architectural/system context, no open-source tool or dataset"
7,Probing with Precision: Probing Question Generation for Architectural Information Elicitation,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202449923&doi=10.1145%2f3643666.3648577&partnerID=40&md5=acafcc84d8ceba7ee6483e45adbd3ee8,,,,,,,,,YES,F,1,,,,,Retrieval-augmented generation (RAG),,GPT-3.5-turbo,No,,Retrieval-augmented generation (RAG),,FS,Instruction,Yes,no,no,"PURE (PUblic REquirements) dataset, annotated subset for ASR",yes,"F2-score (ASR identification), accuracy (RAG module), human evaluation: relevance, seeking new information, usefulness, redundancy","Human expert study (software architects), automated metrics for ASR identification, qualitative human evaluation for PQs",Functional Suitability，Reliability，Performance Efficiency,1,1,1,1,4,no,No,NO,NO,no,no,no,YES,no,no,concept/prototype; future empirical studies planned,No standard automated metrics for PQ quality; LLM output variability; embedding model not fine-tuned on SRS
8,Assessing the Impact of GPT-4 Turbo in Generating Defeaters for Assurance Cases,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197284933&doi=10.1145%2f3650105.3652291&partnerID=40&md5=04cdab32f27799d68ede841be757cf94,,,,,,,,,YES,S,,,,1,,Standalone,"Chain-of-thought prompting, deterministic output via seed setting, expert review for validation",GPT-4 Turbo,No,-,Standalone,"Chain-of-thought prompting, deterministic output via seed setting, expert review for validation","FS, COT",Instruction,Yes,no,no,Custom set of 22 EA-based questions (available on GitHub),yes,"Expert rating (1-5 scale), Kendall rank correlation coefficient",Expert study (two independent raters),Functional Suitability，Reliability,1,1,1,1,4,no,No,NO,NO,no,no,no,YES,no,no,concept/prototype,Limited to preliminary evaluation (Phase I); semantic understanding less robust than structural/generation; future work needed for full pipeline and mitigation phase
9,Interlinking User Stories and GUI Prototyping: A Semi-Automatic LLM-Based Approach,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202735814&doi=10.1109%2fRE59067.2024.00045&partnerID=40&md5=3d10a9520bbfe8f01779c27f8828421c,,,,,,,,,YES,F,1,,,1,,"GUI prototyping for mobile applications (general domain, using Rico dataset)","Requirements realization detection, GUI component recommendation",GPT-4,No,temperature:0,"Standalone (not yet fully integrated, but designed for plugin integration in prototyping tools)","Zero-shot, few-shot, chain-of-thought prompting (in-context learning)","FS,ZS, COT",Instruction,Yes,no,no,Custom user story–GUI dataset based on Rico,yes,"Precision, Recall, F1-score, Accuracy",Controlled experiment (gold standard evaluation with annotated dataset),Interaction Capability， Reliability，Flexibility,1,1,1,1,4,no,No,NO,YES,no,no,YES,YES,no,no,"concept/prototype, not yet integrated; future integration planned, barriers discussed",Dataset limited to mobile GUIs and post-hoc user stories; not yet evaluated in real prototyping tools; recommendations not fully evaluated
10,Deriving Domain Models From User Stories: Human vs. Machines,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202714739&doi=10.1109%2fRE59067.2024.00014&partnerID=40&md5=6dd2268d836bcb322d3649953a1b2b11,,,,,,,,,YES,F,,1,,,,"general domain (user stories from various domains, e.g., Camperplus, Fish&Chips, Grocery, etc.)",Domain model extraction from user stories,GPT-4,No,-,Standalone,"Prompt engineering (structured, persona, context, reasoning, template)",ZS,Instruction,Yes,no,no,Benchmark dataset of 487 user stories and domain models (nine cases),Yes,"F0.5-score, F1-score, F2-score, precision, recall",Controlled experiment (comparison with human and other automated approaches),Functional Suitability，Performance Efficiency,1,1,1,1,4,no,No,NO,YES,no,no,no,YES,no,no,"concept/prototype, barriers highlighted",Performance varies by user story characteristics; LLM struggles with distinguishing classes vs. attributes; no hyperparameter optimization; limited to benchmark domains
11,Evaluating Generative Language Models with Prompt Engineering for Categorizing User Stories to its Sector Domains,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196834386&doi=10.1109%2fI2CT61223.2024.10544242&partnerID=40&md5=17098065a3814fb1c17cd702c9487e2f,,,,,,,,,YES,F,,1,,,,"Software development (Agile, smart home user stories)",User story domain classification,GPT-3.5-turbo，Llama-2-chat-hf,No,temperature:0,Standalone,"zero-shot, few-shot",ZS、FS,Instruction,Yes,no,no,Crowd-RE smart home requirements dataset,yes,"precision, recall, F1-score",controlled experiment (benchmarking on labeled dataset),Functional Suitability， Performance Efficiency,1,1,1,1,4,NO,NO,NO,YES,no,no,YES,YES,YES,no,concept/prototype,"Dataset labeling ambiguity, prompt design sensitivity, generalizability beyond user story classification"
12,Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187400144&doi=10.1145%2f3638247&partnerID=40&md5=37a4b47d9e8fefa20f0d887f69306946,,,,,,,,,YES,F,1,1,,,,General domain; no-code/low-code AI service development for various domains via visual programming and LLMs,Requirements  acquisition and analysis,GPT-3.5/4,YES,-,Standalone,LLM-powered co-pilots for requirement elicitation and task decomposition; block-based visual programming; prompt engineering,FS,Question，description,Yes,Prompt Sapper,yes,no,no,"time spent, correctness, usability scores (cognitive dimensions), Likert-scale user ratings","User study (controlled experiment, usability study)",Functional Suitabilit，Usability，Interaction Capability,1,1,1,1,4,no,no,no,YES,computational,no,no,YES,YES,YES,"concept/prototype, open-source, discussed potential, integration with other tools planned",Prompt testing is ad hoc; lacks systematic prompt evaluation; challenges in maintaining stability with fast LLM iteration; current tool does not support automated generation of control flow (if/while) in design view
13,Requirements are All You Need: From Requirements to Code with LLMs,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202706646&doi=10.1109%2fRE59067.2024.00049&partnerID=40&md5=2397641bfe4b4e34a2edb3ddda92010d,,,,,,,,,YES,F,,1,1,,,General domain; demonstrated on a university event scheduling system (SuperFrog Scheduler),Requirements Understanding and Functional Requirements Extraction,Software Engineer GPT,YES,-,Standalone,,FS,Instruction，iterative,Yes,Software Engineer GPT,yes,"SuperFrog Scheduler requirements (project glossary, vision/scope, use cases)",yes,"qualitative assessment (alignment with requirements, usability, accuracy)","case study (real-world project, stepwise demonstration)",Functional Suitability，Maintainability，Reliability,1,1,0.5,1,3.5,no,no,no,YES,no,no,YES,YES,YES,no,"concept/prototype, open-source, barriers highlighted (usability/UI)",Limited to one case study; no quantitative evaluation; UI/UX limitations of ChatGPT interface; not tested on real-time/AI/games; future work needed for broader applicability and user studies.
14,Structuring Natural Language Requirements with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203107747&doi=10.1109%2fREW61692.2024.00013&partnerID=40&md5=18502d182f23c7478fb9434510e9f1be,,,,,,,,,YES,S,,,1,,,"Aerospace (aircraft certification, space systems); general requirements engineering",Natural language requirements translation to structured formats,GPT-4,NO,temp 0,Standalone,one-shot prompting,OS,Instruction,Yes,no,no,"CS-25 (EASA), Herschel-Planck SRS (ESA)",no,BLEU,"Expert and non-expert annotation comparison (preliminary, not full user study)",Functional Suitability,0.5,0.5,0,1,2,no,no,no,no,no,no,no,YES,YES,no,concept/prototype,Dependency on expert annotation consistency; scalability to few-shot/zero-shot not yet tested
15,Normative Requirements Operationalization with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202749254&doi=10.1109%2fRE59067.2024.00022&partnerID=40&md5=34934c2a4957aa5054a569c726650feb,,,,,,,,,YES,F,1,,,1,,"General domain, with case studies in healthcare, robotics, autonomous vehicles, legal compliance, and more","Semantic relationship extraction, standardized demand analysis, demand verification",GPT-4,NO,-,Hybrid,"LLM-aided semantic relation extraction, logic-based filtering, stakeholder validation",FS,Instruction,Yes,RAINCOAT (with LLM-San module),yes,"Case studies from prior literature and new real-world cases (ALMI, ASPEN, AutoCar, BSN, DressAssist, CSI-Cobot, DAISY, DPA, SafeSCAD, Tabiat, Casper)",yes,"Number of relevant and spurious well-formedness issues identified, Stakeholder validation time, Comprehensiveness of requirements elicitation","Controlled experiment, case study, expert study (with non-technical stakeholders)",Functional Suitability，Reliability,1,1,0.5,1,3.5,no,YES,no,YES,no,no,YES,YES,YES,no,"concept/prototype, barriers highlighted (manual stakeholder validation required, not fully automated)",Manual validation of LLM outputs required; false positives in relation extraction; no automatic WFI resolution; limited to binary relations; only non-technical stakeholders evaluated
16,Quest-RE QUestion Generation and Exploration STrategy for Requirements Engineering,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203105440&doi=10.1109%2fREW61692.2024.00006&partnerID=40&md5=2672e6d4b43544922cb65c51790945a3,,,,,,,,,YES,F,1,1,1,,,General domain (demonstrated on app store platform and NASA X-38 Crew Return Vehicle),Requirements-related question generation,ChatGPT-4,NO,-,Standalone,zero-shot,-,Instruction,Yes,Tuple Manager (TM) / Quest-RE,no,"PURE dataset (NASA X-38 Crew Return Vehicle), hypothetical app store requirements",yes,Manual inspection of generated questions and tuples,"Illustrative examples, manual inspection","Functional Suitability,Reliability ,Interaction Capability",1,0.5,0.5,1,3,no,no,no,no,no,no,YES,YES,no,no,"concept/prototype, not in production",Does not address quality assurance of requirements in current scope; tool not publicly available; no quantitative evaluation
17,Can AI Help with the Formalization of Railway Cybersecurity Requirements?,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206976813&doi=10.1007%2f978-3-031-73709-1_12&partnerID=40&md5=55ce8966b30b976b5a53bd2bef8e220f,,,,,,,,,YES,F,,,1,,,Railway Cybersecurity,Natural language to CNL4DSA translation for railway cybersecurity requirements.,GPT-3.5，GPT-4,NO,-,Standalone experimental prompting,Iterative correction & teaching ,FS,Iterative,Yes,No,No,ERTMS L3 Signalling Requirements (R1–R5).,Semi-available,Qualitative human evaluation,case study / expert study ,Functional Suitability， Reliability，Interaction Capability,1,0.5,0.5,1,3,no,no,YES,YES,no,no,YES,YES,no,no,Proof-of-concept ,No open dataset or benchmark for others to replicate the study.
18,An Experiment in Retrofitting Competency Questions for Existing Ontologies,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195594103&doi=10.1145%2f3605098.3636053&partnerID=40&md5=53f9a5de78bb9f406e56b7d96ba294e8,,,,,,,,,YES,F,,,1,,,"Ontology engineering (general domain, with examples in video games, IoT, healthcare, astronomy)",Competency Questions Generation,GPT-3.5-turbo，GPT-4，LLaMA-2,NO,-,Standalone,,ZS,Instruction，description,Yes,RETROFIT-CQs,yes,"CORAL CQ repository, Video Game, VICINITY Core, Dem@care, Solar System Ontology",yes,"precision, recall, F1 score, human evaluation (developer validation)","controlled experiment, expert study (developer validation)",Functional Suitability，Reliability，Accuracy,1,1,1,1,4,no,no,no,YES,no,no,YES,YES,YES,no,concept/prototype,"Does not handle multi-hop questions, calculation/aggregation, or ambiguous/poorly-phrased CQs; only single-hop CQs generated; LLMs may generate questions not matching practitioner style."
19,ARCHCODE: Incorporating Software Requirements in Code Generation with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204448005&partnerID=40&md5=4297201f8bf1f4f11665c0f25a0f0fcb,,,,,,,,,YES,F,,,1,1,,"General domain (software code generation, public benchmarks: HumanEval, CodeContests)",Extracting Software Requirements from Textual Descriptions,GPT-3.5-Turbo，WizardCoder 7B，SantaCoder 1B,NO,temperature:0.8,Standalone (framework with LLM as core component),"In-context learning (ICL), code filtering, requirements-aware generation, parallel code and test case generation, plug-and-play NFR preference control",FS,Instruction,Yes,ARCHCODE,yes,"HumanEval-NFR, HumanEval, CodeContests, MultiPL-E (Java)",yes,"Pass@k (Pass@1, Pass@5, etc.), category-specific Pass@k for NFRs (time performance, robustness, maintainability, reliability), human validation of requirements and test cases","Controlled experiment (public benchmarks), human validation of requirements and test cases, ablation studies, case studies",Functional Suitability，Reliability，Maintainability,1,1,1,0.5,3.5,no,no,no,YES,Computational,no,YES,YES,YES,no,"concept/prototype, open-source, barriers highlighted (e.g., cascading errors, need for human intervention/self-correction)","Limited prompt engineering, limited to 3 FR and 4 NFR types, future work needed for more complex/varied requirements and evolving requirements, cascading error risk"
20,Leveraging Large Language Model ChatGPT for enhanced understanding of end-user emotions in social media feedbacks,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206451604&doi=10.1016%2fj.eswa.2024.125524&partnerID=40&md5=fdf7e93820b9309bd3f1f54653aa8878,,,,,,,,,YES,F,1,,,,,General domain (user feedback for low-rated software apps in Amazon Appstore),Emotion Classification,GPT-3.5 Turbo,no,-,Standalone (annotation and negotiation tool for dataset creation),"Zero-shot, negotiation (human-in-the-loop conflict resolution)",ZS,Instruction,Yes,No,No,Experimental-work-and-datasets (GitHub),Yes,"Accuracy, Precision, Recall, F1-score, Cohen's kappa, Human agreement","Controlled experiment (manual vs. ChatGPT annotation, DL classifier evaluation)","Functional Suitability,Performance Efficiency,Reliability:",1,1,1,0.5,3.5,YES,no,no,YES,YES,no,YES,YES,YES,no,"concept/prototype, discussed potential, barriers highlighted","Limited to Amazon Appstore, review-level annotation, potential annotation ambiguity, need for further human validation, multi-label and sentence-level classification not addressed"
21,LLM-based user requirement analysis and intelligent Q&A toward Chang'an Twelve Hours,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205777312&doi=10.1109%2fCoST64302.2024.00038&partnerID=40&md5=6ed5e409feff889f27c5c5240214a173,,,,,,,,,YES,F,1,1,1,,,Cultural tourism (Chang'an Twelve Hours Scenic Area),user requirement refinement for tourism domain Q&A,m3e-base，LLM(no mentioned specific model),NO,-,Retrieval-augmented generation (RAG),"User attribute-based prompt engineering, vector database retrieval, context-enriched prompting",FS,Description and Question,Yes,"No (prototype system, not named)",no,Proprietary (Chang'an Twelve Hours vector database),no,"Qualitative comparison (specificity, relevance, user satisfaction)",Case study / comparative experiment (Table I & II),Functional Suitability，Reliability， Performance Efficiency,1,1,1,0.5,3.5,no,no,no,no,no,YES,YES,no,no,no,concept/prototype,"No explicit discussion of generalizability, scalability, or user study limitations"
22,Requirements Engineering Using Generative AI: Prompts and Prompting Patterns,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197030582&doi=10.1007%2f978-3-031-55642-5_5&partnerID=40&md5=6a84dc502bdf787ebc14798fab0169e5,,,,,,,,,YES,F,,1,,,,General domain (requirements engineering tasks: classification and traceability),,GPT-3.5 turbo,NO,,Standalone,"Prompt pattern-based, zero-shot, few-shot, chain-of-thought (patterns include Cognitive Verifier, Context Manager, Persona, Question Refinement, Template)",ZS FS COT,Instruction,Yes,No,No,"PROMISE (for classification), PURE (for traceability)",Yes,"precision, recall, accuracy, F-score, standard deviation",Controlled experiment,Functional Suitability，Reliability,1,1,1,0.5,3.5,no,YES,no,no,no,no,no,YES,YES,no,concept/prototype,Limited to two RE tasks; generalizability to other RE tasks not established; did not analyze prompt wording effects; human oversight recommended
23,Boosting LLM-Based Software Generation by Aligning Code with Requirements,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203104501&doi=10.1109%2fREW61692.2024.00045&partnerID=40&md5=4729a8a0b885ae8c97f3c5962c50d28c,,,,,,,,,YES,F,,,1,1,,"General domain; demonstrated on event-driven systems (e.g., railway crossing), generic event-driven systems, and frame story systems.",Requirements-to-code generation with behavioral programming paradigm,GPT-4-turbo,No,-,Standalone,,ZS,Instruction,Yes,BPpy,yes,"Custom set of 20 system specifications (10 generic, 10 frame story); code and prompts available at https://github.com/bThink-BGU/Papers-2024-MoDRE-BP-LLM",yes,"requirement alignment (number of requirements correctly implemented), statistical significance (Bernoulli variable)",Controlled experiment (comparison of LLM-generated code with and without BP paradigm across 20 specifications),Functional Suitability、Maintainability、Reliability,1,1,0.5,0.5,3,no,no,no,YES,no,no,YES,YES,YES,no,concept/prototype; open-source tool and code available; not in production,Limited to initial evaluation; more extensive and rigorous experiments planned; only BPpy and Python tested; small sample size.
24,Utilizing Process Models in the Requirements Engineering Process Through Model2Text Transformation,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202725174&doi=10.1109%2fRE59067.2024.00028&partnerID=40&md5=5064411d1cc0d9ad6e1adead60b56c8f,,,,,,,,,YES,F,1,,,1,,"General domain; focus on process-oriented requirements engineering, applicable to any domain using business process models (e.g., BPMN)",Model-to-text transformation for process models,"GPT3，3.5，4
LLAMA",No,-,Standalone,"zero-shot, prompt engineering (instructional prompts)",ZS,Instruction,Yes,no,no,PET dataset (Process Extraction from Text),yes,"Flesch-Kincaid Grade Level (FKGL), Flesch Reading Ease (FRE), number of sentences, number of words, words per sentence, non-contextual text similarity (TS-NC), contextual text similarity (TS-C), model-to-text overlap (O-OM, O-OT), model-to-tasks overlap (O-OO, O-OG), number of generated texts containing references to modeling elements",Controlled experiment (quantitative evaluation on benchmark dataset),Functional Suitability，Reliability，Interaction Capability,1,1,0.5,0.5,3,no,no,no,YES,no,no,YES,YES,YES,no,"concept/prototype; barriers highlighted (e.g., hallucinations, lack of control, correctness not guaranteed)",Limited dataset/sample size; simple models; limited BPMN constructs; correctness of generated text not assessed; potential for LLM hallucinations and information loss/excess.
25,A Vision for Operationalising Diversity and Inclusion in AI,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201222036&doi=10.1145%2f3643691.3648587&partnerID=40&md5=273ca46cbcfd41dc9b06c0846a9febad,,,,,,,,,YES,F,1,,,,,"General domain, with case studies in border security (Global Entry Access system) and education (adaptive learning platform)",Persona-based requirements elicitation for diversity and inclusion,No specific,NO,-,Standalone (envisioned as a tool with LLM API backend),,-,Description,No,"no (framework and tool are proposed, not implemented or named)",no,"no (persona repository is proposed, not available)",no,,"N/A (vision paper, no empirical evaluation yet)",Functional Suitabilit，Reliability，Flexibility,1,1,0.5,1,3.5,no,no,no,YES,no,no,YES,YES,no,no,"concept/prototype (framework and tool are proposed, not implemented)","Risks of stereotype reinforcement, representativeness of personas, lack of empirical validation, resource constraints"
26,SimAC: simulating agile collaboration to generate acceptance criteria in user story elaboration,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196531915&doi=10.1007%2fs10515-024-00448-7&partnerID=40&md5=89a3749f146379ff321a3e64a896c71b,,,,,,,,,YES,F,,,1,,,"Agile software development (general domain, with examples from NSF website, university data repository, citizen science platform)",Acceptance criteria generation,gpt-3.5-turbo，OpenLLaMA,,temperature:1,Standalone,"Role-based, few-shot prompting, semantic deduplication, create-update-update collaboration simulation",FS,Instruction，Iterative,Available,SimAC,yes,"Dalpiaz et al. (2019) user story dataset (public), plus released gold standard for US-AC",yes,"INVEST (Independent, Negotiable, Valuable, Estimable, Small, Testable) human scoring (Likert scale), completeness, validity, Cohen's kappa (inter-rater agreement), t-test, Cohen's d","Expert/practitioner study, manual gold standard construction, controlled experiment (comparative, ablation, statistical analysis)",Functional Suitability ，Performance Efficiency，Interaction Capability,1,1,1,1,4,bias,no,no,YES,YES,no,YES,YES,no,YES,"concept/prototype, open-source, barriers highlighted (e.g., LLM limitations, context dependence)",Effectiveness limited by LLM size and vague user stories; gold standard subjectivity; limited model diversity; external validity (real-world context) discussed.
27,How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205563300&doi=10.1109%2fSSE62657.2024.00046&partnerID=40&md5=c80e8845dd20140068d380f172578c0a,,,,,,,,,YES,F,,1,1,,,"General domain (software engineering education, novice analysts)",,GPT-3.5， GPT-4,-,-,Standalone,"Zero-shot, prompt-based interaction",-,Instruction，Iterative,,no,no,Project reports from 45 undergraduate students (Order Processing System case study),no,"Correctness rate (per modeling element), Average score (per model type)",Case study (course-based experiment with 45 students),Functional Suitability，Usability,1,1,1,1,4,no,YES,no,YES,no,no,YES,YES,YES,no,"concept/prototype (educational setting, not production)","Small sample size, novice participants only, manual scoring subjectivity, randomness of LLM outputs"
28,Bringing Legacy Technical Data out of the Shadows Using Modern Digital Enginering Tools,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206798999&doi=10.1109%2fAUTOTESTCON47465.2024.10697525&partnerID=40&md5=e68bd50d1761ee56cf5c218702db9763,,,,,,,,,YES,F,,,1,,1,"Automated test systems for defense (USAF test platforms, e.g., CBATS, VDATS)",Legacy document to model conversion,"Claude
Gemini
Llama
Phi3",NO,-,hybrid,,FS,Instruction，Iterative,NO,TPSPro,no,no,no,"time reduction (qualitative), accuracy (qualitative, human review)","case study, demonstration (no formal controlled experiment)","Functional Suitability ，Performance Efficiency 
，Reliability",1,1,0.5,1,3.5,no,no,no,YES,YES,no,no,YES,YES,no,"concept/prototype (demonstrated in practice, not production)",Requires human verifier; results depend on prompt engineering and model selection; no quantitative evaluation
29,Code Gradients: Towards Automated Traceability of LLM-Generated Code,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202781451&doi=10.1109%2fRE59067.2024.00038&partnerID=40&md5=42326f2abe0852088b61167ac341ed3a,,,,,,,,,YES,F,,,,1,1,"General software engineering (code generation, traceability)",Requirement-focused code improvement,"WizardCoder 
CodeLlama ",NO,-,Standalone,"Gradient-based explainability, iterative reprompting, SmoothGrad",FS,Instruction,NO,no,no,HumanEval,yes,pass@1,controlled experiment,"Functional Suitability 
Performance Efficiency 
Reliability",1,1,1,1,4,no,no,security,YES,YES,no,no,no,no,no,concept/prototype,"Limited dataset size, not applicable to black-box LLM APIs, input size limitations, regressions possible, only preliminary results"
30,Prompting GPT –4 to support automatic safety case generation,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198553538&doi=10.1016%2fj.eswa.2024.124653&partnerID=40&md5=39f2ab52179a8f604e3651303daeb11d,,,,,,,,,YES,F,1,,1,,,"Safety-critical systems (X-ray, automotive, ML-enabled tire noise recognition, lane management system)",Safety case generation,GPT-4,NO,-,Standalone,"Zero-shot, one-shot (for some experiments), prompt-based",ZS,"Instruction, Question",YES,no,no,no,no,"Kendall’s Tau (inter-rater agreement), Average rater score (accuracy), Structural and lexical similarity (manual rating), Cosine similarity (semantic similarity), Reasonability (manual rating)",Controlled experiment with multiple runs and human expert evaluation,Safety,1,1,1,1,4,no,no,no,no,no,no,no,no,no,no,concept/prototype,"Non-determinism of LLM outputs, need for human-in-the-loop, limited to information in reference cases, no open datasets or tools, only structured prose (no graphical GSN output)"
31,GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202761080&doi=10.1109%2fRE59067.2024.00044&partnerID=40&md5=442491e71adf2f1c7ac508808cbadcb7,,,,,,,,,YES,S,1,,,,,Requirements engineering education (training for elicitation interviews),Elicitation interview script generation,GPT-4,NO,-,Retrieval-augmented (RAG-like) with custom knowledge base and prompt chaining,"Prompt chaining, retrieval-augmented generation, in-context learning",COT,Instruction,YES,no,no,"Generated interview scripts (S1-S4), knowledge base, prompt chains",yes,"GRUEN (linguistic quality: grammaticality, non-redundancy, focus, coherence), Expert judgment (naturalness, coherence, completeness, rubric-based)",Automated metric evaluation and expert study,All,1,0.5,0.5,1,3,no,no,no,YES,YES,no,no,no,YES,no,"concept/prototype (educational scripts, not deployed in production)","Limited depth in requirements discovery, lack of new requirement uncovering, some unnatural dialogue, ignoring other stakeholders"
32,Welcome your new ai teammate: On safety analysis by leashing large language models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196549893&doi=10.1145%2f3644815.3644953&partnerID=40&md5=039b33aa25bac9d659bf51fa40a199b1,,,,,,,,,YES,S,,1,,,,"Automotive (Autonomous Vehicles, Safety Engineering)",HARA generation,GPT-4,NO,-,Standalone,"Pipeline of engineered prompts, task decomposition, reflection, question refinement",COT,Instruction,NO,LLM-based HARA pipeline (Python implementation),yes,no,no,Expert review (internal team),"Feasibility study, internal expert review, iterative design",Safety,1,1,0.5,1,3.5,no,yes,no,no,no,no,yes,yes,yes,no,"concept/prototype, not in production, research phase only",No external/independent expert evaluation; not used in production; LLM cannot fully model system as human experts do
33,An integration methodology of safety and security requirements for autonomous vehicles,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204554153&doi=10.1080%2f19439962.2024.2400894&partnerID=40&md5=a1c6effa26033df1ea87720b90baa7bf,,,,,,,,,YES,F,,1,,,,,Classify security and safety requirement,"GPT-4o-2024-05-13, Gemini-1.5-Pro-API-0514, and Claude 3 Opus",NO,-,,,ZS,Instruction,NO,,,,,,,Safety and security,1,1,0.5,0.5,3,no,no,yes,yes,no,yes,no,yes,yes,no,,
34,Towards Taming Large Language Models with Prompt Templates for Legal GRL Modeling,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197138654&doi=10.1007%2f978-3-031-61007-3_17&partnerID=40&md5=c40481ae4c72500103c5c797d995d2f1,,,,,,,,,YES,F,,1,,,,Regulatory compliance (Healthcare & Energy),Analysis and summarization of legal requirements,GPT-3.5,NO,-,Standalone LLM,Meta Language Creation Pattern,ZS,Instruction,YES,No,No,"PHIPA & FIPPA (privacy laws)
Energy community laws",Legal texts public,"Precision & Recall, Manual scoring",Case study / controlled experiments,"Functional Suitability, Reliability",1,1,0.5,0.5,3,no,no,no,yes,no,no,yes,yes,yes,no,Proof-of-concept,Manual baseline comparisons – potential subjectivity.
35,Goal Model Extraction from User Stories Using Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204569883&doi=10.1007%2f978-3-031-70245-7_19&partnerID=40&md5=a0e7d21233053f24c4c16f7412524b49,,,,,,,,,YES,S,,,1,,,General domain,Model transformation,GPT-4,NO,-,Standalone LLM-assisted RE task,Iterative Prompting Strategy ,COT,Description,NO, jUCMNav (existing tool for GRL visualization),Yes,Ten GRL models from literature ,Yes,"Coverage score, Quality score",Controlled experiment ,Functional suitabilility,1,0.5,0.5,0,2,no,no,no,yes,no,no,yes,yes,yes,no,Concept/Prototype,Selected user stories may not reflect real-world diversity.
36,Evaluating OpenAI Large Language Models for Generating Logical Abstractions of Technical Requirements Documents,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206369494&doi=10.1109%2fQRS62785.2024.00032&partnerID=40&md5=225ec3cd4b732be9fdd12b3c48c7735e,,,,,,,,,YES,F,,,1,,,Railway technical systems (ERTMS and EIRENE); generalizable to technical requirements documents,Translation,"GPT-3.5, GPT-4",YES,-,Standalone,"zero-shot, few-shot (via prompt examples), fine-tuning, follow-up/correction loop",COT,"Instruction, description",NO,no,no,RailwayReq Corpus,yes,"plausibility score (consistency-based), stability score (repeatability of verdicts), syntactic validity (SAT/UNSAT/ERROR via ASP solver)",controlled experiment (systematic evaluation over multiple runs and configurations),Functional suitabilility,1,1,1,1,4,no,no,no,no,yes,no,yes,yes,yes,no,"concept/prototype; barriers highlighted (instability, non-determinism, lack of trust for production)",Limited to one technical domain; closed-source/proprietary models; prompt engineering subjectivity; fine-tuning on small sample; semantic correctness only approximated; non-determinism of LLMs
37,Interpretable App Review Classification with Transformers,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203106901&doi=10.1109%2fREW61692.2024.00009&partnerID=40&md5=08f04e45c249fd125148d0a71c6ee06a,,,,,,,,,YES,F,,1,,,,"App review classification for software requirements engineering (general domain, with examples from mobile apps)",Unclear,GPT-2,YES,-,Standalone,"Shapley value-based interpretability, semi-supervised learning, contextual justification generation",-,Unclear,Unclear,IARCT,yes,1679 labeled app reviews (Zenodo: https://doi.org/10.5281/zenodo.11108088),yes,"Precision, Recall, F1 score",controlled experiment (80:20 train-test split),All,1,1,1,1,4,yes,no,no,yes,yes,no,no,yes,yes,no,concept/prototype,"Subjectivity in Shapley value interpretation, limited dataset size, generalizability to other domains"
38,AI-Enabled Regulatory Change Analysis of Legal Requirements,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202771036&doi=10.1109%2fRE59067.2024.00012&partnerID=40&md5=aa95cb347088f90807f96f600f770090,,,,,,,,,YES,F,,1,,,1,Financial regulations (compliance in financial IT systems),Legal requirement updating,"GPT-3.5, GPT-4",NO,-,Standalone (LLM-powered assistant for human analysts),,"ZS, FS, COT","Instruction, description",YES,MURCIA,no,"Regulatory change dataset (AIFMD, AIFMR, MIFID II, MIFIR)",yes,"Precision, Recall, F1-score","Empirical evaluation (manual annotation, inter-rater agreement, accuracy comparison)","Functional Suitability, Reliability",1,1,1,1,4,no,no,no,yes,yes,no,no,yes,yes,yes,"concept/prototype, barriers highlighted","Granularity of legal interpretation, domain-specificity, implicit concept detection, need for human-in-the-loop"
39,Needs Companion: A Novel Approach to Continuous User Needs Sensing Using Virtual Agents and Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208564297&doi=10.3390%2fs24216814&partnerID=40&md5=725e2ce881800e8fbdd9a1794f62d3c8,,,,,,,,,YES,F,1,,,,,"General domain, focused on user service needs across domains such as YouTube, smart home, and SNSs",Requirements extraction and validation,GPT-3.5 Turbo,YES,Temperature = 0,Hybrid,"Few-shot prompting, re-extraction, clarification dialogue, static and dynamic prompt composition",FS,Instruction,Unclear,Needs Companion (with VA 'Mei'),no,Proprietary experiment dataset (user needs dialogues),no,"User confirmation rate (accuracy), G-Eval LLM-based score, Detection time, Survey (Likert scale)","Controlled experiment (5-week user study), baseline human interview comparison, post-experiment survey",All,1,1,1,1,4,yes,yes,yes,yes,yes,yes,no,yes,yes,no,"concept/prototype, barriers highlighted","Limited participant diversity, noise from speech recognition, need for improved reproducibility, not tested on elderly/children, need for multimodal input"
40,Generating Java code pairing with ChatGPT,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204472636&doi=10.1016%2fj.tcs.2024.114879&partnerID=40&md5=6c54a7736f489c9a0c43c29c9d7da28a,,,,,,,,,YES,F,1,1,1,,1,"General domain, demonstrated on a practical sales management system (building materials sales enterprise)",Generation,GPT-3.5,NO,-,Hybrid,,COT,"Instruction, description",YES,Xd-CodeGen,no,no,no,"Functional correctness (manual review, compile, unit test, interface test), Formal verification (runtime verification at code level using MSVL/PPTL)","Case study (real-world sales management system, ~20,000 LOC)",Functional suitabilility,1,1,1,1,4,no,no,no,no,yes,no,yes,no,yes,no,"concept/prototype, applied to real-world pilot project, not in production",Manual intervention required for prompt iteration and error correction; potential for code quality issues; consistency between model and code must be maintained manually
41,Local large language models to simplify requirement engineering documents in the automotive industry,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197682199&doi=10.1080%2f21693277.2024.2375296&partnerID=40&md5=a2cffb0ecc1376288e9141f80b7642df,,,,,,,,,YES,F,,,,,1,Automotive industry; requirements engineering for automotive suppliers and manufacturers,Information retrieval,"Nous-Hermes-13B-GPTQ, WizardLM-7B-Uncensored-GPTQ, Wizard-Vicuna-13B-Uncensored-GPTQ, guanaco-7B-GPTQ, orca_mini_v2_13b-GPTQ",,,retrieval-augmented,,ZS,Question,YES,Local GPT Q&A Retrieval solution (inspired by localGPT),no,"Proprietary set of 10 automotive requirements engineering documents (1,642 pages)",no,"Correctness, Relevance, Completeness, Clarity, Consistency",Comparative experiment with expert-based scoring (1-5 scale) on 7 domain-specific questions,Functional suitabilility,1,1,1,0.5,3.5,no,no,yes,no,yes,yes,yes,yes,yes,no,"concept/prototype; barriers highlighted (computational cost, domain complexity)",Limited handling of highly complex or domain-specific requirements; performance on less powerful hardware; not open source; no public dataset
42,Supporting High-Level to Low-Level Requirements Coverage Reviewing with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197388315&doi=10.1145%2f3643991.3644922&partnerID=40&md5=4f3b4413aa471799af4e56c29b022317,,,,,,,,,YES,F,,1,,1,,"Safety-critical systems (aerospace, healthcare), project management, web tools, general software systems",Coverage validation,"GPT-3.5, GPT-4",NO,-,Standalone,"zero-shot, zero-shot with explanation, chain-of-thought","ZS, FS, COT",Instruction,YES,no,no,"CM1, CCHIT, GANTT, IP, WARC (all from COEST or cited sources)",yes,"precision, recall, F1-score",controlled experiment (quantitative evaluation on benchmark datasets),Functional suitabilility,1,1,1,1,4,no,yes,no,yes,yes,no,yes,yes,no,no,"concept/prototype, discussed potential, barriers highlighted","Domain-specific knowledge gaps, sensitivity to prompt wording, generalizability to industry data, construct validity concerns"
43,Rethinking Legal Compliance Automation: Opportunities with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202744043&doi=10.1109%2fRE59067.2024.00051&partnerID=40&md5=97398405d2c10674b865e290ccca4c32,,,,,,,,,YES,F,,1,,,,Legal compliance automation for software-intensive systems (GDPR compliance in Data Processing Agreements),Legal compliance checker,"Phi-2, Mistral-7B, Mistral-7B-Instruct, Zephyr-7B, Mixtral-8x7B-Instruct-v0.1, gpt-3.5-turbo-0125, gpt-4-0125-preview",YES,-,Standalone,zero-shot,ZS,"Instruction, description",YES,no,no,DPA dataset from Amaral et al. (2023),yes,"Accuracy, Precision, Recall, F-score",Controlled experiment (zero-shot and fine-tuning evaluation on annotated DPA dataset),Functional suitabilility,1,1,0.5,1,3.5,no,yes,yes,yes,yes,yes,yes,yes,yes,no,barriers,Generalizability to other legal domains not established; optimal context span not determined; model bias not fully analyzed; continuous legal text evolution poses risks.
44,Combining Prompts with Examples to Enhance LLM-Based Requirement Elicitation,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204036758&doi=10.1109%2fCOMPSAC61105.2024.00181&partnerID=40&md5=1d98d75f0187009dd1622995d786de04,,,,,,,,,YES,S,1,,1,,,"Mobile app user reviews (App Store, Google Play) for requirements elicitation and goal modeling",Goal model generation,GPT-4,NO,-,Hybrid,"Few-shot, prompt with examples, LDA pre-clustering",FS,Question,YES,no,no,"Proprietary dataset of 1000 user reviews (Line, Google Docs, YouTube)",no,"Tree-Edit-Distance-based Similarity (TEDS), Precision, Recall",Controlled experiment (comparison with manual and existing automated methods),Functional suitabilility,1,1,1,1,4,no,no,no,yes,yes,no,yes,yes,yes,no,concept/prototype,"Instability of LLM outputs, word count limits, need for manual checking, lack of excessive refinement in hierarchical goal models"
45,Leveraging LLMs for the Quality Assurance of Software Requirements,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201565838&doi=10.1109%2fRE59067.2024.00046&partnerID=40&md5=e305b4ac27f83a3d6a285d4fa62a1e05,,,,,,,,,YES,F,,,,1,,"General domain (Stopwatch app, smart home)",Requirement quality validation,Llama 2,NO,-,Standalone,zero-shot,ZS,"Instruction, description",YES,no,no,"PURE (DigitalHome), synthetic Stopwatch requirements",yes,"Cohen’s Kappa, precision, recall, human evaluation (plausibility, improvement)",empirical user study,Functional suitabilility,1,1,1,1,4,no,no,no,yes,yes,yes,no,yes,yes,no,concept/prototype,"Limited to two projects (one synthetic, one real); only one LLM and prompt template tested; scalability to large/complex projects not addressed; token/context length limits; generalizability not established."
46,An LLM-based Approach to Recover Traceability Links between Security Requirements and Goal Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197433521&doi=10.1145%2f3661167.3661261&partnerID=40&md5=3b9b3ce8acfc3590039a45c858f1e3b4,,,,,,,,,YES,F,,,,,1,"Software security engineering for a Virtual Interior Designer application (general software, security-focused)",Goal to security requirement traceability recovery,GPT-3.5-turbo,NO,-,Standalone,Zero-shot,ZS,Instruction,YES,no,no,Virtual Interior Designer GRL model and requirements (proprietary/student-generated),no,"precision, recall, F1-score",controlled experiment (single-case evaluation),"Functional suitability, security",1,1,1,1,4,no,no,yes,yes,yes,yes,no,yes,yes,no,concept/prototype,"Single-case evaluation, limited scale, only TGRL language, prompt quality, model-specificity, uniform treatment of GRL constructs, potential for duplicate links, limited requirement diversity"
47,A framework for creating an IoT system specification with ChatGPT,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197645651&doi=10.1016%2fj.iot.2024.101218&partnerID=40&md5=3804719e738c978f2cbc9194913cfcfd,,,,,,,,,YES,F,1,,,,,"Internet of Things (IoT), specifically industrial/campus laboratory automation",Generation of IoT system requirements,GPT-3.5-turbo,NO,-,Standalone,"Iterative prompt chaining, context propagation","ZS, COT",Instruction,YES,no,no,no,no,"Expert survey (understandability, completeness, unambiguity, suitability, feasibility), Comparison to real implemented system","Expert study (survey of 40 IoT experts), case study (campus laboratory)",Functional suitability,1,1,1,1,4,no,yes,no,no,yes,yes,yes,no,yes,no,"concept/prototype, barriers highlighted","Token/context window limits, generality of ChatGPT (not domain-specific), need for stakeholder validation, integration challenges in regulated environments, only one use case tested"
48,Learning from Failures: Translation of Natural Language Requirements into Linear Temporal Logic with Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206388437&doi=10.1109%2fQRS62785.2024.00029&partnerID=40&md5=1f1d786585589a580091e7cb19f132ce,,,,,,,,,YES,F,,1,1,,,hardware verification (Arm AMBA AHB bus protocol),Requirement transformation,"GPT-3.5-Turbo, GPT-4, Gemini Pro ",NO,-,hybrid,"retrieval-augmented generation (RAG), in-context learning, interactive human-in-the-loop validation, model checker-guided search","FS, COT",Instruction,YES,SYNTHTL,yes,"AMBA AHB protocol NL/TL specifications (from prior work), example outputs",yes,"manual effort (inspections, edits), formula size (normalized), pruning rate, model checking speedup, culprit identification recall","case study, comparative evaluation with nl2spec baseline, quantitative analysis",Functional suitability,1,1,1,1,4,no,no,no,yes,yes,yes,yes,yes,yes,no,"concept/prototype, barriers highlighted","Scalability for very large search spaces, reliance on oracle (human) validation, ambiguity in NL, not all challenges (e.g., security, privacy) discussed."
49,"Can GPT-4 aid in detecting ambiguities, inconsistencies, and incompleteness in requirements analysis? A comprehensive case study.",,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204689412&doi=10.1109%2fACCESS.2024.3464242&partnerID=40&md5=2904125aca501b1457d0a7469526b2e4,,,,,,,,,YES,F,,,,1,,"Healthcare (mechanical lung ventilator, industrial SRS)","Ambiguity, inconsistency, and incompleteness validation",GPT-4,NO,-,Standalone,,ZS,Question,YES,no,no,"MLV SRS (Mechanical Lung Ventilator SRS, ABZ 2024 case study), custom QA dataset from GitHub issues",yes,"Precision (for ambiguity, inconsistency, completeness detection), Recall (for versioning and expert comparison), Severity rating (1-5), Human expert qualitative analysis, Answer accuracy (QA), Verbosity (QA), Reference citation (QA)","Case study, expert review, comparison with formal modeling, version tracking, QA dataset validation",Functional suitability,1,1,1,1,4,no,yes,yes,yes,yes,no,yes,yes,yes,no,"concept/prototype, barriers highlighted","Limited domain knowledge, inability to cross-reference globally, struggles with diagrams, verbose output, not a replacement for formal modeling"
50,Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202710161&doi=10.1109%2fRE59067.2024.00020&partnerID=40&md5=e8f5fc97032f5dadc3271b62a8a510fa,,,,,,,,,YES,F,,1,,,,"General software requirements engineering (multiple domains, including public datasets and real-world software systems)",,GPT-3.5,NO,-,Standalone,"Label verbalization, knowledge integration, entailment reformulation, binary classification",ZS FS,Instruction,,no,no,"Promise, new requirements defects dataset, new conflicts dataset, public conflict datasets (Library, Coffee Machine, ETCS)",yes,"Accuracy, Precision, Recall, F1-score","Controlled experiment (benchmarking on multiple datasets, cross-validation)",Functional Appropriateness，Reliability,1,1,1,1,4,no,no,no,YES,YES,no,YES,YES,no,no,"concept/prototype, discussed potential, barriers highlighted",NLI struggles with compositional conflicts (multi-requirement interdependencies); prompt/verbalization design is dataset-dependent; generalizability limited to tested datasets; environmental/resource cost discussed.
51,Using LLMs in Software Requirements Specifications: An Empirical Evaluation,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202706343&doi=10.1109%2fRE59067.2024.00056&partnerID=40&md5=2f428309a8c336f10c23df70e3d874d0,,,,,,,,,YES,F,,,1,1,,software development tools (university club management portal and other general software systems),,GPT-4 and CodeLlam,NO,-,Standalone,"zero-shot, prompt-context tuning, iterative correction",FS,Instruction,,no,no,no,no,"Likert-scale human expert evaluation (completeness, conciseness, internal consistency, non-redundancy, unambiguity, understandability, correctness, verifiability), time-to-completion (effort reduction)","controlled experiment (human vs LLM SRS generation and validation, multiple use cases, anonymized expert review)",Functional Suitability，Reliability,1,1,1,1,4,no,no,YES,YES,YES,no,YES,YES,YES,no,"concept/prototype, barriers highlighted","LLM stochasticity, prompt/context sensitivity, lack of domain adaptation, hallucinations, incomplete outputs"
52,Transforming Software Requirements into User Stories with GPT-3.5 -: An AI-Powered Approach,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190131589&doi=10.1109%2fIDCIoT59759.2024.10467750&partnerID=40&md5=280733fe088a3bf03db506d67a2ef0ce,,,,,,,,,YES,F,1,,1,,,"General domain, with examples in healthcare and e-commerce",,GPT 3.5,NO,-,Standalone,,FS OS ZS,Instruction,,no,no,no,no,qualitative output inspection,demonstration/case study,Functional Suitability，Usability,1,1,1,1,4,no,no,YES,YES,YES,YES,no,YES,YES,no,concept/prototype,"No explicit discussion of limitations or challenges; future work suggests integration, customization, feedback loop, and additional features."
53,Generating Requirements Elicitation Interview Scripts with Large Language Models,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172431302&doi=10.1109%2fREW57809.2023.00015&partnerID=40&md5=15427b726d1d8a96959cb813af87ccc5,,,,,,,,,YES,F,,1,,,,Requirements engineering education (training/teaching RE interview skills),,GPT-3.5 and Bard,NO,-,Standalone,"Few-shot, chain-of-thought",FS COT,Instruction,,no,no,no,no,"completeness, coherence, accuracy, semantic similarity (BERTScore, cosine similarity)","Qualitative expert review, student/instructor feedback, planned quantitative comparison with expert-generated scripts",Functional Suitability，Interaction Capability,1,1,1,1,4,no,no,no,no,no,no,YES,YES,YES,no,concept/prototype,LLMs struggle with complex conversation graphs; limited performance on certain mistake types; no fine-tuning; future work needed for domain adaptation and interactive script generation
54,Generating domain models from natural language text using NLP: a benchmark dataset and experimental comparison of tools,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192837407&doi=10.1007%2fs10270-024-01176-y&partnerID=40&md5=05083072b9bb803d8276a3f8ed35b8de,,,,,,,,,YES,F,,1,,,,"General software engineering (multiple domains: business, education, technology, health, entertainment, finance, construction, transportation)",domain model extraction from NL requiremetns,ChatGPT 3.5,No,-,Standalone,zero-shot,-,Instruction,NO,No,No,Dataset for: Text requirements to models (IEEEDataPort),Yes,"precision, recall, F-measure (F1-score)",Controlled experiment (empirical comparison on benchmark dataset),Functional Suitability，Performance Efficiency， Reliability,1,1,1,0.5,3.5,no,no,no,YES,no,no,no,YES,no,no,concept/prototype,Limited number of tools evaluated; future work suggests more tool comparisons and extension to behavioral models.
55,An Automated Model of Software Requirement Engineering Using GPT-3.5,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190516542&doi=10.1109%2fICETSIS61505.2024.10459458&partnerID=40&md5=a0778e5b98c3f8782a1f05474651e5f5,,,,,,,,,YES,F,1,,,,,"General domain (banking, medical, college education, multimedia, retail)",Requirements elicitation through automated generation of survey and interview questions,ChatGPT 3.5,No,-,Standalone,Zero-shot,-,Instruction-based,YES,no,no,no,no,"Flesch Reading Ease, Flesch-Kincaid Grade Level, Average Clarity Score, Average Relevance Score, Average Completeness Score","Quantitative analysis of generated questions (readability, clarity, relevance, completeness)",Functional Suitability，Performance Efficiency， Reliability,1,0.5,1,0.5,3,no,no,no,no,no,no,no,YES,YES,no,concept,"Limited detail in prompts affects specificity; struggles with non-textual outputs (e.g., illustrations); improvement possible with more detailed prompts and fine-tuning"
56,Generating Specifications from Requirements Documents for Smart Devices Using Large Language Models (LLMs),,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195833507&doi=10.1007%2f978-3-031-60405-8_7&partnerID=40&md5=927f2c57da5be0672a3e54c3b0c2d890,,,,,,,,,YES,F,,1,1,,,Ambient Assisted Living,Requirements specification generation,"ChatGPT 4.0, Google Bard",No,-,Standalone,Iterative prompting,-,"Instruction, question",YES,No,No,Proprietary product concept catalogue,No,Human evaluation,Controlled experiment (zero-shot and fine-tuning evaluation on annotated DPA dataset),"Functional Suitability, Performance Efficiency ",1,1,1,1,4,no,no,YES,no,YES,YES,YES,YES,YES,YES,Prototype/experimental,Dependence on prompt quality;Limited generalizability 
57,Software development in the age of intelligence: embracing large language models with the right approach; [智能化时代的软件开发: 拥抱大模型的正确姿势],,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178939500&doi=10.1631%2fFITEE.2300537&partnerID=40&md5=c84c7138c549e5ce8616f7ee8de57c27,,,,,,,,,YES->NO,F,1,1,1,,,,UML diagram generation，,GPT-3.5， GPT4,No,-,,,-,interactive/iterative,YES,,,,,,,Functional Suitability， Reliability， Interaction Capability,1,0.5,1,1,3.5,no,YES,YES,YES,no,no,no,no,no,no,,
58,NLP4ReF: Requirements Classification and Forecasting: From Model-Based Design to Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193847289&doi=10.1109%2fAERO58975.2024.10521022&partnerID=40&md5=3b661c07d62eec8653637e41489a9f21,,,,,,,,,YES,F,1,,1,,,"Internet of Things (IoT), general software engineering",Requirements classification and generation,GPT 3.5,NO,-,Standalone,zero-shot,FS,Instruction,,NLP4ReF-GPT,yes,"PROMISE_exp, PROMISE_IoT, proprietary IoT project dataset",yes,"Authenticity, BLEU, Self-BLEU, human evaluation","case study, expert study",Functional Completeness，Reliability,1,1,1,1,4,YES,YES,YES,YES,YES,YES,no,YES,YES,no,"concept/prototype, discussed potential, barriers highlighted","Limited to one real-life project, GPT-3.5 only, dataset size, OpenAI API cost and input size, potential for future policy changes, NLTK model limited by training data"
59,Harnessing LLM Conversations for Goal Model Generation from User Reviews,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190775035&doi=10.5220%2f0012352200003636&partnerID=40&md5=6e2a81192e6c303fafdfec8e995c81cc,,,,,,,,,YES,F,,1,1,,,"Mobile applications (user reviews from Line, Google Docs, YouTube)",Review clustering for goal identification,GPT-4,No,-,Standalone,,-,Question， Instruction,YES,no,no,"proprietary dataset (150 user reviews from Line, Google Docs, YouTube)",no,"Tree-Edit-Distance-based Similarity (TEDS), precision, recall",controlled experiment (comparison with manual and existing automated methods),Functional Suitability， Performance Efficiency， Interaction Capability,1,1,1,1,4,no,no,No,no,no,no,yes,no,no,no,concept/prototype,Stability of LLM output and time complexity are discussed as limitations; suggestions for fine-tuning and few-shot learning are proposed for future work.
60,An Innovative Approach to Develop Persona from Application Reviews,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160573483&doi=10.5220%2f0011996000003464&partnerID=40&md5=9cbb764e3f4fb0a2be237e51f94b09d9,,,,,,,,,YES,F,1,,,,,"E-commerce applications (departmental stores, supermarket, pharmacy, retailer, food, fashion, etc.)",Persona generation,GPT-3,NO,0,Standalone,,ZS,Instruction,,no,no,proprietary dataset of 4931 e-commerce app reviews,no,"manual alignment (expectations/frustrations), accuracy (87% agreement in manual sample)","manual sampling and comparison, cross-case study",Functional Suitability Interaction Capability,1,1,1,0.5,3.5,no,no,yes,no,no,no,no,no,no,no,concept/prototype,"Limited to English reviews, small sample size, some manual analysis required, low quality of some review data, not directly transferable to other languages."
61,MAPE-K Loop-Based Goal Model Generation Using Generative AI,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174704008&doi=10.1109%2fREW57809.2023.00050&partnerID=40&md5=9d113f0783b2a6958a86b903645ff9ba,,,,,,,,,YES,F,,1,1,,,"General domain (case studies: library management system, cleaning robot)",Initial goal model generation,ChatGPT-4,No,-,Hybrid,"Role-based, iterative, prompt engineering, multi-expert simulation",-,Instruction,YES,no,no,no,no,Precision (for expert opinions),Case study,Functional Suitability ， Reliability， Interaction Capability,1,1,1,1,4,no,YES,YES,YES,no,no,YES,YES,YES,no,concept/prototype,LLMs may generate overly generic models; domain knowledge limitations; semi-automated process; need for case-specific goal integration
62,Requirements Modeling Aided by ChatGPT: An Experience in Embedded Systems,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174700840&doi=10.1109%2fREW57809.2023.00035&partnerID=40&md5=4f9f079d80f1428ba684dc9ad50c387a,,,,,,,,,YES,F,,1,,,,Embedded systems (digital home system),Domain model extraction,GPT-3.5,No,Temperature = 0.8,Standalone,Zero-shot,ZS,Instruction,YEs,no,no,Digital Home System requirements document (publicly linked),yes,Coverage (compared to manual modeling),Case study (comparison with manual modeling),Functional Suitability,1,1,1,1,4,no,no,no,YES,no,no,YES,no,no,no,concept/prototype,Prompt design is domain-specific; missing interactions and relations in auto-generated models; LLMs lack domain-specific RE knowledge; input requirements quality impacts extraction
63,MUCE: a multilingual use case model extractor using GPT-3,,2022,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124727718&doi=10.1007%2fs41870-022-00884-2&partnerID=40&md5=02c702b488147448d862922c06dc621b,,,,,,,,,YES,F,,1,,,,"General domain; multilingual software requirements (English, Spanish, French)",Multi-lingual use case extraction,GPT-3,No,Temperature = 0.5,Standalone,Few-shot learning (in-context learning),FS,Instruction,YES,MUCE,No,Proprietary corpus of 50 software engineering case studies (12 used for few-shot learning),No,"Precision, Recall, F1-score",Case study (comparison with human-generated gold standard),Functional Suitability,1,1,0.5,1,3.5,no,no,no,YES,no,no,YES,no,YES,no,concept/prototype,Tool is not open source; dataset is not public; performance depends on clarity of input requirements
64,On the Use of GPT-4 for Creating Goal Models: An Exploratory Study,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174689248&doi=10.1109%2fREW57809.2023.00052&partnerID=40&md5=34feeb56ed09dd870cc9502354c7dc24,,,,,,,,,YES,F,1,,,,,"Goal modeling in requirements engineering; domains: Kids Help Phone (well-known), Social Housing (less studied)",,GPT-4,No,0.5,"Standalone, interactive","Zero-shot, prompt engineering, iterative refinement (interactive feedback)",FS,Instruction,,no,no,"Custom exam questions, Kids Help Phone domain, Social Housing domain (proprietary)",yes,"Manual grading (0-5 scale) by experts, coverage of ground-truth model elements, percentage of correct/incorrect/reasonable elements","Controlled experiment, expert study, interactive session",Performance Efficiency，Usability,1,1,0.5,0.5,3,YES,no,no,YES,no,YES,YES,YES,YES,no,"concept/prototype, barriers highlighted","High output variation, generic responses, limited domain-specific reasoning, need for aggregation, path-dependence in interactive sessions"
65,The Return of Formal Requirements Engineering in the Era of Large Language Models,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190652313&doi=10.1007%2f978-3-031-57327-9_22&partnerID=40&md5=6a6957ef2b5d446efab54060b069cb43,,,,,,,,,YES,F,,,1,,,"General domain, with focus on software engineering and LLM-generated code",Formal requirements extraction from natural language,LLMs in general,No,-,Hybrid,,FS,instruction,No,no,no,no,no,,Vision/position paper; no empirical evaluation,"Reliability, Security",1,0.5,0,1,2.5,YES,YES,no,YES,no,no,YES,YES,no,no,concept/vision only,"Accessibility of formal methods, need for human-in-the-loop, lack of empirical validation"
66,Investigating ChatGPT's Potential to Assist in Requirements Elicitation Processes,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175597991&doi=10.1109%2fSEAA60479.2023.00061&partnerID=40&md5=6ef7b6e358ae85e7a90276b32000b82e,,,,,,,,,YES,F,1,,,,,"Trustworthy AI systems (general domain, including generative AI, autonomous vehicles, self-driving cars, AI chatbots)",,GPT-3.5,NO,-,Standalone,Zero-shot,,Question,,no,no,Supplementary material (ChatGPT responses); interview data (not public),yes,"Expert human evaluation (Abstraction, Atomicity, Consistency, Correctness, Unambiguity, Understandability, Feasibility)","Controlled experiment (comparison with human experts, double-blind evaluation)",Functional suitability，Security,1,1,1,1,4,YES,YES,YES,YES,no,no,YES,no,YES,no,concept/proof-of-concept,"Generalizability to other domains, construct validity, averaging of expert scores, one-shot prompt limitation"
67,Large Language Models in Enterprise Modeling: Case Study and Experiences,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190380959&doi=10.5220%2f0012387000003645&partnerID=40&md5=bac26357d48c439916079333a0539c97,,,,,,,,,YES,F,,1,1,,,"enterprise modeling (hospitality management, corporate event planning)",Enterprise modeling and process modeling,ChatGPT-4,No,-,Standalone,,ZS,instruction-based,YES,no,no,no,no,"accuracy, completeness, comprehensibility, time (efficiency)",quasi-experiment (comparison with domain expert),"Functional Suitability , Interaction Capability, Performance Efficiency",1,1,0.5,1,3.5,no,YES,no,YES,no,no,YES,YES,YES,no,concept/prototype,"Limited context understanding, sensitivity to input, inability to express uncertainty, not generalizable (single experiment), prompt engineering not systematic"
68,Leveraging Natural Language Processing for a Consistency Checking Toolchain of Automotive Requirements,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174411487&doi=10.1109%2fRE57278.2023.00029&partnerID=40&md5=d98c62b056132027522af34e29866df9,,,,,,,,,YES,F,,1,,1,,"Automotive requirements (Adaptive Light System, Advanced Driver Assistance System)",Automatic translation of natural language requirements into structured English,GPT-J,No,-,Standalone,Few-shot learning with OptKATE context selection,FS,Description,No,no,no,Daimler automotive requirements dataset,no,"BLEU, SE score (manual class-based metric)",Controlled experiment (transformation and consistency checking on real-world dataset),"Functional Suitability, Performance Efficiency , Reliability",1,1,0.5,1,3.5,no,no,no,YES,no,no,no,YES,YES,no,prototype,Manual review required for LLM outputs; rare false positives in consistency checking; dataset not public; only one LLM evaluated
69,CRAFTER: A Persona Generation Tool for Requirements Engineering,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193961909&doi=10.5220%2f0012718400003687&partnerID=40&md5=b119bedbee18c6221981f0d0a405d2d0,,,,,,,,,YES,F,1,,1,,,"General domain; supports multiple domains including health, education, software development, etc.",Domain-specific persona generation,GPT-3.5,No,-,Standalone,User-guided persona generation using LLM prompts based on user-selected domain and human factors.,FS,Description,No,CRAFTER,Yes,no,no,"System Usability Scale (SUS), qualitative user feedback",User study (questionnaire with 19 participants),"Functional Suitability, Interaction Capability, Maintainability, Flexibility",1,1,1,1,4,YES,YES,YES,YES,no,no,YES,YES,YES,no,concept/prototype,"User interface and navigation issues, lack of persona layout flexibility, limited context/domain adaptability, lack of introductory guidance for new users."
70,Prompt Patterns for Agile Software Project Managers: First Results,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188687773&doi=10.1007%2f978-3-031-53227-6_14&partnerID=40&md5=0bbb9dfd12db3ada0b4615c14b6e4046,,,,,,,,,YES,F,,1,,1,1,Agile Project Management ,Requirements engineering and management,GPT-3.5 and GPT-4,No,-,Standalone conversational assistant,No,FS,Instruction,YES,No,no,no,no,Human qualitative evaluation,Case-based empirical demonstration,"Functional Suitability , Interaction Capability, Reliability, Maintainability",1,1,1,1,4,YES,YES,YES,YES,no,no,YES,YES,YES,no,concept/prototype,Token-size limit (2048) may restrict large-scale RE specifications.
71,A Transformer-based Approach for Abstractive Summarization of Requirements from Obligations in Software Engineering Contracts,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174402797&doi=10.1109%2fRE57278.2023.00025&partnerID=40&md5=47d6bbb87806e5d0f9fd10eb69fde5dd,,,,,,,,,YES,F,1,1,,,,"General domain (13 domains: healthcare, automotive, finance, banking, pharmaceuticals, telecom, technology, clothing retail, supermarket, agriculture, ecommerce, manufacturing, logistics and supply chain)",,GPT-3,YES,-,Standalone,"few-shot (prompt engineering for GPT-3, fine-tuning for NLG models)",ZS,Instruction,,no,no,"Proprietary SE contracts dataset (251 contracts, 13 domains)",no,"ROUGE-1, ROUGE-2, ROUGE-L, human evaluation (Correctness, Coherence, Completeness, Readability, Conciseness)","Controlled experiment (automated metrics), expert study (human evaluation)",Functional suitability，Reliability,1,1,1,1,4,no,YES,YES,no,no,no,YES,YES,YES,no,concept/prototype,"Dataset generalizability, reliance on manual refinement, ROUGE limitations, human evaluation bias, inability to fine-tune GPT-3, proprietary data"
72,Inconsistency Detection in Natural Language Requirements using ChatGPT: a Preliminary Evaluation,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174384397&doi=10.1109%2fRE57278.2023.00045&partnerID=40&md5=b8959a0ae02bbd555cdc01b46b60a647,,,,,,,,,YES,S,,,,1,,"General domain (software requirements for coffee machine, e-shop, library system, train control system)",,GPT-3.5,NO,-,Standalone,Zero-shot,OS,Instruction,,no,no,Zenodo archive (https://zenodo.org/record/8089810),Yes,"precision, recall",Controlled experiment (comparison with expert judgment),Reliability，Maintainability,1,1,1,1,4,no,no,no,YES,no,no,no,YES,YES,no,concept/prototype,Limited to short documents; performance drops with longer/more complex requirements; only preliminary results; small number of participants
73,"Large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study",,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180630873&doi=10.1007%2f978-3-031-46002-9_23&partnerID=40&md5=317aeedef81c776751800c5f7caa7a52,,,,,,,,,YES,F,1,1,1,1,,"General domain (software requirements for coffee machine, e-shop, library system, train control system)",Requirements elication and refinement,ChatGPT Google's Bard,No,-,Hybrid,GPT/Bard,FS,Iterative /Question,No,No,no,no,no,"human reviewers, and quantitatively,BLEU, ROUGE ",Controlled experiment (comparison with expert judgment),"Functional Suitability， Interaction Capability
Reliability",1,1,1,1,4,YES,YES,YES,YES,YES,no,YES,YES,YES,YES,concept,Legal Uncertainty and Copyright Issues.
74,Large language models in requirements engineering for digital twins,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186961854&partnerID=40&md5=ee90c31d4520c375549194130c380710,,,,,,,,,YES,F,1,,,,,Digital twin engineering for air conditioning and ventilation systems,,GPT4,NO,-,Standalone,"Role prompting, iterative prompting, feedback loop",,Instruction,,no,no,no,no,"completeness, correctness (expert evaluation)","quasi-experiment, qualitative content analysis, expert evaluation",Functional suitability，Reliability,1,1,1,1,4,,,,,,,,,,,concept/prototype,"Single domain expert, limited domain, ChatGPT cannot interpret visual material, prompt engineering not fully explored, data cutoff limits, consistency issues"
75,Requirements Verification Through the Analysis of Source Code by Large Language Modelså,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191742945&doi=10.1109%2fSoutheastCon52093.2024.10500073&partnerID=40&md5=e119f7de29930b833cca2c5cce6de4ab,,,,,,,,,YES,F,,,,1,,general software development (code verification against requirements),Requirements verification and analysis,GPT3.5,NO,-,Standalone,zero-shot,-,"Instruction, iterative",,no,no,no,no,qualitative analysis (requirement satisfaction assessment),case study (multiple code/requirement scenarios),Functional Correctness，Reliability,1,1,1,1,4,no,YES,no,YES,YES,no,no,YES,YES,no,concept/prototype,Limited to qualitative scenarios; no large-scale or quantitative evaluation
76,LLM-Based Class Diagram Derivation from User Stories with Chain-of-Thought Promptings,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196535115&doi=10.1109%2fCOMPSAC61105.2024.00017&partnerID=40&md5=a6538760d541339e5bd4c8587606d91d,,,,,,,,,YES,F,,1,,,,"General domain (agile software projects, user stories to class diagrams)",Class identification,GPT-3.5-turbo,NO,-,Standalone,"Chain-of-thought, zero-shot, few-shot",COT,Instruction/description,YES,no,no,User stories from Project Data Hub (DH) and Planning Poker (PP) (from [17]),no,"validity (precision), completeness (recall), human evaluation","Case study, comparative experiment with human and LLM baselines",Functional Suitability， Performance Efficiency ， Reliability,1,1,1,1,4,YES,no,no,YES,YES,no,YES,YES,YES,no,concept/prototype,"LLM struggles with aggregation summarization, status attribute identification, and relationship inference when context is implicit."
77,Extracting Domain Models from Textual Requirements in the Era of Large Language Models,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175600987&doi=10.1109%2fMODELS-C59198.2023.00096&partnerID=40&md5=382007bd0bd9f1adad0b4c572becf766,,,,,,,,,YES,F,,1,,,,"General domain (agile software development, user story backlogs)",Domain model extraction,GPT-3.5,NO,0,Standalone,"Function call API with JSON schema constraints, prompt engineering, conversation-based extraction",FS,Instruction,,no,no,"Dalpiaz et al. (2018) user story dataset (22 products, 1,679 user stories), manual annotation (Doccano)",yes,F1-score,"Controlled experiment (comparison to ground truth and two baselines: Visual Narrator, CRF)","Functional suitability, Maintainability",1,1,1,1,4,no,YES,YES,YES,YES,YES,YES,YES,YES,no,"concept/prototype, barriers highlighted","Limited to GPT-3.5, prompt engineering is a black box, only public datasets, privacy concerns for proprietary data, only F1 metric, no external annotation validation"
78,Towards an automatic contradiction detection in requirements engineering,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194078808&doi=10.1017%2fpds.2024.207&partnerID=40&md5=07d66edb9986459bb75b86598a6a92a2,,,,,,,,,YES,F,,1,,,,"engineering/product development, specifically electric bus systems and general technical requirements",requirements contradiction detection,GPT-3,NO,-,hybrid,formal logic + LLM (prompt engineering),ZS,instruction-based,No,ALICE,no,"Dataset 1 (curated), Dataset 2 (electric bus, 1071 pairs), Dataset 3 (electric bus, 3916 pairs)",partial,"accuracy, recall",controlled experiment (manual labeling and validation),"Functional Suitability,Reliability, Maintainability",1,1,0.5,0.5,3,No,YES,YES,YES,Computational cost,No,No,Reproducibility,No,No,"concept/prototype, discussed potential, barriers highlighted",Requires controlled natural language; atomicity; filler words and passive voice can cause errors; overfitting risk due to limited dataset; not optimized for speed
79,"Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT",,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193068034&partnerID=40&md5=9e2cd1fb480cf135828ef43c5be4352e,,,,,,,,,YES,F,,1,,,,"general domain (software requirements classification across multiple datasets: PROMISE, Dronology, ReqView, Leeds Library, WASP)",Enhanced requirements classification,gpt-3.5-turbo and gpt-4,NO,-,Standalone,,ZS FS,Instruction,,no,no,"PROMISE, Dronology, ReqView, Leeds Library, WASP",yes,"F-beta score (class-weighted), precision, recall",controlled experiment (empirical evaluation on public datasets),Functional Appropriateness，Reliability,1,1,1,1,4,YES,no,no,YES,YES,YES,no,YES,YES,no,barriers (limitations and threats to validity discussed),"Prompt sensitivity, non-determinism, dataset imbalance, subjectivity of annotations, server/API errors"
80,Zero-shot Bilingual App Reviews Mining with Large Language Models,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182397320&doi=10.1109%2fICTAI59109.2023.00135&partnerID=40&md5=84f680d30041e89f4f3660fc7c06165a,,,,,,,,,YES,F,1,1,,,,Health & Fitness mobile apps (bilingual app review mining),"Zero-shot requirements elicitation, Cross-lingual clustering, Abstractive summarization",GPT-3.5-turbo,NO,-,Standalone,zero-shot,ZS,instruction-based,YES,Mini-BAR,yes,"Mini-BAR annotated bilingual app review dataset (12,000 reviews)",yes,"precision, recall, F1-score, Normalized Mutual Information (NMI), Adjusted Rand Index (ARI), human evaluation (Likert scale: relevance, consistency, fluency, coherence)","controlled experiment, human evaluation","Functional Suitability,Performance Efficiency,Flexibility",1,1,1,0.5,3.5,bias,No,No,YES,Computational cost,No,No,Reproducibility,No,No,concept/prototype,Limited to Health & Fitness domain; subjectivity in annotation; ChatGPT access/cost; small clustering evaluation dataset
81,A Self-Iteration Code Generation Method Based on Large Language Models,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190276702&doi=10.1109%2fICPADS60453.2023.00049&partnerID=40&md5=05fb124e1cf798bb56fc8a3395744d5b,,,,,,,,,YES->NO,F,1,1,,,,,The task focuses on iterative refinement of requirements and code in software development cycles.,GPT-3.5,NO,-,,,FS,instruction-based,YES,,,,,,,"Functional Suitability, Maintainability, Flexibility",1,1,1,0.5,3.5,Bias,No,No,YES,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,,
82,Human-Centric Autonomous Systems With LLMs for User Command Reasoning,,2024,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188691382&doi=10.1109%2fWACVW60836.2024.00108&partnerID=40&md5=df07239d5bb722f133c2fbde45f1dc34,,,,,,,,,YES,F,1,1,,,,autonomous driving (in-cabin user command understanding),Classification of user commands into system requirements. Reasoning about user intent and safety for autonomous driving scenarios.,"GPT-4, GPT-3.5-turbo, CodeLlama-34b-Instruct, and Llama-2-70b-Chat.",NO,-,Standalone,"few-shot, chain-of-thought",FS,instruction-based,YES,no,no,UCU Dataset,yes,accuracy,controlled experiment (benchmark evaluation),"Functional Suitability, Interaction Capability, Safety",1,1,1,0.5,3.5,Bias,YES,YES,YES,Computational cost,Real-Time Processing,No,Reproducibility,Controllability,No,concept/prototype,Ambiguity in ground truth for in-cabin monitoring; prompt design sensitivity
83,Efficient Extraction of Technical Requirements Applying Data Augmentation,,2022,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146926373&doi=10.1109%2fISSE54508.2022.10005452&partnerID=40&md5=1640610e2c705d8af3b55ebcfc416fdf,,,,,,,,,YES,F,1,,1,,,"Automotive engineering (EDAG case studies), with additional data from software engineering specifications",Classifier training automation,GPT-J,No,-,Standalone,"Data augmentation for training classifiers; no advanced LLM-specific techniques (e.g., chain-of-thought) described",FS,"instruction-based, descriptive, and iterative prompts",,no,no,"EDAG requirements (proprietary), open-source software requirements (see references)",no,"Precision, Recall, F1-score","Controlled experiment (cross-validation, transferability tests on real and augmented data)",Functional Suitability， Maintainability,1,1,1,1,4,no,no,no,no,YES,YES,YES,YES,YES,no,"concept/prototype, barriers highlighted",Domain mismatch in augmentation reduces performance; manual quality check of augmented data required; parsing rules may need adaptation for new document types
84,Empirical Evaluation of ChatGPT on Requirements Information Retrieval Under Zero-Shot Setting,,2023,Scopus,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184991119&doi=10.1109%2fICNGN59831.2023.10396810&partnerID=40&md5=f2576db24af0385b5cf88b5aa37096a6,,,,,,,,,YES,F,1,1,,,,"General domain (software requirements, app reviews, app descriptions, user stories)",Zero-shot requirements retrieval,GPT-3.5-turbo,NO,0,Standalone,Zero-shot,ZS,Instruction,,no,no,"PROMISE NFR, App review NFR, Smarthome Crowd Requirements, App Descriptions (Wu et al. 2021)",Yes,"Precision, Recall, F1/Fβ",Controlled experiment (empirical evaluation on benchmark datasets),Functional suitability，Reliability,1,1,1,1,4,no,no,no,YES,no,no,no,YES,YES,no,concept,Limited number of tasks and datasets; prompt sensitivity; non-determinism of LLM outputs
85,Investigating ChatGPT’s Potential to Assist in Requirements Elicitation Processes,,2023,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371698,,,,,,,,,YES,F,1,,,,,"Trustworthy AI systems (general domain, not system-specific)",Requirements generation for Trustworthy AI qualities. Requirements comparison between human-generated and AI-generated artifacts.,GPT-3.5,No,-,Standalone,Zero-shot,ZS,Instruction-based,YES,no,no,Supplementary material (ChatGPT responses); interview data (not public),yes,"Expert human evaluation (7 requirements quality attributes: Abstraction, Atomicity, Consistency, Correctness, Unambiguity, Understandability, Feasibility)","Controlled experiment (comparison of ChatGPT vs. human expert responses, evaluated by independent RE experts)","Functional Suitability, Understandability.",1,1,1,0.5,3.5,Bias,Ethical concerns,Privacy,Explainability,No,No,Hallucinations,No,No,No,concept/proof-of-concept; not in production,Generalizability to other domains; construct validity (definitions not provided to participants); averaging of expert scores may minimize variation; one-shot prompt design may limit interaction
86,Exploring the Potential Use of Generative AI in Software Engineering Education,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740416,,,,,,,,,YES,F,1,1,,,,,"equirements elicitation and refinement for game development.
Generating diagrams (class, sequence).
Debugging and test case creation.","GPT-3.5, GPT-4",No,,,,ZS,instruction-based,YES,,,,,,,"Functional Suitability, Flexibility, Interaction Capability",1,1,1,1,4,Bias,Ethical concerns,Privacy,Explainability,Computational cost,No,Hallucinations,No,Controllability,Authorship,,
87,ChatGPT Chats Decoded: Uncovering Prompt Patterns for Superior Solutions in Software Development Lifecycle,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555800,,,,,,,,,YES,F,1,1,,1,,,Requirements elicitation with tailored questions.Error identification in generated requirements.Contextual refinement of outputs for better validation.,"ChatGPT, Code-Llama, and Mistral-7B",No,"General software development lifecycle (including requirements engineering, design, development, quality assurance, maintenance, management)",Standalone,"Manual and LLM-assisted prompt pattern classification, peer LLM review for response quality",-,instruction-based,YES,no,no,DevGPT,no,"Code quality (Cyclomatic Complexity, Maximum Levels, Number of Paths, Unconditional Jumps, Comment Frequency, Program Length, Average Size, Number of Inputs/Outputs), Manual static analysis, Percentage-based scoring","Manual analysis, LLM-based peer review, clustering, and categorization","Functional Suitability, Interaction Capability,Reliability",1,1,1,0.5,3.5,Bias,Ethical concerns,No,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,concept,ChatGPT's self-correction ability is limited; effectiveness of some prompt patterns is low; dataset is not public.
88,Exploring the Capabilities of Large Language Models for the Generation of Safety Cases: the Case of GPT-4,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628935,,,,,,,,,YES,F,,,,1,,,"Generating safety cases in GSN-compliant structured prose.
Validating the semantic and structural correctness of generated safety arguments.",GPT-4,No,"Safety-critical systems (energy, automotive, ML-enabled vehicle components, X-ray systems)",Standalone,"Zero-shot, few-shot (prompting with/without domain knowledge and syntax)",ZS,instruction-based,YES,no,no,"X-ray safety case (from [33]), ML-enabled Tire Noise Recognition (TNR) safety case (from [34])",no,"Structural and lexical similarity (manual rating), Cosine similarity (semantic), Reasonability (manual rating), Kendall’s Tau (inter-rater agreement)","Expert study (manual rating by graduate students and faculty, multiple rounds)","Functional Suitability,Reliability,Flexibility",1,1,1,1,4,No,Ethical concerns,Security,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,concept/prototype,Inconsistent hierarchy generation; limited to simplified GSN; lack of public datasets; human intervention still required.
89,Enhancing Legal Compliance and Regulation Analysis with Large Language Models,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628489,,,,,,,,,YES,F,1,,,1,,Legal compliance and regulatory analysis in food safety and GDPR (Data Processing Agreements),"Legal requirements classification: Identifying relevant provisions in regulatory texts.
Compliance assessment: Automating the evaluation of DPAs against GDPR rules.","GPT-3.5, GPT-4,","YES,",,Standalone,,ZS,instruction-based,YES,no,no,"DPA dataset, food-safety regulations, FSRG, US FDA regulations",no,"Accuracy, Precision, Recall, F-score","Controlled experiment (multiple experiments, boxplots, comparison with baselines)","Functional Suitability, Performance Efficiency, Flexibility",1,1,1,1,4,Bias,Ethical concerns,Privacy,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,concept/prototype,Limited dataset size for some concepts; future work needed for expert validation and broader regulatory coverage
90,Building Device Models Using LLMs for Requirements Simulation in Smart Homes,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628634,,,,,,,,,YES,F,1,1,,,,smart home (IoT) devices,"Device behavior extraction.
Generating Mealy machines for requirements simulation.
Simulation-based requirements validation.",GPT-4,No,,Standalone (with iterative feedback loop and external model checker),"ReAct paradigm, multi-turn dialogue, iterative self-correction with external feedback",ZS,instruction-based,YES,no,no,no,no,"requirements simulation usability (scenario-based), model validity (clarity, determinism, connectivity, resettable)","Case study (multiple smart home devices, scenario simulation)","Functional Suitability,Maintainability,Flexibility",1,1,1,1,4,Bias,No,No,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"concept/prototype, barriers highlighted (e.g., context window, semantic validation)",Semantic-level validation not addressed; only syntax-level model checks; context window limits for long manuals
91,Using GPT-4 Turbo to Automatically Identify Defeaters in Assurance Cases,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628633,,,,,,,,,YES,F,1,,,1,,"Assurance cases in safety-critical domains (nuclear, aviation)","Defeater generation for assurance cases.
Context-aware validation of safety-critical claims.",GPT-4 Turbo.,No,"YES, mentions reproducible outputs with a fixed seed, but no specific temperature values were provided.",Standalone,"Chain-of-thought prompting, predicate-based rules","ZS,OS",instruction-based,YES,no,no,"CERN LHC Machine Protection System assurance case fragments, Air Traffic Control System assurance case fragment",no,"Fuzzy string similarity, BLEU score, Cosine semantic similarity, Human reasonability rating, Cohen’s Kappa",Controlled experiment with human expert assessment,Functional Suitability Reliability Interaction Capability,1,1,1,1,4,No,Ethical concerns,Security,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"concept/prototype, barriers highlighted","Small, domain-unbalanced dataset; possible overlap with LLM training data; manual data translation risk"
92,Cartoon Extraction Mechanism via UML Model Based on Natural Language Requirement Specs,,2023,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590006,,,,,,,,,YES,F,,1,1,,,Cartoon/image generation from natural language requirements in software engineering context,"Requirement formalization using UML diagrams.
Mapping UML models to visual cartoon elements for further generative applications.",Not Applicable,,,Standalone (conceptual mechanism),"Linguistic analysis, semantic role labeling, UML mapping",-,Not Applicable,No,no,no,no,no,,"Conceptual/method proposal, no empirical evaluation",Functional Suitability Interaction Capability Flexibility,1,1,1,0.5,3.5,No,No,No,Explainability,Computational cost,No,No,No,Controllability,No,concept,No empirical validation; method is conceptual and requires further research for automation and practical deployment.
93,Development of a GenAI-Powered Hypertension Management Assistant: Early Development Phases and Architectural Design,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628598,,,,,,,,,YES,F,1,,,1,,Healthcare (hypertension management via remote patient monitoring),"Generating personalized patient communication.
Creating clinical summaries for hypertension management workflows.",GPT-4,YES,,"Hybrid (microservice architecture with EHR, SMS, and GenAI integration)","few-shot, prompt-based personalization, human-in-the-loop validation, rule-based filtering, adversarial debiasing, RLHF","FS,ZS",instruction-based,,RPM AI Assistant,no,"10 hypothetical patient scenarios (non-PHI), internal patient/provider feedback",no,"accuracy, empathy (human evaluation), readability (human evaluation), provider satisfaction (survey)","expert study (provider and patient advisory committees, surveys, qualitative feedback)",Functional Suitability Reliability Security,1,1,1,1,4,Bias,Ethical concerns,Privacy,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"pilot (MVP, not yet in production)","Limited to MVP, small-scale evaluation, no real patient data, future work needed for broader deployment and generalizability"
94,AI-Driven User Story Generation,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467677,,,,,,,,,YES,F,1,,,,,"General domain (agile software development, user story generation)","Generating user stories based on templates.
Evaluating user story coherence and semantic relevance using BLEU, ROUGE-N, and BERTScore.",GPT-3,YES,,Standalone,fine-tuning,FS,instruction-based,YES,no,no,Dalpiaz et al. user story corpora (22 corpora),"partial (some corpora not public, but main set used is public)","BLEU, ROUGE-N, BERTScore",Quantitative experiment (automatic comparison to reference user stories),Functional Suitability  Reliability Flexibility,1,1,1,1,4,Bias,No,No,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,concept/prototype,Need for real-world validation with practitioners; optimal N-gram size and corpus adaptation not fully explored
95,Requirements Satisfiability with In-Context Learning,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628468,,,,,,,,,YES,F,,,,1,,Legal compliance for mobile applications (GDPR consent requirements),,"GPT-3.5-turbo, GPT-4",NO,0.7 top1.0,Standalone,,ZS FS COT,Instruction,,no,no,Synthetic dataset of mobile app scenarios and design practices (based on GDPR consent requirements),yes,accuracy,"Controlled experiment (using synthetic and annotated datasets, inter-rater agreement)",Functional Suitability， Reliability,1,1,1,1,4,no,YES,no,YES,YES,YES,YES,YES,YES,no,concept/prototype,Synthetic data may not represent real practices; alignment tax in LLMs; limited authoritative ground truth; domain-specific limitations
96,Prompts Matter: Insights and Strategies for Prompt Engineering in Automated Software Traceability,,2023,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260721,,,,,,,,,YES,F,,,,1,1,"General software engineering (traceability across embedded systems, healthcare, UAVs)","Traceability link generation using classification and ranking.
Validation of traceability predictions with intermediate reasoning.","Claude, GPT-3",No,,Standalone,"Chain-of-thought, prompt engineering, ranking, classification, VSM pre-sorting for ranking","ZS,FS,COT",instruction-based,YES,no,no,"CM1, iTrust, Dronology (NL and PL)",yes,"Precision, Recall, Mean Average Precision (MAP)",Controlled experiment (on public datasets),Functional Suitability Maintainability Flexibility,1,1,1,1,4,Bias,No,No,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"concept/prototype, barriers highlighted","Limited number of datasets and queries, possible prior exposure of LLM to public datasets, limited LLMs tested, prompt engineering is time-consuming"
97,Requirements-Driven Slicing of Simulink Models using LLMs,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628750,,,,,,,,,YES,F,1,,1,1,,"cyber-physical systems (CPS), specifically Simulink models in domains like avionics, railways, maritime, and automotive","Requirements-driven slicing for simplifying model analysis.
Validation of model slices against specified requirements.",GPT-4,No,0.7,Standalone,,"ZS,FS,COT",instruction-based,YES,no,no,"Effector Blender (training), Tustin Integrator (evaluation)",no,"accuracy (fitness polarity match between slice and original model), conciseness (number of blocks in slice)",controlled experiment (with repeated runs and union of results),Functional Suitability Maintainability Reliability,1,1,1,1,4,No,No,Security,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,concept/prototype,"Limited evaluation (only two models, one LLM); prompt size/token limit for large models; partial accuracy assessment (test suite based, not exhaustive verification)"
98,Development of Data-driven Persona Including User Behavior and Pain Point through Clustering with User Log of B2B Software,,2024,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556427,,,,,,,,,YES,F,1,1,,,,B2B software (real estate agent tools); generalizable to B2B software services,"Persona construction with attributes like age, behaviors, and demographics.
Behavior clustering to analyze user logs for pain point detection.",ChatGPT,No,,Hybrid,"Clustering (k-means, TF-IDF) + LLM text generation + AI face generation",FS,instruction-based,YES,"No (uses ChatGPT and FaceGenerator as components, not a named tool)",No,Proprietary user log dataset from 'ES Good Property One',No,"Cosine similarity (quantitative), Expert qualitative evaluation",Case study with expert review and quantitative cluster validation,Functional Suitability Interaction Capability Flexibility,1,1,1,1,4,Bias,No,Privacy,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"concept/prototype (case study, not in production)",Session clusters not based on sentiment; not suitable for early-stage agile development; automation of process not fully optimized
99,ECHO: An Approach to Enhance Use Case Quality Exploiting Large Language Models,,2023,IEEE Xplore,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371553,,,,,,,,,YES,F,1,,,1,,"General domain (UML use cases, with experiment in telemedicine microservice application)","Use case quality analysis.
Iterative improvement of UML use cases based on defined criteria (completeness, correctness, and clarity).",ChatGPT,No,,Standalone (ChatGPT Web interface),,FS,instruction-based and iterative,YES,ECHO,yes,Proprietary use case dataset (telemedicine microservice application),yes,"Completeness score, Correctness score, Clarity score, Unadjusted Use Case Points (UUCP), User satisfaction","Controlled experiment (experimental vs. control group, with expert oracle)",Functional Suitability Interaction Capability Reliability,1,1,1,1,4,No,No,No,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,"concept/prototype, discussed potential","Small sample size, limited domains, inability to set LLM hyperparameters, novelty effect, single oracle"
100,Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation,,2024,arXiv,,https://arxiv.org/abs/2404.16045,,,,,,,,,YES,F,1,,,,,"Product design, general domain (focus on early-stage product development and design requirements)",Diverse user agent generation,GPT-4-Turbo,No,-,"Agent-based simulation (standalone, with serial and parallel agent generation)","Chain-of-thought, diversity sampling, clustering (KMeans), context-aware prompting, role-based agent simulation",ZS COT,"Instruction, iterative",,Elicitron,no,"Proprietary (experiment-specific, based on simulated agents and interviews)",no,"Convex hull volume, Mean distance to centroid, Silhouette score, Precision, Recall, F1-score, Human qualitative evaluation","Controlled experiment (three experiments: agent diversity, latent needs identification, latent needs detection)",Functional Suitability，Usability,1,1,0.5,1,3.5,no,no,no,yes,yes,no,yes,no,yes,no,concept/prototype,Quality of insights depends on LLM capabilities; prioritizing latent needs remains a designer’s task; future work includes user studies and multi-agent interactions.
101,Automated Annotation with Generative AI Requires Validation,,2023,arXiv,,https://arxiv.org/abs/2306.00176,,,,,,,,,YES,F,,1,,,,,"Automated dataset annotation.
Validation of human annotations.
Improvement of codebooks for specific classification tasks.",GPT-4,No,,,,-,instruction-based,YES,,,,,,,Functional Suitabilit  Reliability Maintainability,1,1,1,1,4,Bias,Ethical concerns,Privacy,Explainability,Computational cost,No,Hallucinations,Reproducibility,Controllability,No,,
102,MARE: Multi-Agents Collaboration Framework for Requirements Engineering,,2024,arXiv,,https://arxiv.org/abs/2405.03256,,,,,,,,,YES,F,1,,1,1,,"general domain (multiple RE benchmarks: ATM, smart home, library, etc.)",,GPT 3.5 turbo,NO,0,hybrid,"multi-agent collaboration, prompt engineering, workspace artifact sharing",-,"Instruction, iterative",,MARE,no,"GoalModelDataset, 5 public use case benchmarks, 4 new problem diagram cases","partial (GoalModelDataset: yes, others: no)","Precision, Recall, F1-score, Human evaluation (completeness, correctness, consistency)","controlled experiment, human evaluation, ablation study",Functional Suitability，Reliability,1,1,0.5,1,3.5,no,no,no,YES,YES,no,YES,YES,YES,no,concept/prototype,Lower completeness in generated specifications; text length reduction by LLMs
103,Semantic API Alignment: Linking High-level User Goals to APIs,,2024,arXiv,,https://arxiv.org/abs/2405.04236,,,,,,,,,YES,S,1,,1,1,,"Software engineering, specifically API alignment for GitHub statistics applications (CatWatch)",,GPT4,No,-,"Agent-based (multi-agent cognitive architecture, standalone interactions in pilot)","Iterative prompt-based decomposition, role-based agent simulation, self-critique (planned, not implemented)",-,"Instruction, iterative",,no,no,"CatWatch API (Swagger), EMB database application",Yes,Qualitative mapping success (number of goals mapped to endpoints),"Case study (inspirational example, manual prompt interactions)",Compatibility，Reliability,1,1,0.5,1,3.5,no,no,YES,no,no,YES,no,no,YES,no,"concept/prototype, barriers highlighted","Manual intervention required, non-homogeneous outputs, difficulty in mapping business-specific endpoints, need for self-critique and iterative refinement"
104,LLM-based agents for automating the enhancement of user story quality: An early report,,2024,arXiv,,https://arxiv.org/abs/2403.09442,,,,,,,,,YES,F,,,1,,,"Agile software development in the postal/logistics domain (Austrian Post Group IT, mobile delivery application)",,GPT-3.5-Turbo， GPT-4,NO,1,Agent-based (multi-agent system),"Role-based, chain-of-thought, k-shot, AI planning, fact checklist, persona pattern",FS,"Instruction, iterative",,ALAS (Autonomous LLM-based Agent System),no,Synthetic user stories from Austrian Post Group IT (Mobile Delivery project),no,"Likert-scale human evaluation (simplicity, size, detail, description, achievability, measurable AC, validation), overall satisfaction",User study (questionnaire with 11 participants from 6 agile teams),Usability，Reliability,1,1,1,1,4,no,no,no,YES,YES,no,YES,YES,YES,no,"pilot (proof-of-concept in industry, not production)",Manual validation by human experts (PO) required; limited agent roles; increased story length/complexity; context alignment issues
105,Model Generation from Requirements with LLMs: an Exploratory Study,,2024,arXiv,,https://arxiv.org/abs/2404.06371,,,,,,,,,YES,F,,,1,,,"General domain (multiple domains: cyber-physical, healthcare, e-commerce, gaming, etc.)",Model Generation from Requirements,GPT3.5,No,-,Standalone,zero-shot,ZS,Instruction,YES,no,no,"PURE, Ten Lockheed Martin Cyber-Physical Challenges, user story dataset (Dalpiaz & Sturm 2020)",yes,"completeness, correctness, adherence to standard, understandability, terminological alignment","Expert study (qualitative and quantitative evaluation by experienced annotators, thematic analysis)","Functional Suitability 
Reliability 
Interaction Capability ",1,1,1,1,4,no,no,no,YES,no,no,YES,YES,YES,no,concept/prototype,"Lack of domain/contextual knowledge, memory-induced hallucinations, ignored requirements modifications, variability of output, subjectivity in evaluation"
Snowballing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,On the Use of ChatGPT to Support Requirements Engineering Teaching and Learning Process,"Carvallo Juan Pablo, Erazo-Garzón Lenin",2023,,10.1007/978-981-99-7353-8_25,,,,,,,,,,,,1,1,1,1,,Education ,Generating organizational context and environment models (DHARMA method).,GPT-3,No,No,Standalone conversational use,Basic interaction only,Zero-shot ,Instructional & interactive,No,No,No,No,No,Human evaluation,Exploratory case study & user study,"functional suitability, usability",1,1,1,1,4,0,0,0,0,0,0,1,0,1,0,Concept,"Accuracy issues, context forgetting, vague answers, lack of graphs."
2,nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models,"Cosler Matthias, Hahn Christopher",2023,,10.1007/978-3-031-37703-7_18,,,,,,,,,,,,,,1,,,"general domain (framework is domain-agnostic, demonstrated on formal specification translation)",Translation of unstructured natural language requirements to formal specifications in temporal logics (LTL) with ambiguity detection and interactive refinement,"Codex (code-davinci-002, commercial 2022 version), Bloom (176B, Huggingface API)",No,No,Standalone (web-based tool with human-in-the-loop),,,Instruction + Descriptive + Iterative (interactive few-shot),Yes,nl2spec,Yes,Expert user study benchmark (36 challenging NL-to-LTL instances),Yes,translation accuracy (correctness of LTL formula),"user study (expert-provided benchmark), interactive evaluation","functional_suitability, reliability, performance_efficiency, usability, security, maintainability, portability",1,1,1,1,4,0,0,0,1,1,0,0,0,1,0,"concept/prototype (open-source, not in production)",Quality depends on LLM pretraining data;requirements still require manual intervention
3,Inconsistency Detection in Natural Language Requirements using ChatGPT: a Preliminary Evaluation,"Fantechi Alessandro, Gnesi Stefania",2023,,10.1109/RE57278.2023.00045,,,,,,,,,,,,,1,,,,"General domain (software requirements for coffee machine, e-shop, library system, train control system)",Inconsistency detection in natural language requirements,GPT-3.5,No,No,Standalone,Reinforcement Learning from Human Feedback (RLHF),Zero-shot,Instruction,Yes,No,No,Zenodo archive (https://zenodo.org/record/8089810),Yes,"precision, recall",Controlled experiment (comparison with expert judgment),"functional_suitability, usability",1,1,1,1,4,0,0,0,1,0,0,0,1,0,0,concept/prototype,"Limited to small datasets, input size limitations, non-expert human judges, linguistic complexity not fully explored"
4,Extracting Domain Models from Textual Requirements in the Era of Large Language Models,"Arulmohan Sathurshan, Meurs Marie-Jean",2023,,10.1109/MODELS-C59198.2023.00096,,,,,,,,,,,,,1,,,,General domain (agile software product backlogs),Domain model (concept) extraction from agile user story backlogs,GPT-3.5-turbo-0613,No,No,Standalone,"Function call API with JSON schema constraints, prompt engineering, conversation-based extraction",Zero-shot (with prompt engineering and examples),Instruction + Example + Iterative (multi-phase conversation),Yes,No,No,"Dalpiaz et al. (2018) user story dataset (22 products, 1,679 user stories), manual annotation (Doccano)",Yes,F1-score,Controlled experiment (comparison to ground truth and other tools),"functional_suitability, performance_efficiency, usability, cost, reliability",1,1,1,1,4,0,0,1,0,1,1,1,1,0,0,"concept/prototype, barriers highlighted","dataset annotation subjectivity, no external validation, and no comparison to GPT-4 or other LLMs"
,,2022,4,,,,,,,,,,,,,,101,137,101,87,31,,,,,,,,,,,,174,,107,,,Count,237,218,194,210,173,,,,,,,,,,,,
,,2023,24,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,19,40,27,40,,,,,,,,,,,,
,,2024,113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1,4,1,20,,,,,,,,,,,,
,,2025,97,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,
,,,238,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,238,,,,,,,,,,,,